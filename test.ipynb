{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/WAVE/users/unix/smalladi/varian_ml/patient_data_resampled_training.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.CT_Size.value_counts())\n",
    "print(df.PT_Size.value_counts())\n",
    "print(df.Label_Size.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.CT_PixDim.value_counts())\n",
    "print(df.PT_PixDim.value_counts())\n",
    "print(df.Label_PixDim.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from monai.config import print_config\n",
    "from monai.data import (\n",
    "ArrayDataset,\n",
    "create_test_image_3d,\n",
    "decollate_batch,\n",
    "DataLoader,\n",
    "CacheDataset\n",
    ")\n",
    "from monai.handlers import (\n",
    "    MeanDice,\n",
    "    MLFlowHandler,\n",
    "    StatsHandler,\n",
    "    TensorBoardImageHandler,\n",
    "    TensorBoardStatsHandler,\n",
    ")\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.losses import DiceCELoss, DeepSupervisionLoss, DiceLoss\n",
    "from monai.metrics import compute_dice, DiceMetric\n",
    "from monai.networks.nets import UNet, SegResNet, SegResNetDS, SwinUNETR\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    Spacingd,\n",
    "    CropForegroundd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    Resized,\n",
    "    ScaleIntensityRanged,\n",
    "    RandShiftIntensityd,\n",
    "    RandAffined,\n",
    "    RandFlipd,\n",
    "    ToTensord,\n",
    "\n",
    ")\n",
    "from monai.utils import first\n",
    "import ignite\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'Hecktor22/model_data'\n",
    "data_dir = 'hecktor2022_training/hecktor2022'\n",
    "resampled_ct_path = 'hecktor2022_training/hecktor2022/resampled_largerCt'\n",
    "resampled_pt_path = 'hecktor2022_training/hecktor2022/resampled_largerPt'\n",
    "resampled_label_path = 'hecktor2022_training/hecktor2022/resampled_largerlabel'\n",
    "\n",
    "train_images = sorted(\n",
    "    glob.glob(os.path.join(resampled_ct_path, \"*_CT*\")))\n",
    "train_images2 = sorted(\n",
    "    glob.glob(os.path.join(resampled_pt_path, \"*_PT*\")))\n",
    "train_labels = sorted(\n",
    "    glob.glob(os.path.join(resampled_label_path, \"*.nii.gz\")))\n",
    "data_dicts = [{\"image\": image_name, \"image2\": pet_image, 'label': label_name}\n",
    "    for image_name, pet_image, label_name in zip(train_images, train_images2, train_labels)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = data_dicts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_a_min = -200\n",
    "ct_a_max = 400\n",
    "pt_a_min = 0\n",
    "pt_a_max = 25\n",
    "crop_samples = 2\n",
    "input_size = [96, 96, 96]\n",
    "modes_2d = ['bilinear', 'bilinear', 'nearest']\n",
    "p = 0.5\n",
    "strength = 1\n",
    "image_keys = [\"image\", \"image2\", \"label\"]\n",
    "val_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\", \"image2\", \"label\"]),\n",
    "    # EnsureChannelFirstd(keys = [\"image\", \"image2\"]),\n",
    "    EnsureChannelFirstd(keys = [\"image\", \"image2\", \"label\"]),\n",
    "    # EnsureTyped(keys=[\"image\", \"image2\", \"label\"]),\n",
    "    # ConvertToMultiChannelBasedOnClassesd(keys='label'),\n",
    "    Orientationd(keys=[\"image\", \"image2\", \"label\"], axcodes=\"RAS\"),\n",
    "    Spacingd(\n",
    "        keys=image_keys,\n",
    "        pixdim=(1, 1, 1),\n",
    "        mode=modes_2d,\n",
    "    ),\n",
    "    ScaleIntensityRanged(keys=['image'], a_min=ct_a_min, a_max=ct_a_max, b_min=0.0, b_max=1.0, clip=True),\n",
    "    ScaleIntensityRanged(keys=['image2'], a_min=pt_a_min, a_max=pt_a_max, b_min=0.0, b_max=1.0, clip=True),\n",
    "    CropForegroundd(keys=image_keys, source_key='image'),\n",
    "    ToTensord(keys=[\"image\", \"image2\", \"label\"])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = CacheDataset(data=test_files, transform=val_transforms, cache_rate=0.0)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_AMP = True\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = SegResNet(\n",
    "    blocks_down=[1, 2, 2, 4],\n",
    "    init_filters=16,\n",
    "    blocks_up=[1, 1, 1],\n",
    "    in_channels = 2,\n",
    "    out_channels= 3,\n",
    "    dropout_prob = 0.2\n",
    ").to(device)\n",
    "\n",
    "# define inference method\n",
    "def inference(input):\n",
    "    def _compute(input):\n",
    "        return sliding_window_inference(\n",
    "            inputs=input,\n",
    "            roi_size=input_size,\n",
    "            sw_batch_size=1,\n",
    "            predictor=model,\n",
    "            overlap=0.5,\n",
    "        )\n",
    "\n",
    "    if VAL_AMP:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            return _compute(input)\n",
    "    else:\n",
    "        return _compute(input)\n",
    "    \n",
    "post_label = AsDiscrete(to_onehot=3)\n",
    "post_pred = AsDiscrete(argmax=True, to_onehot=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_no = 90\n",
    "images = 10\n",
    "model.load_state_dict(torch.load(os.path.join(root_dir, \"best_metric_model.pth\")))\n",
    "model.eval()\n",
    "for image_no in range(images):\n",
    "    with torch.no_grad():\n",
    "        # select one image to evaluate and visualize the model output\n",
    "        val_inputct = test_ds[image_no][\"image\"].unsqueeze(0).to(device)\n",
    "        val_inputpt = test_ds[image_no][\"image2\"].unsqueeze(0).to(device)\n",
    "        val_input = torch.concat([val_inputct, val_inputpt], axis=1)\n",
    "        roi_size = (192, 192, 192)\n",
    "        sw_batch_size = 4\n",
    "        val_output = inference(val_input)\n",
    "        val_output = post_pred(val_output[0])\n",
    "    # plt.figure(\"image\", (6, 6))\n",
    "    # for i in range(1):\n",
    "    #     plt.subplot(1, 1, i + 1)\n",
    "    #     plt.title(f\"image channel {i}\")\n",
    "    #     plt.imshow(test_ds[image_no][\"image\"][i, :, :, slice_no].detach().cpu(), cmap=\"gray\")\n",
    "    # plt.show()\n",
    "    # plt.figure(\"image2\", (6, 6))\n",
    "    # for i in range(1):\n",
    "    #     plt.subplot(1, 1, i + 1)\n",
    "    #     plt.title(f\"image2 channel {i}\")\n",
    "    #     plt.imshow(test_ds[image_no][\"image2\"][i, :, :, slice_no].detach().cpu(), cmap=\"gray\")\n",
    "    # plt.show()\n",
    "    plt.figure(\"label\", (6, 6))\n",
    "    for i in range(1):\n",
    "        plt.subplot(1, 1, i + 1)\n",
    "        plt.title(f\"label channel {i}\")\n",
    "        plt.imshow(test_ds[2][\"label\"][i, :, :, slice_no].detach().cpu())\n",
    "    plt.show()\n",
    "    # visualize the 3 channels model output corresponding to this image\n",
    "    plt.figure(\"output\", (18, 6))\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.title(f\"output channel {i}\")\n",
    "        plt.imshow(val_output[i, :, :, slice_no].detach().cpu())\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
