{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb7414aa-f82c-4627-85f3-fdbb43854925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training of Swin UNETR model.\n",
    "\"\"\"\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "# from torchinfo import summary\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from monai.utils import set_determinism\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.networks.nets import SwinUNETR\n",
    "from monai.data import (\n",
    "    DataLoader,\n",
    "    Dataset,\n",
    "    CacheDataset,\n",
    "    PersistentDataset,\n",
    "    decollate_batch,\n",
    ")\n",
    "\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AddChanneld,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandAffined,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandRotated,\n",
    "    ToTensord,\n",
    ")\n",
    "\n",
    "from misc import copy_file, create_folder_if_not_exists, sort_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2198db-fdf5-446e-bacd-465534a9f24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change working directory\n",
    "root_path = '/data/pg-umcg_mii/'\n",
    "os.chdir(root_path)\n",
    "datetime_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Initialize variables\n",
    "# Data\n",
    "ct_a_min = -200\n",
    "ct_a_max = 400\n",
    "pt_a_min = 0\n",
    "pt_a_max = 25\n",
    "strength = 1  # Data aug strength\n",
    "p = 0.5  # Data aug transforms probability\n",
    "# Training\n",
    "perform_test_run = False\n",
    "n_channels = 2\n",
    "n_classes = 3  # including background\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device:', device)\n",
    "seed = 0  # Seed for reproducibility\n",
    "crop_samples = 2\n",
    "input_size = [96, 96, 96]\n",
    "max_epochs = 200\n",
    "batch_size = 1\n",
    "num_workers = 12\n",
    "pin_memory = True if num_workers > 0 else False  # Do not change \n",
    "optimizer_name = 'adam_w'  # ['adam', 'adam_w', 'rmsprop', 'sgd', 'sgd_w', 'acc_sgd', 'ada_belief', 'ada_bound',\n",
    "# 'ada_hessian', 'apollo', 'diff_grad', 'madgrad', 'novo_grad', 'pid', 'qh_adam', 'qhm', 'r_adam', 'ranger_qh',\n",
    "# 'ranger_21', 'swats', 'yogi'].\n",
    "lr = 1e-4\n",
    "momentum = 0\n",
    "weight_decay = 1e-5\n",
    "T_0 = 40  # Cosine scheduler\n",
    "epoch_early_stopping = max_epochs\n",
    "# Plotting\n",
    "figsize = (18, 12)\n",
    "nr_images = 8\n",
    "\n",
    "# Paths\n",
    "user_path = os.path.join(root_path, 'hung')\n",
    "exp_path = os.path.join(user_path, 'exp')\n",
    "exp_folder = os.path.join(user_path, 'exp', '{}_'.format(datetime_str) + '{}')\n",
    "tb_path = os.path.join(user_path, 'tb')\n",
    "data_path = os.path.join(root_path, 'data/hecktor2022/resampled_larger/')\n",
    "cache_path = os.path.join(user_path, 'cache')\n",
    "folds_path = os.path.join(root_path, 'wei/data/train_folds7.csv')\n",
    "pretrained_path = os.path.join(root_path, 'hung', 'model_swinvit.pt')  # if None: no pretraining\n",
    "best_model_filename = 'best_model.pth'\n",
    "\n",
    "# Create empty folders if they do not exist yet\n",
    "for f in [user_path, exp_path, tb_path, cache_path]:\n",
    "    create_folder_if_not_exists(f)\n",
    "\n",
    "# Variables for test run\n",
    "if perform_test_run:\n",
    "    n_train_testing = 4\n",
    "    n_val_testing = 2\n",
    "    crop_samples = 1\n",
    "    max_epochs = 2\n",
    "    batch_size = 1\n",
    "    pretrained_path = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4573856-bc77-4b90-aaa6-a27f8ac20c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation process\n",
    "def validation(epoch_iterator_val, mode, device):\n",
    "    print('Evaluation on {}.'.format(mode))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(epoch_iterator_val):\n",
    "            val_ct, val_pt, val_label = (batch['ct'].to(device), batch['pt'].to(device), batch['gtv'].to(device))\n",
    "            val_inputs = torch.concat([val_ct, val_pt], axis=1)\n",
    "            \n",
    "            # Note: y_outputs is expected to have binarized predictions and y_label should be in one-hot format\n",
    "            val_outputs = sliding_window_inference(val_inputs, input_size, 4, model)\n",
    "            val_label_list = decollate_batch(val_label)\n",
    "            val_label_convert = [post_label(val_label_tensor) for val_label_tensor in val_label_list]\n",
    "            val_outputs_list = decollate_batch(val_outputs)\n",
    "            val_output_convert = [post_pred(val_pred_tensor) for val_pred_tensor in val_outputs_list]\n",
    "            \n",
    "            # Compute metric          \n",
    "            dice_metric(y_pred=val_output_convert, y=val_label_convert)\n",
    "            epoch_iterator_val.set_description('Validate (%d / %d Steps)' % (epoch, 10.0))\n",
    "            \n",
    "        mean_dice_val = dice_metric.aggregate().item()\n",
    "        dice_metric.reset()\n",
    "    return mean_dice_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df411dcb-a981-4fbf-960e-6d4bf275be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, train_loader, val_loader, scheduler, dice_val_best, epoch_best, writer, nr_images, device):\n",
    "    train_num_iterations = len(train_loader)\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    epoch_iterator = tqdm(train_loader, desc='Training (X / X Steps) (loss=X.X)', dynamic_ncols=True)\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "        step += 1\n",
    "        \n",
    "        ct, pt, y = (batch['ct'].to(device), batch['pt'].to(device), batch['gtv'].to(device))\n",
    "        x = torch.concat([ct, pt], axis=1)\n",
    "        \n",
    "        logit_map = model(x)\n",
    "        loss = loss_function(logit_map, y)\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Scheduler: step() called after every batch update\n",
    "        # scheduler.step(epoch + (i + 1) / train_num_iterations) is specifically for 'cosine' scheduler\n",
    "        # Normally just use `scheduler.step()`\n",
    "        scheduler.step(epoch + (step / train_num_iterations))\n",
    "            \n",
    "        epoch_iterator.set_description('Training (%d / %d Steps) (loss=%2.5f)' % (epoch, max_epochs, loss))\n",
    "    \n",
    "    # Evaluate after completing epoch\n",
    "    # DiceCE loss\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    writer.add_scalar('Loss/train', epoch_loss, epoch)\n",
    "    \n",
    "    # Dice metric\n",
    "    epoch_iterator_2 = tqdm(train_loader, desc='Training (X / X Steps) (loss=X.X)', dynamic_ncols=True)\n",
    "    epoch_iterator_val = tqdm(val_loader, desc='Validate (X / X Steps) (dice=X.X)', dynamic_ncols=True)\n",
    "    dice_train = validation(epoch_iterator_2, 'training data', device)\n",
    "    dice_val = validation(epoch_iterator_val, 'validation data', device)\n",
    "    dice_metric_values.append(dice_val)\n",
    "    writer.add_scalar('Dice/train', dice_train, epoch)\n",
    "    writer.add_scalar('Dice/val', dice_val, epoch)\n",
    "                 \n",
    "    if dice_val > dice_val_best:\n",
    "        dice_val_best = dice_val\n",
    "        epoch_best = epoch\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print('Model saved. Current best avg. Dice: {}. Current avg. Dice: {}.'.format(dice_val_best, dice_val))\n",
    "    else:\n",
    "        print('Model not saved. Current best avg. Dice: {}. Current avg. Dice: {}.'.format(dice_val_best, dice_val))\n",
    "\n",
    "    if (epoch % 10) == 0:\n",
    "        # Check best model output with the input image and label\n",
    "        # model.load_state_dict(torch.load(best_model_path, map_location=torch.device(device)))\n",
    "        # TRAINING\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            batch = next(iter(train_loader))\n",
    "            val_ct, val_pt, val_label = (batch['ct'].to(device), batch['pt'].to(device), batch['gtv'].to(device))\n",
    "            val_inputs = torch.concat([val_ct, val_pt], axis=1)\n",
    "            val_outputs = sliding_window_inference(val_inputs, input_size, 4, model)              \n",
    "                    \n",
    "            # Determine slices to be plotted\n",
    "            # Make sure that nr_images that we want to plot is greater than or equal to the number of slices available\n",
    "            nr_slices = val_inputs.cpu().numpy().shape[-1]\n",
    "            if nr_slices < nr_images:\n",
    "                nr_images = nr_slices\n",
    "            slice_indices = np.linspace(0, nr_slices - 1, num=nr_images)\n",
    "            # Only consider unique values\n",
    "            slice_indices = np.unique(slice_indices.astype(int))\n",
    "            \n",
    "            # Create images\n",
    "            instance = random.randint(0, val_inputs.shape[0] - 1)\n",
    "            for i, idx in enumerate(slice_indices):\n",
    "                j = i+1\n",
    "                plt.figure('Instance = {}'.format(instance), figsize=figsize)\n",
    "                plt.subplot(4, nr_images, j)\n",
    "                plt.title('CT ({})'.format(idx))\n",
    "                plt.imshow(val_inputs.cpu().numpy()[instance, 0, :, :, idx], cmap='gray', vmin=0, vmax=1)\n",
    "                plt.axis('off')\n",
    "                \n",
    "                plt.subplot(4, nr_images, nr_images + j)\n",
    "                plt.title('PET ({})'.format(idx))\n",
    "                plt.imshow(val_inputs.cpu().numpy()[instance, 1, :, :, idx], cmap='hot', vmin=0, vmax=1)\n",
    "                plt.axis('off')\n",
    "                \n",
    "                plt.subplot(4, nr_images, 2*nr_images + j)\n",
    "                plt.title('GTV ({})'.format(idx))\n",
    "                plt.imshow(val_label.cpu().numpy()[instance, 0, :, :, idx])\n",
    "                plt.axis('off')\n",
    "                \n",
    "                plt.subplot(4, nr_images, 3*nr_images + j)\n",
    "                plt.title('Prediction ({})'.format(idx))\n",
    "                plt.imshow(torch.argmax(val_outputs, dim=1).detach().cpu()[instance, :, :, idx])\n",
    "                plt.axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(figures_folder_i, 'output_epoch_{}_train.png'.format(epoch)))\n",
    "            plt.close()\n",
    "            \n",
    "        # Check best model output with the input image and label\n",
    "        # model.load_state_dict(torch.load(best_model_path, map_location=torch.device(device)))\n",
    "        # VALIDATION\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            batch = next(iter(val_loader))\n",
    "            val_ct, val_pt, val_label = (batch['ct'].to(device), batch['pt'].to(device), batch['gtv'].to(device))\n",
    "            val_inputs = torch.concat([val_ct, val_pt], axis=1)\n",
    "            val_outputs = sliding_window_inference(val_inputs, input_size, 4, model)              \n",
    "                    \n",
    "            # Determine slices to be plotted\n",
    "            # Make sure that nr_images that we want to plot is greater than or equal to the number of slices available\n",
    "            nr_slices = val_inputs.cpu().numpy().shape[-1]\n",
    "            if nr_slices < nr_images:\n",
    "                nr_images = nr_slices\n",
    "            slice_indices = np.linspace(0, nr_slices - 1, num=nr_images)\n",
    "            # Only consider unique values\n",
    "            slice_indices = np.unique(slice_indices.astype(int))\n",
    "            \n",
    "            # Create images\n",
    "            instance = random.randint(0, val_inputs.shape[0] - 1)\n",
    "            for i, idx in enumerate(slice_indices):\n",
    "                j = i+1\n",
    "                plt.figure('Instance = {}'.format(instance), figsize=figsize)\n",
    "                plt.subplot(4, nr_images, j)\n",
    "                plt.title('CT ({})'.format(idx))\n",
    "                plt.imshow(val_inputs.cpu().numpy()[instance, 0, :, :, idx], cmap='gray', vmin=0, vmax=1)\n",
    "                plt.axis('off')\n",
    "                \n",
    "                plt.subplot(4, nr_images, nr_images + j)\n",
    "                plt.title('PET ({})'.format(idx))\n",
    "                plt.imshow(val_inputs.cpu().numpy()[instance, 1, :, :, idx], cmap='hot', vmin=0, vmax=1)\n",
    "                plt.axis('off')\n",
    "                \n",
    "                plt.subplot(4, nr_images, 2*nr_images + j)\n",
    "                plt.title('GTV ({})'.format(idx))\n",
    "                plt.imshow(val_label.cpu().numpy()[instance, 0, :, :, idx])\n",
    "                plt.axis('off')\n",
    "                \n",
    "                plt.subplot(4, nr_images, 3*nr_images + j)\n",
    "                plt.title('Prediction ({})'.format(idx))\n",
    "                plt.imshow(torch.argmax(val_outputs, dim=1).detach().cpu()[instance, :, :, idx])\n",
    "                plt.axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(figures_folder_i, 'output_epoch_{}_val.png'.format(epoch)))\n",
    "            plt.close()\n",
    "    \n",
    "    epoch += 1\n",
    "    return epoch, dice_val_best, epoch_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21353b4c-a2f3-4edc-8064-a32bc5edc417",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data transforms\n",
    "image_keys = ['ct', 'pt', 'gtv']  # Do not change\n",
    "modes_3d = ['trilinear', 'trilinear', 'nearest']\n",
    "modes_2d = ['bilinear', 'bilinear', 'nearest']\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=image_keys),\n",
    "        AddChanneld(keys=image_keys),\n",
    "        Orientationd(keys=image_keys, axcodes='RAS'),\n",
    "        Spacingd(\n",
    "            keys=image_keys,\n",
    "            pixdim=(1, 1, 1),\n",
    "            mode=modes_2d,\n",
    "        ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=['ct'],\n",
    "            a_min=ct_a_min,\n",
    "            a_max=ct_a_max,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=['pt'],\n",
    "            a_min=pt_a_min,\n",
    "            a_max=pt_a_max,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=image_keys, source_key='ct'),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=image_keys,\n",
    "            label_key='gtv',\n",
    "            spatial_size=input_size,\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=crop_samples,\n",
    "            image_key='ct',\n",
    "            image_threshold=0,\n",
    "        ),\n",
    "        RandAffined(keys=image_keys, prob=p,\n",
    "                    translate_range=(round(10 * strength), round(10 * strength), round(10 * strength)),\n",
    "                    padding_mode='border', mode=modes_2d),\n",
    "        RandAffined(keys=image_keys, prob=p, scale_range=(0.10 * strength, 0.10 * strength, 0.10 * strength),\n",
    "                    padding_mode='border', mode=modes_2d),\n",
    "        RandFlipd(\n",
    "            keys=image_keys,\n",
    "            spatial_axis=[0],\n",
    "            prob=p / 3,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=image_keys,\n",
    "            spatial_axis=[1],\n",
    "            prob=p / 3,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=image_keys,\n",
    "            spatial_axis=[2],\n",
    "            prob=p / 3,\n",
    "        ),\n",
    "        RandShiftIntensityd(\n",
    "            keys=['ct', 'pt'],\n",
    "            offsets=0.10,\n",
    "            prob=p,\n",
    "        ),\n",
    "        ToTensord(keys=image_keys),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=image_keys),\n",
    "        AddChanneld(keys=image_keys),\n",
    "        Orientationd(keys=image_keys, axcodes='RAS'),\n",
    "        Spacingd(keys=image_keys, pixdim=(1, 1, 1), mode=modes_2d),\n",
    "        ScaleIntensityRanged(keys=['ct'], a_min=ct_a_min, a_max=ct_a_max, b_min=0.0, b_max=1.0, clip=True),\n",
    "        ScaleIntensityRanged(keys=['pt'], a_min=pt_a_min, a_max=pt_a_max, b_min=0.0, b_max=1.0, clip=True),\n",
    "        CropForegroundd(keys=image_keys, source_key='ct'),\n",
    "        ToTensord(keys=image_keys),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67ecfbc-5f2f-48e8-9fda-f445b8305cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# Dataset\n",
    "all_files = sort_human(os.listdir(data_path))\n",
    "patient_ids_ct = [x for x in all_files if 'CT' in x]  # ['HMR-040__CT.nii.gz', 'HMR-041__CT.nii.gz', 'HMR-042__CT.nii.gz', ...]\n",
    "patient_ids_pt = [x.replace('CT', 'PT_nobrain') for x in patient_ids_ct]\n",
    "patient_ids_gtv = [x.replace('CT', 'gtv') for x in patient_ids_ct]\n",
    "patient_ids = [x.replace('__CT.nii.gz', '') for x in patient_ids_ct]  \n",
    "\n",
    "# Train model\n",
    "df_folds = pd.read_csv(folds_path)\n",
    "folds = set(df_folds['fold_center'])\n",
    "\n",
    "# K-Fold cross-validation\n",
    "for k in range(7):\n",
    "    # Set seed\n",
    "    torch.manual_seed(seed=seed)\n",
    "    set_determinism(seed=seed)\n",
    "    random.seed(a=seed)\n",
    "    np.random.seed(seed=seed)\n",
    "\n",
    "    print('Fold: {}'.format(k))\n",
    "    exp_folder_i = exp_folder.format('Fold_{}'.format(k))\n",
    "    figures_folder_i = os.path.join(exp_folder_i, 'figures')\n",
    "    for folder in [exp_folder_i, figures_folder_i]:\n",
    "        create_folder_if_not_exists(folder)\n",
    "    best_model_path = os.path.join(exp_folder_i, best_model_filename)\n",
    "    # Copy files\n",
    "    for filename in ['main.py']:\n",
    "        copy_file(src=os.path.join(user_path, filename), dst=os.path.join(exp_folder_i, filename))\n",
    "\n",
    "    # Training-validation fold\n",
    "    val_ct = [x for x, y in zip(patient_ids_ct, patient_ids) if df_folds[df_folds['ID'] == y]['fold_center'].values[0] == k]\n",
    "    val_pt = [x for x, y in zip(patient_ids_pt, patient_ids) if df_folds[df_folds['ID'] == y]['fold_center'].values[0] == k]\n",
    "    val_gtv = [x for x, y in zip(patient_ids_gtv, patient_ids) if df_folds[df_folds['ID'] == y]['fold_center'].values[0] == k]\n",
    "\n",
    "    train_ct = [x for x in patient_ids_ct if x not in val_ct]\n",
    "    train_pt = [x for x in patient_ids_pt if x not in val_pt]\n",
    "    train_gtv = [x for x in patient_ids_gtv if x not in val_gtv]\n",
    "\n",
    "    assert len(train_ct) == len(train_pt) == len(train_gtv)\n",
    "    assert len(val_ct) == len(val_pt) == len(val_gtv)\n",
    "\n",
    "    if perform_test_run:\n",
    "        train_ct = patient_ids_ct[:n_train_testing]\n",
    "        train_pt = patient_ids_pt[:n_train_testing]\n",
    "        train_gtv = patient_ids_gtv[:n_train_testing]\n",
    "\n",
    "        val_ct = patient_ids_ct[-n_val_testing:]\n",
    "        val_pt = patient_ids_pt[-n_val_testing:]\n",
    "        val_gtv = patient_ids_gtv[-n_val_testing:]\n",
    "\n",
    "    # Initialize DataLoader\n",
    "    train_dict = [{'ct': os.path.join(data_path, ct), 'pt': os.path.join(data_path, pt), 'gtv': os.path.join(data_path, gtv)} for ct, pt, gtv in zip(train_ct, train_pt, train_gtv)]\n",
    "    train_ds = CacheDataset(data=train_dict, transform=train_transforms, cache_rate=1.0, num_workers=num_workers)\n",
    "    # train_ds = PersistentDataset(data=train_dict, transform=train_transforms, cache_dir=cache_path)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "    val_dict = [{'ct': os.path.join(data_path, ct), 'pt': os.path.join(data_path, pt), 'gtv': os.path.join(data_path, gtv)} for ct, pt, gtv in zip(val_ct, val_pt, val_gtv)]\n",
    "    val_ds = CacheDataset(data=val_dict, transform=val_transforms, cache_rate=1.0, num_workers=int(num_workers//2))\n",
    "    # val_ds = PersistentDataset(data=val_dict, transform=val_transforms, cache_dir=cache_path)\n",
    "    val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=int(num_workers//2), pin_memory=pin_memory)\n",
    "\n",
    "    # Initialize  model\n",
    "    model = SwinUNETR(\n",
    "        img_size=input_size,\n",
    "        in_channels=n_channels,\n",
    "        out_channels=n_classes,\n",
    "        feature_size=48,\n",
    "        use_checkpoint=True,\n",
    "    ).to(device)\n",
    "\n",
    "    summary(model=model, input_size=[1, n_channels] + input_size, device=device)\n",
    "\n",
    "    # Load pretrained model\n",
    "    if pretrained_path is not None:\n",
    "        weight = torch.load(pretrained_path, map_location=torch.device(device))\n",
    "        model.load_from(weights=weight)\n",
    "        print('Using pretrained weights!')\n",
    "\n",
    "    # Optimizer and loss function\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    loss_function = DiceCELoss(include_background=False, to_onehot_y=True, softmax=True)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=T_0,\n",
    "                                                                     T_mult=1, eta_min=1e-8)\n",
    "\n",
    "    # Initalize classes\n",
    "    writer = SummaryWriter(os.path.join(tb_path, '{}_'.format(datetime_str) + 'fold_{}'.format(k)))\n",
    "    # Note: y_outputs/y_preds is expected to have binarized predictions and y_label should be in one-hot format\n",
    "    post_label = AsDiscrete(to_onehot=n_classes)\n",
    "    post_pred = AsDiscrete(argmax=True, to_onehot=n_classes)\n",
    "    dice_metric = DiceMetric(include_background=False, reduction='mean', get_not_nans=False)\n",
    "\n",
    "    epoch = 0\n",
    "    dice_val_best = 0.0\n",
    "    epoch_best = 0\n",
    "    epoch_loss_values = []\n",
    "    dice_metric_values = []\n",
    "    while (epoch < max_epochs) and (epoch - epoch_best <= epoch_early_stopping):\n",
    "        epoch, dice_val_best, epoch_best = train(\n",
    "            epoch, train_loader, val_loader, scheduler, dice_val_best, epoch_best, writer, nr_images, device\n",
    "        )\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=torch.device(device)))\n",
    "\n",
    "    print(\n",
    "        f'Train completed, best_metric: {dice_val_best:.4f} '\n",
    "        f'at iteration: {epoch_best}'\n",
    "    )\n",
    "\n",
    "    # Close Tensorboard writer\n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
