/WAVE/users/unix/smalladi/.conda/envs/venv/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/WAVE/users/unix/smalladi/.conda/envs/venv/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda20CUDACachingAllocator9allocatorE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/WAVE/users/unix/smalladi/.local/lib/python3.9/site-packages/monai/transforms/utils.py:509: UserWarning: Num foregrounds 0, Num backgrounds 3326877, unable to generate class balanced samples, setting `pos_ratio` to 0.
  warnings.warn(
/WAVE/users/unix/smalladi/.local/lib/python3.9/site-packages/monai/transforms/utils.py:509: UserWarning: Num foregrounds 0, Num backgrounds 7077888, unable to generate class balanced samples, setting `pos_ratio` to 0.
  warnings.warn(
----------
Epoch 1/50
1/200, train_loss: 3.5863
2/200, train_loss: 2.4894
3/200, train_loss: 1.9697
4/200, train_loss: 1.6974
5/200, train_loss: 1.7153
6/200, train_loss: 1.6358
7/200, train_loss: 1.6371
8/200, train_loss: 1.3138
9/200, train_loss: 1.3281
10/200, train_loss: 1.4106
11/200, train_loss: 1.3547
12/200, train_loss: 1.6653
13/200, train_loss: 1.4288
14/200, train_loss: 1.5242
15/200, train_loss: 1.5874
16/200, train_loss: 1.3445
17/200, train_loss: 1.6292
18/200, train_loss: 1.3887
19/200, train_loss: 1.4911
20/200, train_loss: 1.3612
21/200, train_loss: 1.2586
22/200, train_loss: 1.5184
23/200, train_loss: 1.2916
24/200, train_loss: 1.1752
25/200, train_loss: 1.3763
26/200, train_loss: 1.7000
27/200, train_loss: 1.2324
28/200, train_loss: 1.1970
29/200, train_loss: 1.4264
30/200, train_loss: 1.2311
31/200, train_loss: 1.2577
32/200, train_loss: 1.2701
33/200, train_loss: 1.2871
34/200, train_loss: 1.1997
35/200, train_loss: 1.2689
36/200, train_loss: 1.3441
37/200, train_loss: 1.1888
38/200, train_loss: 1.2889
39/200, train_loss: 1.1874
40/200, train_loss: 1.3814
41/200, train_loss: 1.1209
42/200, train_loss: 1.1680
43/200, train_loss: 1.2500
44/200, train_loss: 1.1657
45/200, train_loss: 1.1875
46/200, train_loss: 1.1109
47/200, train_loss: 1.2899
48/200, train_loss: 1.1982
49/200, train_loss: 1.1299
50/200, train_loss: 1.1730
51/200, train_loss: 1.1823
52/200, train_loss: 1.1761
53/200, train_loss: 1.3036
54/200, train_loss: 1.1904
55/200, train_loss: 1.1539
56/200, train_loss: 1.1570
57/200, train_loss: 1.2781
58/200, train_loss: 1.2404
59/200, train_loss: 1.3207
60/200, train_loss: 1.2546
61/200, train_loss: 1.1859
62/200, train_loss: 1.2200
63/200, train_loss: 1.1933
64/200, train_loss: 1.1540
65/200, train_loss: 1.1291
66/200, train_loss: 1.3375
67/200, train_loss: 1.1959
68/200, train_loss: 1.1279
69/200, train_loss: 1.1962
70/200, train_loss: 1.2766
71/200, train_loss: 1.2699
72/200, train_loss: 1.1930
73/200, train_loss: 1.0743
74/200, train_loss: 1.1812
75/200, train_loss: 1.1255
76/200, train_loss: 1.2141
77/200, train_loss: 1.2435
78/200, train_loss: 1.2516
79/200, train_loss: 1.2211
80/200, train_loss: 1.2188
81/200, train_loss: 1.1499
82/200, train_loss: 1.2034
83/200, train_loss: 1.2288
84/200, train_loss: 1.0819
85/200, train_loss: 1.1391
86/200, train_loss: 1.1943
87/200, train_loss: 1.2410
88/200, train_loss: 1.1405
89/200, train_loss: 1.3351
90/200, train_loss: 1.3090
91/200, train_loss: 1.1764
92/200, train_loss: 1.0419
93/200, train_loss: 1.1070
94/200, train_loss: 1.1837
95/200, train_loss: 1.0799
96/200, train_loss: 1.3033
97/200, train_loss: 1.2570
98/200, train_loss: 1.1427
99/200, train_loss: 1.0471
100/200, train_loss: 1.1018
101/200, train_loss: 1.0698
102/200, train_loss: 1.2310
103/200, train_loss: 1.2719
104/200, train_loss: 1.1194
105/200, train_loss: 1.0909
106/200, train_loss: 1.0275
107/200, train_loss: 1.0156
108/200, train_loss: 1.1244
109/200, train_loss: 1.0887
110/200, train_loss: 1.1885
111/200, train_loss: 1.1160
112/200, train_loss: 1.2382
113/200, train_loss: 1.6403
114/200, train_loss: 1.1625
115/200, train_loss: 1.1281
116/200, train_loss: 1.2764
117/200, train_loss: 1.1591
118/200, train_loss: 0.9829
119/200, train_loss: 1.1402
120/200, train_loss: 1.0330
121/200, train_loss: 1.1630
122/200, train_loss: 1.0917
123/200, train_loss: 1.0653
124/200, train_loss: 1.1907
125/200, train_loss: 1.1851
126/200, train_loss: 1.0893
127/200, train_loss: 1.5547
128/200, train_loss: 1.1910
129/200, train_loss: 1.3365
130/200, train_loss: 1.1654
131/200, train_loss: 1.1161
132/200, train_loss: 1.2325
133/200, train_loss: 1.3131
134/200, train_loss: 1.0326
135/200, train_loss: 1.1474
136/200, train_loss: 1.1168
137/200, train_loss: 1.3273
138/200, train_loss: 1.1374
139/200, train_loss: 1.1403
140/200, train_loss: 1.0549
141/200, train_loss: 1.1212
142/200, train_loss: 1.1963
143/200, train_loss: 1.1899
144/200, train_loss: 0.9746
145/200, train_loss: 1.1969
146/200, train_loss: 1.3852
147/200, train_loss: 1.2904
148/200, train_loss: 1.2765
149/200, train_loss: 1.2289
150/200, train_loss: 1.2931
151/200, train_loss: 1.1633
152/200, train_loss: 1.3823
153/200, train_loss: 1.2066
154/200, train_loss: 1.0561
155/200, train_loss: 1.1481
156/200, train_loss: 1.2463
157/200, train_loss: 1.2432
158/200, train_loss: 1.1218
159/200, train_loss: 1.2605
160/200, train_loss: 1.1457
161/200, train_loss: 1.1481
162/200, train_loss: 1.1218
163/200, train_loss: 1.3337
164/200, train_loss: 1.2210
165/200, train_loss: 1.1764
166/200, train_loss: 1.2215
167/200, train_loss: 1.2305
168/200, train_loss: 1.2693
169/200, train_loss: 1.2367
170/200, train_loss: 1.0588
171/200, train_loss: 1.1153
172/200, train_loss: 1.2007
173/200, train_loss: 1.2088
174/200, train_loss: 1.1265
175/200, train_loss: 1.0905
176/200, train_loss: 1.1663
177/200, train_loss: 1.1660
178/200, train_loss: 1.0813
179/200, train_loss: 1.2034
180/200, train_loss: 1.1539
181/200, train_loss: 1.1816
182/200, train_loss: 1.2744
183/200, train_loss: 1.1342
184/200, train_loss: 1.1556
185/200, train_loss: 1.1235
186/200, train_loss: 1.1698
187/200, train_loss: 1.1497
188/200, train_loss: 1.1544
189/200, train_loss: 1.1130
190/200, train_loss: 1.1983
191/200, train_loss: 1.2049
192/200, train_loss: 1.1429
193/200, train_loss: 1.1927
194/200, train_loss: 1.2348
195/200, train_loss: 1.2728
196/200, train_loss: 1.1662
197/200, train_loss: 1.1796
198/200, train_loss: 1.2441
199/200, train_loss: 1.1621
200/200, train_loss: 1.1106
epoch 1 average loss: 1.2457
saved new best metric model
current epoch: 1 current mean dice: 0.2555 1: 0.3123 2: 0.1959
best mean dice: 0.2555 at epoch: 1
Epoch 1 completed
time consuming of epoch 1 is: 650.8523
----------
Epoch 2/50
1/200, train_loss: 1.0070
2/200, train_loss: 1.0680
3/200, train_loss: 1.2309
4/200, train_loss: 1.1553
5/200, train_loss: 1.1296
6/200, train_loss: 1.2185
7/200, train_loss: 1.2628
8/200, train_loss: 1.1342
9/200, train_loss: 1.2193
10/200, train_loss: 1.1044
11/200, train_loss: 1.1438
12/200, train_loss: 1.0089
13/200, train_loss: 1.1085
14/200, train_loss: 1.0174
15/200, train_loss: 1.0363
16/200, train_loss: 1.2468
17/200, train_loss: 1.3741
18/200, train_loss: 1.0127
19/200, train_loss: 1.2068
20/200, train_loss: 1.0252
21/200, train_loss: 1.1371
22/200, train_loss: 1.4852
23/200, train_loss: 1.1868
24/200, train_loss: 1.1977
25/200, train_loss: 1.1201
26/200, train_loss: 1.1906
27/200, train_loss: 1.2240
28/200, train_loss: 1.0785
29/200, train_loss: 1.0209
30/200, train_loss: 1.0958
31/200, train_loss: 1.1493
32/200, train_loss: 1.1020
33/200, train_loss: 1.0884
34/200, train_loss: 1.3880
35/200, train_loss: 1.1929
36/200, train_loss: 1.0784
37/200, train_loss: 1.1959
38/200, train_loss: 1.0582
39/200, train_loss: 0.9402
40/200, train_loss: 1.1536
41/200, train_loss: 1.1662
42/200, train_loss: 1.1285
43/200, train_loss: 1.1453
44/200, train_loss: 1.1947
45/200, train_loss: 1.1245
46/200, train_loss: 1.1549
47/200, train_loss: 1.0249
48/200, train_loss: 1.3362
49/200, train_loss: 1.1471
50/200, train_loss: 1.5193
51/200, train_loss: 1.1991
52/200, train_loss: 1.1713
53/200, train_loss: 1.1360
54/200, train_loss: 1.0867
55/200, train_loss: 0.9861
56/200, train_loss: 1.0210
57/200, train_loss: 1.1468
58/200, train_loss: 1.1611
59/200, train_loss: 1.1140
60/200, train_loss: 1.1496
61/200, train_loss: 1.1361
62/200, train_loss: 1.2161
63/200, train_loss: 1.1529
64/200, train_loss: 1.2783
65/200, train_loss: 1.4246
66/200, train_loss: 1.3417
67/200, train_loss: 1.2963
68/200, train_loss: 1.0786
69/200, train_loss: 1.0922
70/200, train_loss: 1.2263
71/200, train_loss: 1.1096
72/200, train_loss: 1.1270
73/200, train_loss: 1.1574
74/200, train_loss: 1.1876
75/200, train_loss: 1.1805
76/200, train_loss: 1.1748
77/200, train_loss: 1.0879
78/200, train_loss: 1.1550
79/200, train_loss: 1.1557
80/200, train_loss: 1.1655
81/200, train_loss: 1.1700
82/200, train_loss: 1.3006
83/200, train_loss: 1.2251
84/200, train_loss: 1.4610
85/200, train_loss: 0.9256
86/200, train_loss: 1.1380
87/200, train_loss: 1.1006
88/200, train_loss: 1.2230
89/200, train_loss: 1.1474
90/200, train_loss: 1.1946
91/200, train_loss: 1.0942
92/200, train_loss: 1.0609
93/200, train_loss: 1.1260
94/200, train_loss: 1.1474
95/200, train_loss: 1.0847
96/200, train_loss: 1.2377
97/200, train_loss: 1.0254
98/200, train_loss: 1.2295
99/200, train_loss: 1.1591
100/200, train_loss: 1.2449
101/200, train_loss: 1.1240
102/200, train_loss: 1.1875
103/200, train_loss: 1.0749
104/200, train_loss: 1.0322
105/200, train_loss: 1.1130
106/200, train_loss: 1.0440
107/200, train_loss: 1.1674
108/200, train_loss: 1.0455
109/200, train_loss: 1.0821
110/200, train_loss: 1.1077
111/200, train_loss: 1.1416
112/200, train_loss: 0.9219
113/200, train_loss: 1.1483
114/200, train_loss: 1.0233
115/200, train_loss: 1.1221
116/200, train_loss: 1.4919
117/200, train_loss: 1.1877
118/200, train_loss: 1.1541
119/200, train_loss: 1.1454
120/200, train_loss: 1.0636
121/200, train_loss: 1.2237
122/200, train_loss: 1.2463
123/200, train_loss: 1.2020
124/200, train_loss: 1.2333
125/200, train_loss: 1.2954
126/200, train_loss: 1.1467
127/200, train_loss: 1.0725
128/200, train_loss: 1.2179
129/200, train_loss: 1.1447
130/200, train_loss: 1.0012
131/200, train_loss: 1.1415
132/200, train_loss: 1.2530
133/200, train_loss: 1.1211
134/200, train_loss: 1.0658
135/200, train_loss: 1.1329
136/200, train_loss: 0.9941
137/200, train_loss: 1.2081
138/200, train_loss: 1.0362
139/200, train_loss: 1.1616
140/200, train_loss: 1.0267
141/200, train_loss: 1.1388
142/200, train_loss: 1.1222
143/200, train_loss: 1.1755
144/200, train_loss: 1.0086
145/200, train_loss: 1.3787
146/200, train_loss: 1.0150
147/200, train_loss: 1.1212
148/200, train_loss: 0.8973
149/200, train_loss: 1.0169
150/200, train_loss: 1.1442
151/200, train_loss: 1.0377
152/200, train_loss: 1.0780
153/200, train_loss: 1.0683
154/200, train_loss: 1.2093
155/200, train_loss: 1.4158
156/200, train_loss: 1.2749
157/200, train_loss: 1.1231
158/200, train_loss: 1.1022
159/200, train_loss: 1.0925
160/200, train_loss: 1.1374
161/200, train_loss: 1.1220
162/200, train_loss: 1.1768
163/200, train_loss: 1.0394
164/200, train_loss: 1.3422
165/200, train_loss: 1.1085
166/200, train_loss: 1.0598
167/200, train_loss: 1.1399
168/200, train_loss: 1.0720
169/200, train_loss: 1.0382
170/200, train_loss: 0.9859
171/200, train_loss: 1.0817
172/200, train_loss: 0.9795
173/200, train_loss: 1.0005
174/200, train_loss: 1.0711
175/200, train_loss: 1.0805
176/200, train_loss: 1.1095
177/200, train_loss: 1.1556
178/200, train_loss: 1.0983
179/200, train_loss: 1.2041
180/200, train_loss: 1.1336
181/200, train_loss: 1.1143
182/200, train_loss: 1.0220
183/200, train_loss: 1.1198
184/200, train_loss: 1.1706
185/200, train_loss: 0.9696
186/200, train_loss: 1.2469
187/200, train_loss: 1.1585
188/200, train_loss: 1.0490
189/200, train_loss: 1.1446
190/200, train_loss: 1.1169
191/200, train_loss: 1.1241
192/200, train_loss: 1.0962
193/200, train_loss: 1.0266
194/200, train_loss: 1.2478
195/200, train_loss: 1.0352
196/200, train_loss: 1.2253
197/200, train_loss: 1.2498
198/200, train_loss: 1.1064
199/200, train_loss: 1.1461
200/200, train_loss: 1.1193
epoch 2 average loss: 1.1415
saved new best metric model
current epoch: 2 current mean dice: 0.3209 1: 0.3259 2: 0.3116
best mean dice: 0.3209 at epoch: 2
Epoch 2 completed
time consuming of epoch 2 is: 614.3454
----------
Epoch 3/50
1/200, train_loss: 1.1173
2/200, train_loss: 1.0783
3/200, train_loss: 1.1751
4/200, train_loss: 1.1023
5/200, train_loss: 1.0645
6/200, train_loss: 1.2677
7/200, train_loss: 1.1060
8/200, train_loss: 1.0431
9/200, train_loss: 1.0732
10/200, train_loss: 1.2184
11/200, train_loss: 1.1804
12/200, train_loss: 1.1480
13/200, train_loss: 1.0702
14/200, train_loss: 1.2655
15/200, train_loss: 1.3605
16/200, train_loss: 0.9491
17/200, train_loss: 1.0039
18/200, train_loss: 1.1217
19/200, train_loss: 1.0741
20/200, train_loss: 1.1965
21/200, train_loss: 1.1301
22/200, train_loss: 1.1057
23/200, train_loss: 1.1477
24/200, train_loss: 1.1882
25/200, train_loss: 1.1824
26/200, train_loss: 1.1878
27/200, train_loss: 1.1358
28/200, train_loss: 1.1858
29/200, train_loss: 1.0660
30/200, train_loss: 1.1440
31/200, train_loss: 1.1241
32/200, train_loss: 1.1446
33/200, train_loss: 1.1100
34/200, train_loss: 1.0111
35/200, train_loss: 1.1874
36/200, train_loss: 1.2655
37/200, train_loss: 1.1225
38/200, train_loss: 1.0825
39/200, train_loss: 1.1577
40/200, train_loss: 1.1515
41/200, train_loss: 1.3410
42/200, train_loss: 1.1641
43/200, train_loss: 1.0495
44/200, train_loss: 1.3363
45/200, train_loss: 1.1872
46/200, train_loss: 1.3130
47/200, train_loss: 1.0202
48/200, train_loss: 1.0676
49/200, train_loss: 0.9698
50/200, train_loss: 1.4273
51/200, train_loss: 1.1285
52/200, train_loss: 1.1063
53/200, train_loss: 1.1191
54/200, train_loss: 1.0529
55/200, train_loss: 1.3856
56/200, train_loss: 1.0505
57/200, train_loss: 1.3144
58/200, train_loss: 1.1269
59/200, train_loss: 1.2560
60/200, train_loss: 1.2466
61/200, train_loss: 1.1623
62/200, train_loss: 1.2085
63/200, train_loss: 1.0676
64/200, train_loss: 1.1241
65/200, train_loss: 1.0737
66/200, train_loss: 1.1284
67/200, train_loss: 1.2086
68/200, train_loss: 1.1835
69/200, train_loss: 1.0893
70/200, train_loss: 1.0656
71/200, train_loss: 1.1324
72/200, train_loss: 1.0287
73/200, train_loss: 1.1377
74/200, train_loss: 0.9979
75/200, train_loss: 1.1143
76/200, train_loss: 1.1240
77/200, train_loss: 1.0889
78/200, train_loss: 1.1375
79/200, train_loss: 1.0548
80/200, train_loss: 1.0305
81/200, train_loss: 1.0688
82/200, train_loss: 0.9371
83/200, train_loss: 1.0659
84/200, train_loss: 1.1803
85/200, train_loss: 1.1303
86/200, train_loss: 1.0796
87/200, train_loss: 1.0192
88/200, train_loss: 1.0081
89/200, train_loss: 0.9024
90/200, train_loss: 1.0271
91/200, train_loss: 1.1016
92/200, train_loss: 1.1343
93/200, train_loss: 1.0984
94/200, train_loss: 1.1128
95/200, train_loss: 1.3168
96/200, train_loss: 1.1315
97/200, train_loss: 1.1028
98/200, train_loss: 1.2293
99/200, train_loss: 1.0536
100/200, train_loss: 1.0767
101/200, train_loss: 1.5175
102/200, train_loss: 1.0607
103/200, train_loss: 1.1038
104/200, train_loss: 1.0065
105/200, train_loss: 1.1345
106/200, train_loss: 1.1755
107/200, train_loss: 1.1853
108/200, train_loss: 0.9866
109/200, train_loss: 1.1220
110/200, train_loss: 1.2851
111/200, train_loss: 1.0049
112/200, train_loss: 1.0708
113/200, train_loss: 1.1920
114/200, train_loss: 1.0244
115/200, train_loss: 1.1478
116/200, train_loss: 0.9764
117/200, train_loss: 1.0001
118/200, train_loss: 1.0274
119/200, train_loss: 1.1187
120/200, train_loss: 1.0953
121/200, train_loss: 1.2032
122/200, train_loss: 1.0473
123/200, train_loss: 1.2537
124/200, train_loss: 1.0695
125/200, train_loss: 1.0817
126/200, train_loss: 1.0115
127/200, train_loss: 1.0353
128/200, train_loss: 1.1997
129/200, train_loss: 1.1156
130/200, train_loss: 1.2094
131/200, train_loss: 1.0966
132/200, train_loss: 1.3164
133/200, train_loss: 0.9896
134/200, train_loss: 1.1304
135/200, train_loss: 1.0467
136/200, train_loss: 1.0103
137/200, train_loss: 1.0766
138/200, train_loss: 1.1334
139/200, train_loss: 1.1842
140/200, train_loss: 1.0099
141/200, train_loss: 1.0929
142/200, train_loss: 1.0628
143/200, train_loss: 1.1035
144/200, train_loss: 0.8448
145/200, train_loss: 1.1092
146/200, train_loss: 1.0866
147/200, train_loss: 1.1832
148/200, train_loss: 1.0655
149/200, train_loss: 1.0173
150/200, train_loss: 1.1133
151/200, train_loss: 1.1577
152/200, train_loss: 1.2385
153/200, train_loss: 0.9833
154/200, train_loss: 1.2685
155/200, train_loss: 1.0275
156/200, train_loss: 1.0525
157/200, train_loss: 1.1879
158/200, train_loss: 1.1663
159/200, train_loss: 1.0783
160/200, train_loss: 1.1245
161/200, train_loss: 1.1068
162/200, train_loss: 1.1023
163/200, train_loss: 1.0983
164/200, train_loss: 1.0207
165/200, train_loss: 0.9837
166/200, train_loss: 1.1643
167/200, train_loss: 1.1320
168/200, train_loss: 1.1317
169/200, train_loss: 1.2894
170/200, train_loss: 1.4026
171/200, train_loss: 1.1218
172/200, train_loss: 1.1062
173/200, train_loss: 1.1050
174/200, train_loss: 1.0099
175/200, train_loss: 1.1891
176/200, train_loss: 1.1633
177/200, train_loss: 0.9676
178/200, train_loss: 1.1126
179/200, train_loss: 1.1122
180/200, train_loss: 1.0253
181/200, train_loss: 1.2996
182/200, train_loss: 1.0697
183/200, train_loss: 0.9621
184/200, train_loss: 1.0473
185/200, train_loss: 1.0865
186/200, train_loss: 1.0672
187/200, train_loss: 1.0696
188/200, train_loss: 1.0402
189/200, train_loss: 0.9985
190/200, train_loss: 1.1735
191/200, train_loss: 1.1502
192/200, train_loss: 1.0021
193/200, train_loss: 1.0846
194/200, train_loss: 1.0652
195/200, train_loss: 1.0422
196/200, train_loss: 1.0160
197/200, train_loss: 0.9840
198/200, train_loss: 1.4536
199/200, train_loss: 0.9251
200/200, train_loss: 1.1202
epoch 3 average loss: 1.1173
current epoch: 3 current mean dice: 0.3023 1: 0.2074 2: 0.4086
best mean dice: 0.3209 at epoch: 2
Epoch 3 completed
time consuming of epoch 3 is: 595.1343
----------
Epoch 4/50
1/200, train_loss: 0.9764
2/200, train_loss: 1.2885
3/200, train_loss: 1.2839
4/200, train_loss: 1.0653
5/200, train_loss: 1.1190
6/200, train_loss: 0.9498
7/200, train_loss: 0.9848
8/200, train_loss: 1.0100
9/200, train_loss: 1.2404
10/200, train_loss: 0.9945
11/200, train_loss: 1.5845
12/200, train_loss: 1.0649
13/200, train_loss: 1.0913
14/200, train_loss: 1.0756
15/200, train_loss: 1.2383
16/200, train_loss: 1.1804
17/200, train_loss: 1.0985
18/200, train_loss: 1.0065
19/200, train_loss: 1.1075
20/200, train_loss: 1.1258
21/200, train_loss: 1.4808
22/200, train_loss: 1.0826
23/200, train_loss: 1.0463
24/200, train_loss: 1.0522
25/200, train_loss: 0.9795
26/200, train_loss: 1.1219
27/200, train_loss: 1.2188
28/200, train_loss: 1.1136
29/200, train_loss: 1.0235
30/200, train_loss: 1.0770
31/200, train_loss: 1.1804
32/200, train_loss: 0.9390
33/200, train_loss: 1.4385
34/200, train_loss: 1.1342
35/200, train_loss: 1.2244
36/200, train_loss: 1.1436
37/200, train_loss: 1.0974
38/200, train_loss: 1.0664
39/200, train_loss: 1.0209
40/200, train_loss: 1.1374
41/200, train_loss: 0.9531
42/200, train_loss: 1.0286
43/200, train_loss: 0.9865
44/200, train_loss: 0.8960
45/200, train_loss: 1.0936
46/200, train_loss: 1.0316
47/200, train_loss: 1.1116
48/200, train_loss: 1.0446
49/200, train_loss: 1.0696
50/200, train_loss: 1.0619
51/200, train_loss: 0.9867
52/200, train_loss: 1.0481
53/200, train_loss: 1.0216
54/200, train_loss: 1.0465
55/200, train_loss: 0.9798
56/200, train_loss: 0.9807
57/200, train_loss: 1.1429
58/200, train_loss: 1.0575
59/200, train_loss: 0.9567
60/200, train_loss: 1.1256
61/200, train_loss: 1.1234
62/200, train_loss: 0.9735
63/200, train_loss: 1.0377
64/200, train_loss: 0.9951
65/200, train_loss: 0.9448
66/200, train_loss: 1.0241
67/200, train_loss: 1.0498
68/200, train_loss: 0.9653
69/200, train_loss: 1.0961
70/200, train_loss: 0.9997
71/200, train_loss: 0.9669
72/200, train_loss: 1.0675
73/200, train_loss: 1.1850
74/200, train_loss: 1.1342
75/200, train_loss: 0.9317
76/200, train_loss: 1.0607
77/200, train_loss: 1.0262
78/200, train_loss: 0.9101
79/200, train_loss: 0.8912
80/200, train_loss: 1.1268
81/200, train_loss: 1.1315
82/200, train_loss: 1.0203
83/200, train_loss: 1.0561
84/200, train_loss: 1.1532
85/200, train_loss: 1.0392
86/200, train_loss: 1.0692
87/200, train_loss: 1.0885
88/200, train_loss: 1.0104
89/200, train_loss: 0.9951
90/200, train_loss: 0.9895
91/200, train_loss: 1.2572
92/200, train_loss: 1.1348
93/200, train_loss: 1.0950
94/200, train_loss: 1.1232
95/200, train_loss: 0.9645
96/200, train_loss: 1.1923
97/200, train_loss: 1.3100
98/200, train_loss: 0.9364
99/200, train_loss: 1.0718
100/200, train_loss: 1.1630
101/200, train_loss: 1.3473
102/200, train_loss: 1.1707
103/200, train_loss: 1.1370
104/200, train_loss: 0.9614
105/200, train_loss: 0.9243
106/200, train_loss: 1.2094
107/200, train_loss: 0.9849
108/200, train_loss: 1.1397
109/200, train_loss: 0.8979
110/200, train_loss: 1.1340
111/200, train_loss: 0.9589
112/200, train_loss: 1.0692
113/200, train_loss: 1.0390
114/200, train_loss: 0.9311
115/200, train_loss: 1.1347
116/200, train_loss: 0.9062
117/200, train_loss: 0.9288
118/200, train_loss: 1.1864
119/200, train_loss: 1.0626
120/200, train_loss: 1.0720
121/200, train_loss: 1.0395
122/200, train_loss: 1.1778
123/200, train_loss: 1.2136
124/200, train_loss: 1.1431
125/200, train_loss: 1.0142
126/200, train_loss: 1.0326
127/200, train_loss: 1.0864
128/200, train_loss: 1.1226
129/200, train_loss: 1.2819
130/200, train_loss: 1.0532
131/200, train_loss: 1.2117
132/200, train_loss: 1.0962
133/200, train_loss: 1.0096
134/200, train_loss: 0.9639
135/200, train_loss: 1.0449
136/200, train_loss: 1.0336
137/200, train_loss: 0.8730
138/200, train_loss: 0.9507
139/200, train_loss: 1.2511
140/200, train_loss: 0.9841
141/200, train_loss: 0.9835
142/200, train_loss: 1.0198
143/200, train_loss: 1.2044
144/200, train_loss: 1.0559
145/200, train_loss: 1.0516
146/200, train_loss: 1.0711
147/200, train_loss: 0.9075
148/200, train_loss: 1.1530
149/200, train_loss: 1.1111
150/200, train_loss: 0.9614
151/200, train_loss: 1.0166
152/200, train_loss: 1.2244
153/200, train_loss: 1.1464
154/200, train_loss: 0.9634
155/200, train_loss: 0.9916
156/200, train_loss: 1.2780
157/200, train_loss: 0.9946
158/200, train_loss: 0.9608
159/200, train_loss: 0.9472
160/200, train_loss: 0.9802
161/200, train_loss: 1.1638
162/200, train_loss: 1.2458
163/200, train_loss: 1.0718
164/200, train_loss: 1.0593
165/200, train_loss: 1.1307
166/200, train_loss: 1.2750
167/200, train_loss: 1.0908
168/200, train_loss: 1.0990
169/200, train_loss: 1.0911
170/200, train_loss: 1.0381
171/200, train_loss: 1.0792
172/200, train_loss: 1.0845
173/200, train_loss: 1.2420
174/200, train_loss: 0.9811
175/200, train_loss: 1.3067
176/200, train_loss: 1.0293
177/200, train_loss: 1.0477
178/200, train_loss: 1.0571
179/200, train_loss: 0.9367
180/200, train_loss: 1.2738
181/200, train_loss: 1.1027
182/200, train_loss: 1.0895
183/200, train_loss: 1.0056
184/200, train_loss: 0.9383
185/200, train_loss: 1.1444
186/200, train_loss: 1.0761
187/200, train_loss: 1.0810
188/200, train_loss: 1.0885
189/200, train_loss: 1.0533
190/200, train_loss: 0.9142
191/200, train_loss: 1.2751
192/200, train_loss: 1.0980
193/200, train_loss: 1.0384
194/200, train_loss: 0.9146
195/200, train_loss: 1.2383
196/200, train_loss: 1.0358
197/200, train_loss: 1.0335
198/200, train_loss: 0.9326
199/200, train_loss: 0.9747
200/200, train_loss: 0.9817
epoch 4 average loss: 1.0756
saved new best metric model
current epoch: 4 current mean dice: 0.3315 1: 0.3406 2: 0.3218
best mean dice: 0.3315 at epoch: 4
Epoch 4 completed
time consuming of epoch 4 is: 612.4842
----------
Epoch 5/50
1/200, train_loss: 0.9556
2/200, train_loss: 1.0620
3/200, train_loss: 0.9636
4/200, train_loss: 1.1534
5/200, train_loss: 1.1223
6/200, train_loss: 1.1719
7/200, train_loss: 1.0887
8/200, train_loss: 1.1085
9/200, train_loss: 1.0939
10/200, train_loss: 1.0487
11/200, train_loss: 1.0209
12/200, train_loss: 1.2520
13/200, train_loss: 1.1949
14/200, train_loss: 1.1933
15/200, train_loss: 1.2515
16/200, train_loss: 0.9652
17/200, train_loss: 1.1437
18/200, train_loss: 0.9333
19/200, train_loss: 1.0839
20/200, train_loss: 1.0877
21/200, train_loss: 1.1775
22/200, train_loss: 1.1327
23/200, train_loss: 1.1215
24/200, train_loss: 0.9608
25/200, train_loss: 1.1083
26/200, train_loss: 1.0348
27/200, train_loss: 1.5456
28/200, train_loss: 0.9998
29/200, train_loss: 1.0735
30/200, train_loss: 1.1528
31/200, train_loss: 1.0450
32/200, train_loss: 1.1610
33/200, train_loss: 1.1360
34/200, train_loss: 1.0885
35/200, train_loss: 0.9327
36/200, train_loss: 1.0895
37/200, train_loss: 1.1223
38/200, train_loss: 0.8980
39/200, train_loss: 1.0095
40/200, train_loss: 1.0309
41/200, train_loss: 1.1110
42/200, train_loss: 1.0860
43/200, train_loss: 0.8720
44/200, train_loss: 1.0354
45/200, train_loss: 1.0818
46/200, train_loss: 1.1175
47/200, train_loss: 1.3521
48/200, train_loss: 0.9902
49/200, train_loss: 1.0330
50/200, train_loss: 1.1345
51/200, train_loss: 1.0496
52/200, train_loss: 0.9790
53/200, train_loss: 1.0252
54/200, train_loss: 1.0265
55/200, train_loss: 1.1516
56/200, train_loss: 0.9720
57/200, train_loss: 0.9798
58/200, train_loss: 1.0890
59/200, train_loss: 1.2169
60/200, train_loss: 1.0484
61/200, train_loss: 0.9222
62/200, train_loss: 1.0111
63/200, train_loss: 1.1222
64/200, train_loss: 1.0039
65/200, train_loss: 1.2519
66/200, train_loss: 1.0655
67/200, train_loss: 1.1025
68/200, train_loss: 1.1296
69/200, train_loss: 1.0652
70/200, train_loss: 1.1159
71/200, train_loss: 1.0246
72/200, train_loss: 0.8842
73/200, train_loss: 1.2013
74/200, train_loss: 1.0234
75/200, train_loss: 0.9206
76/200, train_loss: 1.1645
77/200, train_loss: 0.9846
78/200, train_loss: 1.1267
79/200, train_loss: 0.9645
80/200, train_loss: 0.9752
81/200, train_loss: 1.0525
82/200, train_loss: 1.0532
83/200, train_loss: 1.0388
84/200, train_loss: 1.4567
85/200, train_loss: 1.1144
86/200, train_loss: 0.9183
87/200, train_loss: 0.9693
88/200, train_loss: 1.0868
89/200, train_loss: 0.9715
90/200, train_loss: 1.1859
91/200, train_loss: 1.1616
92/200, train_loss: 0.9198
93/200, train_loss: 0.9364
94/200, train_loss: 1.0200
95/200, train_loss: 1.0729
96/200, train_loss: 1.3257
97/200, train_loss: 1.1328
98/200, train_loss: 1.1703
99/200, train_loss: 1.1702
100/200, train_loss: 1.1083
101/200, train_loss: 1.0729
102/200, train_loss: 1.1253
103/200, train_loss: 1.0122
104/200, train_loss: 1.1741
105/200, train_loss: 1.1853
106/200, train_loss: 0.9865
107/200, train_loss: 1.1596
108/200, train_loss: 1.0919
109/200, train_loss: 1.0980
110/200, train_loss: 0.9606
111/200, train_loss: 0.9811
112/200, train_loss: 0.8870
113/200, train_loss: 1.0306
114/200, train_loss: 0.9857
115/200, train_loss: 0.9762
116/200, train_loss: 1.1392
117/200, train_loss: 1.0134
118/200, train_loss: 0.9472
119/200, train_loss: 0.9871
120/200, train_loss: 1.0037
121/200, train_loss: 1.0879
122/200, train_loss: 1.1018
123/200, train_loss: 1.1376
124/200, train_loss: 1.0457
125/200, train_loss: 1.1579
126/200, train_loss: 1.1131
127/200, train_loss: 1.1383
128/200, train_loss: 1.1664
129/200, train_loss: 1.1608
130/200, train_loss: 1.1018
131/200, train_loss: 0.9561
132/200, train_loss: 0.9523
133/200, train_loss: 1.0664
134/200, train_loss: 0.9550
135/200, train_loss: 1.0537
136/200, train_loss: 1.1826
137/200, train_loss: 1.0345
138/200, train_loss: 1.3724
139/200, train_loss: 0.8865
140/200, train_loss: 1.0221
141/200, train_loss: 1.1167
142/200, train_loss: 0.9210
143/200, train_loss: 0.8630
144/200, train_loss: 0.9265
145/200, train_loss: 1.1034
146/200, train_loss: 1.0618
147/200, train_loss: 0.9986
148/200, train_loss: 1.1998
149/200, train_loss: 1.3590
150/200, train_loss: 1.3230
151/200, train_loss: 1.1558
152/200, train_loss: 1.1977
153/200, train_loss: 0.9209
154/200, train_loss: 1.0425
155/200, train_loss: 1.1945
156/200, train_loss: 0.9820
157/200, train_loss: 1.1236
158/200, train_loss: 0.9226
159/200, train_loss: 1.1492
160/200, train_loss: 1.0586
161/200, train_loss: 1.1531
162/200, train_loss: 1.0647
163/200, train_loss: 0.9490
164/200, train_loss: 1.0760
165/200, train_loss: 0.9525
166/200, train_loss: 1.0362
167/200, train_loss: 1.1442
168/200, train_loss: 1.1370
169/200, train_loss: 1.2592
170/200, train_loss: 1.1878
171/200, train_loss: 1.0708
172/200, train_loss: 1.0705
173/200, train_loss: 0.9301
174/200, train_loss: 1.0500
175/200, train_loss: 0.9144
176/200, train_loss: 1.1046
177/200, train_loss: 0.9832
178/200, train_loss: 1.1327
179/200, train_loss: 1.0634
180/200, train_loss: 1.0535
181/200, train_loss: 1.0069
182/200, train_loss: 0.9661
183/200, train_loss: 1.1363
184/200, train_loss: 1.1518
185/200, train_loss: 1.2532
186/200, train_loss: 0.9984
187/200, train_loss: 1.1014
188/200, train_loss: 0.8091
189/200, train_loss: 0.9874
190/200, train_loss: 1.0120
191/200, train_loss: 1.0561
192/200, train_loss: 0.9893
193/200, train_loss: 1.0613
194/200, train_loss: 1.0575
195/200, train_loss: 0.9384
196/200, train_loss: 1.0337
197/200, train_loss: 1.0741
198/200, train_loss: 1.1344
199/200, train_loss: 1.0224
200/200, train_loss: 0.9375
epoch 5 average loss: 1.0709
saved new best metric model
current epoch: 5 current mean dice: 0.3380 1: 0.2900 2: 0.3899
best mean dice: 0.3380 at epoch: 5
Epoch 5 completed
time consuming of epoch 5 is: 605.8628
----------
Epoch 6/50
1/200, train_loss: 1.1009
2/200, train_loss: 0.8731
3/200, train_loss: 0.9869
4/200, train_loss: 1.0847
5/200, train_loss: 1.1776
6/200, train_loss: 1.0673
7/200, train_loss: 1.0139
8/200, train_loss: 1.0751
9/200, train_loss: 1.1765
10/200, train_loss: 0.9686
11/200, train_loss: 1.1114
12/200, train_loss: 0.9870
13/200, train_loss: 0.9081
14/200, train_loss: 1.1854
15/200, train_loss: 1.0826
16/200, train_loss: 1.0400
17/200, train_loss: 0.9854
18/200, train_loss: 1.1972
19/200, train_loss: 1.0256
20/200, train_loss: 1.1668
21/200, train_loss: 1.1212
22/200, train_loss: 1.0660
23/200, train_loss: 1.0897
24/200, train_loss: 1.2154
25/200, train_loss: 1.0957
26/200, train_loss: 1.0938
27/200, train_loss: 1.1304
28/200, train_loss: 0.8333
29/200, train_loss: 1.1389
30/200, train_loss: 0.9552
31/200, train_loss: 0.9034
32/200, train_loss: 1.1983
33/200, train_loss: 1.0197
34/200, train_loss: 0.9318
35/200, train_loss: 0.9756
36/200, train_loss: 0.9670
37/200, train_loss: 1.0846
38/200, train_loss: 1.1042
39/200, train_loss: 1.1212
40/200, train_loss: 0.9935
41/200, train_loss: 1.0542
42/200, train_loss: 0.9934
43/200, train_loss: 0.9265
44/200, train_loss: 1.1607
45/200, train_loss: 0.9762
46/200, train_loss: 0.9575
47/200, train_loss: 1.0284
48/200, train_loss: 0.9355
49/200, train_loss: 1.1941
50/200, train_loss: 1.0068
51/200, train_loss: 1.2558
52/200, train_loss: 1.1266
53/200, train_loss: 1.0810
54/200, train_loss: 0.9931
55/200, train_loss: 0.9915
56/200, train_loss: 1.0169
57/200, train_loss: 0.9185
58/200, train_loss: 0.9527
59/200, train_loss: 1.0055
60/200, train_loss: 1.0514
61/200, train_loss: 1.1117
62/200, train_loss: 0.8477
63/200, train_loss: 1.0005
64/200, train_loss: 1.0715
65/200, train_loss: 1.1695
66/200, train_loss: 0.9873
67/200, train_loss: 1.0225
68/200, train_loss: 1.2121
69/200, train_loss: 1.0832
70/200, train_loss: 1.0927
71/200, train_loss: 1.0803
72/200, train_loss: 1.0674
73/200, train_loss: 1.2421
74/200, train_loss: 1.0116
75/200, train_loss: 1.0175
76/200, train_loss: 1.0653
77/200, train_loss: 1.2017
78/200, train_loss: 0.9309
79/200, train_loss: 1.0974
80/200, train_loss: 1.1532
81/200, train_loss: 0.9970
82/200, train_loss: 0.9783
83/200, train_loss: 0.8763
84/200, train_loss: 0.9079
85/200, train_loss: 1.0613
86/200, train_loss: 0.8504
87/200, train_loss: 1.0770
88/200, train_loss: 1.0708
89/200, train_loss: 1.0381
90/200, train_loss: 1.1012
91/200, train_loss: 1.1163
92/200, train_loss: 1.0489
93/200, train_loss: 1.0751
94/200, train_loss: 0.9893
95/200, train_loss: 1.0901
96/200, train_loss: 1.0846
97/200, train_loss: 1.0889
98/200, train_loss: 1.0538
99/200, train_loss: 1.1607
100/200, train_loss: 0.9920
101/200, train_loss: 1.0995
102/200, train_loss: 1.1963
103/200, train_loss: 0.9775
104/200, train_loss: 0.9984
105/200, train_loss: 1.0115
106/200, train_loss: 0.9805
107/200, train_loss: 1.1406
108/200, train_loss: 1.2165
109/200, train_loss: 0.9582
110/200, train_loss: 1.1493
111/200, train_loss: 1.1111
112/200, train_loss: 0.9015
113/200, train_loss: 1.0599
114/200, train_loss: 1.0956
115/200, train_loss: 1.0394
116/200, train_loss: 1.1160
117/200, train_loss: 1.0650
118/200, train_loss: 1.0420
119/200, train_loss: 1.1203
120/200, train_loss: 1.1567
121/200, train_loss: 0.9720
122/200, train_loss: 0.8945
123/200, train_loss: 1.0639
124/200, train_loss: 1.0876
125/200, train_loss: 0.9383
126/200, train_loss: 0.9362
127/200, train_loss: 0.9115
128/200, train_loss: 1.1239
129/200, train_loss: 0.8420
130/200, train_loss: 1.1300
131/200, train_loss: 0.8515
132/200, train_loss: 1.2920
133/200, train_loss: 1.4223
134/200, train_loss: 1.0485
135/200, train_loss: 1.1143
136/200, train_loss: 0.9520
137/200, train_loss: 0.9278
138/200, train_loss: 0.9900
139/200, train_loss: 1.0186
140/200, train_loss: 1.1472
141/200, train_loss: 0.9867
142/200, train_loss: 1.0752
143/200, train_loss: 1.1742
144/200, train_loss: 1.0499
145/200, train_loss: 1.0782
146/200, train_loss: 0.9880
147/200, train_loss: 1.1279
148/200, train_loss: 1.0279
149/200, train_loss: 1.0927
150/200, train_loss: 1.4993
151/200, train_loss: 1.0637
152/200, train_loss: 0.9411
153/200, train_loss: 1.0425
154/200, train_loss: 1.0103
155/200, train_loss: 1.1627
156/200, train_loss: 1.0434
157/200, train_loss: 0.9201
158/200, train_loss: 1.1073
159/200, train_loss: 1.1387
160/200, train_loss: 0.9080
161/200, train_loss: 1.0459
162/200, train_loss: 1.0644
163/200, train_loss: 0.9213
164/200, train_loss: 1.1903
165/200, train_loss: 1.1273
166/200, train_loss: 1.0273
167/200, train_loss: 0.9577
168/200, train_loss: 1.1510
169/200, train_loss: 1.0871
170/200, train_loss: 1.0788
171/200, train_loss: 0.9951
172/200, train_loss: 1.1397
173/200, train_loss: 0.9436
174/200, train_loss: 1.0473
175/200, train_loss: 0.9137
176/200, train_loss: 1.0958
177/200, train_loss: 0.9635
178/200, train_loss: 0.9555
179/200, train_loss: 1.0518
180/200, train_loss: 1.0820
181/200, train_loss: 1.0944
182/200, train_loss: 0.9789
183/200, train_loss: 0.9288
184/200, train_loss: 1.0714
185/200, train_loss: 1.0776
186/200, train_loss: 0.9208
187/200, train_loss: 1.1256
188/200, train_loss: 0.9447
189/200, train_loss: 0.8445
190/200, train_loss: 1.1476
191/200, train_loss: 1.1160
192/200, train_loss: 1.1403
193/200, train_loss: 1.0737
194/200, train_loss: 1.0177
195/200, train_loss: 1.1221
196/200, train_loss: 1.3953
197/200, train_loss: 1.0116
198/200, train_loss: 1.0608
199/200, train_loss: 1.1032
200/200, train_loss: 1.1322
epoch 6 average loss: 1.0534
saved new best metric model
current epoch: 6 current mean dice: 0.3535 1: 0.3058 2: 0.4031
best mean dice: 0.3535 at epoch: 6
Epoch 6 completed
time consuming of epoch 6 is: 606.4216
----------
Epoch 7/50
1/200, train_loss: 1.0447
2/200, train_loss: 1.0420
3/200, train_loss: 1.0908
4/200, train_loss: 1.0161
5/200, train_loss: 1.0507
6/200, train_loss: 1.0809
7/200, train_loss: 1.1695
8/200, train_loss: 1.0003
9/200, train_loss: 1.1316
10/200, train_loss: 0.9484
11/200, train_loss: 0.9096
12/200, train_loss: 0.9785
13/200, train_loss: 0.9476
14/200, train_loss: 1.1351
15/200, train_loss: 1.0407
16/200, train_loss: 1.2800
17/200, train_loss: 1.1301
18/200, train_loss: 1.1466
19/200, train_loss: 1.0053
20/200, train_loss: 1.1432
21/200, train_loss: 1.1172
22/200, train_loss: 1.0195
23/200, train_loss: 1.0567
24/200, train_loss: 1.0882
25/200, train_loss: 0.8570
26/200, train_loss: 0.8989
27/200, train_loss: 1.0106
28/200, train_loss: 0.9436
29/200, train_loss: 1.0382
30/200, train_loss: 1.1405
31/200, train_loss: 0.9907
32/200, train_loss: 1.1248
33/200, train_loss: 1.0143
34/200, train_loss: 1.1350
35/200, train_loss: 1.1251
36/200, train_loss: 1.0559
37/200, train_loss: 0.9021
38/200, train_loss: 1.0509
39/200, train_loss: 0.9944
40/200, train_loss: 1.0312
41/200, train_loss: 0.8508
42/200, train_loss: 1.0738
43/200, train_loss: 1.1775
44/200, train_loss: 1.1005
45/200, train_loss: 0.9932
46/200, train_loss: 0.9424
47/200, train_loss: 0.8341
48/200, train_loss: 1.1260
49/200, train_loss: 1.1418
50/200, train_loss: 0.9561
51/200, train_loss: 0.9042
52/200, train_loss: 1.0177
53/200, train_loss: 1.0643
54/200, train_loss: 1.1645
55/200, train_loss: 0.8887
56/200, train_loss: 1.0751
57/200, train_loss: 1.1416
58/200, train_loss: 0.9177
59/200, train_loss: 0.8806
60/200, train_loss: 0.9946
61/200, train_loss: 1.0614
62/200, train_loss: 1.0933
63/200, train_loss: 1.3539
64/200, train_loss: 1.1731
65/200, train_loss: 1.3636
66/200, train_loss: 0.8980
67/200, train_loss: 1.1445
68/200, train_loss: 1.1778
69/200, train_loss: 1.0501
70/200, train_loss: 1.0442
71/200, train_loss: 1.0404
72/200, train_loss: 1.0492
73/200, train_loss: 0.9754
74/200, train_loss: 1.1086
75/200, train_loss: 1.1677
76/200, train_loss: 1.0069
77/200, train_loss: 0.9958
78/200, train_loss: 1.1296
79/200, train_loss: 1.3828
80/200, train_loss: 1.0145
81/200, train_loss: 1.0818
82/200, train_loss: 1.0889
83/200, train_loss: 0.9649
84/200, train_loss: 1.1673
85/200, train_loss: 1.1336
86/200, train_loss: 1.1805
87/200, train_loss: 1.2053
88/200, train_loss: 1.1711
89/200, train_loss: 1.1013
90/200, train_loss: 1.1687
91/200, train_loss: 0.9204
92/200, train_loss: 1.0063
93/200, train_loss: 0.9515
94/200, train_loss: 1.1733
95/200, train_loss: 0.9294
96/200, train_loss: 1.0807
97/200, train_loss: 0.9165
98/200, train_loss: 0.9260
99/200, train_loss: 0.9152
100/200, train_loss: 1.1116
101/200, train_loss: 0.9280
102/200, train_loss: 0.9518
103/200, train_loss: 1.0621
104/200, train_loss: 1.0019
105/200, train_loss: 1.1232
106/200, train_loss: 1.0911
107/200, train_loss: 1.0562
108/200, train_loss: 1.1170
109/200, train_loss: 1.1096
110/200, train_loss: 1.0253
111/200, train_loss: 1.0853
112/200, train_loss: 0.9581
113/200, train_loss: 0.9513
114/200, train_loss: 1.2101
115/200, train_loss: 1.2361
116/200, train_loss: 1.1598
117/200, train_loss: 1.1583
118/200, train_loss: 0.9522
119/200, train_loss: 1.1957
120/200, train_loss: 1.0397
121/200, train_loss: 1.1637
122/200, train_loss: 1.0870
123/200, train_loss: 1.0119
124/200, train_loss: 1.1483
125/200, train_loss: 1.0036
126/200, train_loss: 0.9858
127/200, train_loss: 1.0867
128/200, train_loss: 1.0881
129/200, train_loss: 0.9946
130/200, train_loss: 0.9058
131/200, train_loss: 0.9351
132/200, train_loss: 0.9875
133/200, train_loss: 1.1771
134/200, train_loss: 1.1042
135/200, train_loss: 0.9086
136/200, train_loss: 0.9310
137/200, train_loss: 0.9152
138/200, train_loss: 1.0008
139/200, train_loss: 0.9117
140/200, train_loss: 1.1489
141/200, train_loss: 0.8227
142/200, train_loss: 0.9740
143/200, train_loss: 1.1859
144/200, train_loss: 1.1067
145/200, train_loss: 0.9264
146/200, train_loss: 0.9892
147/200, train_loss: 0.8427
148/200, train_loss: 1.0050
149/200, train_loss: 1.1001
150/200, train_loss: 0.9536
151/200, train_loss: 0.9194
152/200, train_loss: 1.0613
153/200, train_loss: 1.0967
154/200, train_loss: 1.0874
155/200, train_loss: 0.9236
156/200, train_loss: 1.2590
157/200, train_loss: 0.9648
158/200, train_loss: 0.8861
159/200, train_loss: 1.0295
160/200, train_loss: 1.0034
161/200, train_loss: 1.5096
162/200, train_loss: 1.0116
163/200, train_loss: 0.9743
164/200, train_loss: 1.0574
165/200, train_loss: 0.9623
166/200, train_loss: 1.0610
167/200, train_loss: 1.2028
168/200, train_loss: 1.1005
169/200, train_loss: 0.8997
170/200, train_loss: 1.0965
171/200, train_loss: 1.0372
172/200, train_loss: 1.0196
173/200, train_loss: 1.2323
174/200, train_loss: 1.0584
175/200, train_loss: 0.8799
176/200, train_loss: 0.9751
177/200, train_loss: 1.0830
178/200, train_loss: 1.2262
179/200, train_loss: 1.1703
180/200, train_loss: 0.9206
181/200, train_loss: 0.8715
182/200, train_loss: 0.8641
183/200, train_loss: 1.0837
184/200, train_loss: 1.0609
185/200, train_loss: 0.9736
186/200, train_loss: 1.0735
187/200, train_loss: 1.0499
188/200, train_loss: 1.1656
189/200, train_loss: 1.1265
190/200, train_loss: 0.8602
191/200, train_loss: 1.0393
192/200, train_loss: 0.9848
193/200, train_loss: 1.0401
194/200, train_loss: 1.3605
195/200, train_loss: 1.0106
196/200, train_loss: 0.9249
197/200, train_loss: 0.8483
198/200, train_loss: 0.9084
199/200, train_loss: 0.9973
200/200, train_loss: 1.1050
epoch 7 average loss: 1.0471
current epoch: 7 current mean dice: 0.3430 1: 0.2973 2: 0.3884
best mean dice: 0.3535 at epoch: 6
Epoch 7 completed
time consuming of epoch 7 is: 580.8600
----------
Epoch 8/50
1/200, train_loss: 1.0517
2/200, train_loss: 1.1111
3/200, train_loss: 1.1049
4/200, train_loss: 1.0780
5/200, train_loss: 0.9590
6/200, train_loss: 1.0587
7/200, train_loss: 1.1032
8/200, train_loss: 1.0573
9/200, train_loss: 1.0607
10/200, train_loss: 0.9033
11/200, train_loss: 1.1825
12/200, train_loss: 1.0782
13/200, train_loss: 1.0782
14/200, train_loss: 0.8586
15/200, train_loss: 1.0849
16/200, train_loss: 1.0070
17/200, train_loss: 1.0505
18/200, train_loss: 1.0881
19/200, train_loss: 0.7769
20/200, train_loss: 0.9581
21/200, train_loss: 1.0814
22/200, train_loss: 1.1327
23/200, train_loss: 1.4734
24/200, train_loss: 1.1878
25/200, train_loss: 0.9708
26/200, train_loss: 0.9285
27/200, train_loss: 1.0655
28/200, train_loss: 1.0614
29/200, train_loss: 0.8958
30/200, train_loss: 1.0035
31/200, train_loss: 0.9047
32/200, train_loss: 1.0126
33/200, train_loss: 1.0061
34/200, train_loss: 1.1200
35/200, train_loss: 1.0717
36/200, train_loss: 1.0370
37/200, train_loss: 1.1323
38/200, train_loss: 0.9042
39/200, train_loss: 1.2441
40/200, train_loss: 0.9828
41/200, train_loss: 1.5282
42/200, train_loss: 1.0003
43/200, train_loss: 0.9275
44/200, train_loss: 0.9418
45/200, train_loss: 0.9546
46/200, train_loss: 0.8868
47/200, train_loss: 1.1667
48/200, train_loss: 0.9719
49/200, train_loss: 1.0697
50/200, train_loss: 1.0708
51/200, train_loss: 1.0848
52/200, train_loss: 1.1227
53/200, train_loss: 1.1029
54/200, train_loss: 1.2303
55/200, train_loss: 1.1460
56/200, train_loss: 1.1521
57/200, train_loss: 0.9026
58/200, train_loss: 0.9672
59/200, train_loss: 1.0257
60/200, train_loss: 0.9739
61/200, train_loss: 0.9376
62/200, train_loss: 1.1216
63/200, train_loss: 1.1528
64/200, train_loss: 0.9766
65/200, train_loss: 1.1035
66/200, train_loss: 0.9897
67/200, train_loss: 1.0019
68/200, train_loss: 1.0039
69/200, train_loss: 0.9300
70/200, train_loss: 1.2039
71/200, train_loss: 1.0545
72/200, train_loss: 1.0036
73/200, train_loss: 1.0293
74/200, train_loss: 1.0400
75/200, train_loss: 0.9500
76/200, train_loss: 1.0779
77/200, train_loss: 1.0271
78/200, train_loss: 0.9846
79/200, train_loss: 0.9861
80/200, train_loss: 0.8785
81/200, train_loss: 1.0065
82/200, train_loss: 1.1749
83/200, train_loss: 0.9944
84/200, train_loss: 0.9734
85/200, train_loss: 1.0846
86/200, train_loss: 1.0225
87/200, train_loss: 0.9385
88/200, train_loss: 1.0215
89/200, train_loss: 1.0539
90/200, train_loss: 0.8595
91/200, train_loss: 1.0892
92/200, train_loss: 1.0354
93/200, train_loss: 1.2275
94/200, train_loss: 0.8666
95/200, train_loss: 1.1677
96/200, train_loss: 0.9808
97/200, train_loss: 1.0446
98/200, train_loss: 1.1559
99/200, train_loss: 0.8823
100/200, train_loss: 1.1700
101/200, train_loss: 1.0574
102/200, train_loss: 0.9806
103/200, train_loss: 1.1211
104/200, train_loss: 1.0340
105/200, train_loss: 1.0814
106/200, train_loss: 1.0201
107/200, train_loss: 1.1638
108/200, train_loss: 1.1034
109/200, train_loss: 0.9804
110/200, train_loss: 1.2150
111/200, train_loss: 1.1421
112/200, train_loss: 1.2772
113/200, train_loss: 0.9616
114/200, train_loss: 1.0459
115/200, train_loss: 1.0320
116/200, train_loss: 1.0673
117/200, train_loss: 0.8393
118/200, train_loss: 1.1470
119/200, train_loss: 1.1119
120/200, train_loss: 1.1961
121/200, train_loss: 1.1962
122/200, train_loss: 0.9468
123/200, train_loss: 1.1399
124/200, train_loss: 1.3095
125/200, train_loss: 1.1884
126/200, train_loss: 0.9619
127/200, train_loss: 1.0383
128/200, train_loss: 1.0511
129/200, train_loss: 0.9806
130/200, train_loss: 1.0584
131/200, train_loss: 0.9334
132/200, train_loss: 1.0146
133/200, train_loss: 0.9943
134/200, train_loss: 1.0369
135/200, train_loss: 0.9409
136/200, train_loss: 1.0875
137/200, train_loss: 0.9768
138/200, train_loss: 1.0036
139/200, train_loss: 0.8884
140/200, train_loss: 1.1648
141/200, train_loss: 1.1147
142/200, train_loss: 1.0734
143/200, train_loss: 0.9887
144/200, train_loss: 1.0715
145/200, train_loss: 1.0794
146/200, train_loss: 1.1896
147/200, train_loss: 1.0555
148/200, train_loss: 1.0312
149/200, train_loss: 1.1093
150/200, train_loss: 1.0180
151/200, train_loss: 0.9062
152/200, train_loss: 1.0565
153/200, train_loss: 1.0144
154/200, train_loss: 0.9762
155/200, train_loss: 1.1303
156/200, train_loss: 1.0757
157/200, train_loss: 1.2592
158/200, train_loss: 1.0057
159/200, train_loss: 1.2106
160/200, train_loss: 1.0589
161/200, train_loss: 0.9962
162/200, train_loss: 0.9720
163/200, train_loss: 0.8762
164/200, train_loss: 1.0457
165/200, train_loss: 0.9745
166/200, train_loss: 0.8894
167/200, train_loss: 1.0010
168/200, train_loss: 1.0287
169/200, train_loss: 0.9828
170/200, train_loss: 1.1253
171/200, train_loss: 0.8834
172/200, train_loss: 0.9321
173/200, train_loss: 1.1020
174/200, train_loss: 1.0190
175/200, train_loss: 0.8660
176/200, train_loss: 1.0070
177/200, train_loss: 0.9310
178/200, train_loss: 1.1547
179/200, train_loss: 0.9860
180/200, train_loss: 0.9133
181/200, train_loss: 1.0078
182/200, train_loss: 1.1023
183/200, train_loss: 0.9403
184/200, train_loss: 0.8656
185/200, train_loss: 0.9712
186/200, train_loss: 1.0179
187/200, train_loss: 1.1024
188/200, train_loss: 1.3382
189/200, train_loss: 0.9928
190/200, train_loss: 0.9904
191/200, train_loss: 0.9873
192/200, train_loss: 1.0897
193/200, train_loss: 1.0965
194/200, train_loss: 1.0438
195/200, train_loss: 0.9363
196/200, train_loss: 1.0708
197/200, train_loss: 1.0031
198/200, train_loss: 1.0926
199/200, train_loss: 1.0017
200/200, train_loss: 1.0676
epoch 8 average loss: 1.0431
current epoch: 8 current mean dice: 0.3485 1: 0.3256 2: 0.3707
best mean dice: 0.3535 at epoch: 6
Epoch 8 completed
time consuming of epoch 8 is: 590.5287
----------
Epoch 9/50
1/200, train_loss: 1.0578
2/200, train_loss: 0.8772
3/200, train_loss: 1.1041
4/200, train_loss: 0.9490
5/200, train_loss: 0.9708
6/200, train_loss: 1.0612
7/200, train_loss: 1.1198
8/200, train_loss: 0.9746
9/200, train_loss: 1.0191
10/200, train_loss: 1.1482
11/200, train_loss: 1.1072
12/200, train_loss: 1.1107
13/200, train_loss: 1.0940
14/200, train_loss: 0.8624
15/200, train_loss: 1.2268
16/200, train_loss: 0.9386
17/200, train_loss: 1.0963
18/200, train_loss: 1.0576
19/200, train_loss: 1.0499
20/200, train_loss: 0.9545
21/200, train_loss: 1.1115
22/200, train_loss: 1.0761
23/200, train_loss: 1.1532
24/200, train_loss: 1.0533
25/200, train_loss: 0.9356
26/200, train_loss: 0.9031
27/200, train_loss: 1.2705
28/200, train_loss: 0.9893
29/200, train_loss: 0.9088
30/200, train_loss: 1.1302
31/200, train_loss: 1.2132
32/200, train_loss: 1.1801
33/200, train_loss: 0.9066
34/200, train_loss: 1.0308
35/200, train_loss: 1.1553
36/200, train_loss: 1.0642
37/200, train_loss: 0.9567
38/200, train_loss: 1.0176
39/200, train_loss: 1.0254
40/200, train_loss: 0.9608
41/200, train_loss: 1.0558
42/200, train_loss: 0.9452
43/200, train_loss: 1.1215
44/200, train_loss: 1.0205
45/200, train_loss: 0.9383
46/200, train_loss: 1.3183
47/200, train_loss: 0.9681
48/200, train_loss: 1.0559
49/200, train_loss: 1.0854
50/200, train_loss: 1.2093
51/200, train_loss: 0.8943
52/200, train_loss: 0.9569
53/200, train_loss: 1.1345
54/200, train_loss: 1.2028
55/200, train_loss: 1.0365
56/200, train_loss: 0.9920
57/200, train_loss: 1.1901
58/200, train_loss: 1.1831
59/200, train_loss: 1.0771
60/200, train_loss: 0.9739
61/200, train_loss: 0.9999
62/200, train_loss: 1.0710
63/200, train_loss: 1.2419
64/200, train_loss: 0.9505
65/200, train_loss: 1.1366
66/200, train_loss: 1.1084
67/200, train_loss: 0.9218
68/200, train_loss: 0.9996
69/200, train_loss: 1.0123
70/200, train_loss: 0.9805
71/200, train_loss: 1.0799
72/200, train_loss: 0.9857
73/200, train_loss: 1.1548
74/200, train_loss: 0.8903
75/200, train_loss: 1.2769
76/200, train_loss: 0.9190
77/200, train_loss: 1.1804
78/200, train_loss: 1.0855
79/200, train_loss: 1.0766
80/200, train_loss: 1.0524
81/200, train_loss: 0.9442
82/200, train_loss: 1.0547
83/200, train_loss: 0.9873
84/200, train_loss: 1.1290
85/200, train_loss: 0.9465
86/200, train_loss: 0.9549
87/200, train_loss: 1.0264
88/200, train_loss: 0.9369
89/200, train_loss: 0.9825
90/200, train_loss: 0.9477
91/200, train_loss: 0.9722
92/200, train_loss: 1.0515
93/200, train_loss: 0.9010
94/200, train_loss: 1.0138
95/200, train_loss: 0.9607
96/200, train_loss: 1.0344
97/200, train_loss: 1.0870
98/200, train_loss: 1.0230
99/200, train_loss: 1.3395
100/200, train_loss: 0.8226
101/200, train_loss: 0.9099
102/200, train_loss: 1.1831
103/200, train_loss: 1.0037
104/200, train_loss: 1.0011
105/200, train_loss: 0.9338
106/200, train_loss: 0.9898
107/200, train_loss: 1.0526
108/200, train_loss: 1.0089
109/200, train_loss: 1.0571
110/200, train_loss: 0.9251
111/200, train_loss: 1.1285
112/200, train_loss: 0.8835
113/200, train_loss: 0.9497
114/200, train_loss: 1.0383
115/200, train_loss: 1.1575
116/200, train_loss: 1.1138
117/200, train_loss: 1.0369
118/200, train_loss: 1.0612
119/200, train_loss: 1.0970
120/200, train_loss: 1.2339
121/200, train_loss: 0.9464
122/200, train_loss: 1.0597
123/200, train_loss: 1.0196
124/200, train_loss: 0.8991
125/200, train_loss: 1.0268
126/200, train_loss: 0.8954
127/200, train_loss: 0.9847
128/200, train_loss: 1.0906
129/200, train_loss: 0.8890
130/200, train_loss: 1.0468
131/200, train_loss: 1.0113
132/200, train_loss: 0.9400
133/200, train_loss: 1.0443
134/200, train_loss: 1.0559
135/200, train_loss: 1.0168
136/200, train_loss: 0.9544
137/200, train_loss: 1.0590
138/200, train_loss: 1.0356
139/200, train_loss: 0.9037
140/200, train_loss: 0.9672
141/200, train_loss: 1.0805
142/200, train_loss: 0.9288
143/200, train_loss: 1.0878
144/200, train_loss: 0.9747
145/200, train_loss: 1.0109
146/200, train_loss: 0.9562
147/200, train_loss: 1.0535
148/200, train_loss: 0.9949
149/200, train_loss: 0.9865
150/200, train_loss: 0.9712
151/200, train_loss: 0.9830
152/200, train_loss: 1.0380
153/200, train_loss: 1.0595
154/200, train_loss: 1.0908
155/200, train_loss: 1.2709
156/200, train_loss: 0.9833
157/200, train_loss: 1.2228
158/200, train_loss: 1.0472
159/200, train_loss: 0.9618
160/200, train_loss: 1.0336
161/200, train_loss: 1.0713
162/200, train_loss: 1.0907
163/200, train_loss: 1.1025
164/200, train_loss: 1.0749
165/200, train_loss: 0.9974
166/200, train_loss: 1.2138
167/200, train_loss: 1.0037
168/200, train_loss: 1.0077
169/200, train_loss: 0.9044
170/200, train_loss: 1.1447
171/200, train_loss: 0.8829
172/200, train_loss: 1.0212
173/200, train_loss: 1.0860
174/200, train_loss: 0.9115
175/200, train_loss: 0.9583
176/200, train_loss: 1.1449
177/200, train_loss: 1.0129
178/200, train_loss: 1.0739
179/200, train_loss: 0.9134
180/200, train_loss: 1.0057
181/200, train_loss: 0.9540
182/200, train_loss: 0.9120
183/200, train_loss: 0.8806
184/200, train_loss: 0.8994
185/200, train_loss: 0.9735
186/200, train_loss: 0.9731
187/200, train_loss: 0.9021
188/200, train_loss: 1.0935
189/200, train_loss: 1.0621
190/200, train_loss: 1.0159
191/200, train_loss: 1.1841
192/200, train_loss: 1.0494
193/200, train_loss: 0.9397
194/200, train_loss: 0.9710
195/200, train_loss: 1.1878
196/200, train_loss: 0.8989
197/200, train_loss: 0.9941
198/200, train_loss: 0.9563
199/200, train_loss: 1.1315
200/200, train_loss: 0.8470
epoch 9 average loss: 1.0311
saved new best metric model
current epoch: 9 current mean dice: 0.3588 1: 0.3265 2: 0.3952
best mean dice: 0.3588 at epoch: 9
Epoch 9 completed
time consuming of epoch 9 is: 601.6596
----------
Epoch 10/50
1/200, train_loss: 0.9359
2/200, train_loss: 1.0301
3/200, train_loss: 0.9207
4/200, train_loss: 0.8367
5/200, train_loss: 1.0651
6/200, train_loss: 1.0478
7/200, train_loss: 1.0536
8/200, train_loss: 0.9404
9/200, train_loss: 0.9321
10/200, train_loss: 0.9621
11/200, train_loss: 0.8947
12/200, train_loss: 1.0478
13/200, train_loss: 1.0321
14/200, train_loss: 1.0385
15/200, train_loss: 1.1146
16/200, train_loss: 0.8650
17/200, train_loss: 0.9908
18/200, train_loss: 1.0391
19/200, train_loss: 0.8190
20/200, train_loss: 1.1954
21/200, train_loss: 1.1262
22/200, train_loss: 1.0934
23/200, train_loss: 1.0837
24/200, train_loss: 0.9163
25/200, train_loss: 0.9793
26/200, train_loss: 0.8507
27/200, train_loss: 1.0272
28/200, train_loss: 1.1872
29/200, train_loss: 0.8667
30/200, train_loss: 1.1432
31/200, train_loss: 0.8013
32/200, train_loss: 1.0311
33/200, train_loss: 0.9883
34/200, train_loss: 1.0746
35/200, train_loss: 0.9499
36/200, train_loss: 1.0463
37/200, train_loss: 0.9356
38/200, train_loss: 1.0215
39/200, train_loss: 1.0129
40/200, train_loss: 1.0882
41/200, train_loss: 1.0182
42/200, train_loss: 0.9881
43/200, train_loss: 0.9918
44/200, train_loss: 1.0557
45/200, train_loss: 1.1165
46/200, train_loss: 1.1436
47/200, train_loss: 1.0610
48/200, train_loss: 1.0133
49/200, train_loss: 0.9211
50/200, train_loss: 0.9754
51/200, train_loss: 1.2073
52/200, train_loss: 1.0164
53/200, train_loss: 1.0329
54/200, train_loss: 0.8506
55/200, train_loss: 0.9377
56/200, train_loss: 1.1212
57/200, train_loss: 1.1204
58/200, train_loss: 1.0552
59/200, train_loss: 1.0133
60/200, train_loss: 0.8359
61/200, train_loss: 0.9745
62/200, train_loss: 0.9549
63/200, train_loss: 1.2676
64/200, train_loss: 0.9140
65/200, train_loss: 0.9990
66/200, train_loss: 0.8769
67/200, train_loss: 0.9740
68/200, train_loss: 1.1450
69/200, train_loss: 1.0104
70/200, train_loss: 1.1438
71/200, train_loss: 1.0655
72/200, train_loss: 1.1325
73/200, train_loss: 1.0169
74/200, train_loss: 1.0083
75/200, train_loss: 1.1213
76/200, train_loss: 1.0072
77/200, train_loss: 1.0574
78/200, train_loss: 1.3628
79/200, train_loss: 1.0329
80/200, train_loss: 1.0419
81/200, train_loss: 0.9445
82/200, train_loss: 1.1573
83/200, train_loss: 0.9850
84/200, train_loss: 1.1244
85/200, train_loss: 0.9483
86/200, train_loss: 1.1178
87/200, train_loss: 0.8703
88/200, train_loss: 0.9562
89/200, train_loss: 0.9350
90/200, train_loss: 1.0361
91/200, train_loss: 1.0610
92/200, train_loss: 0.9241
93/200, train_loss: 0.9807
94/200, train_loss: 0.9665
95/200, train_loss: 1.1888
96/200, train_loss: 1.0849
97/200, train_loss: 0.9459
98/200, train_loss: 1.1383
99/200, train_loss: 0.9766
100/200, train_loss: 0.9687
101/200, train_loss: 0.7837
102/200, train_loss: 0.9585
103/200, train_loss: 1.0134
104/200, train_loss: 0.9843
105/200, train_loss: 0.9076
106/200, train_loss: 1.0787
107/200, train_loss: 0.9297
108/200, train_loss: 0.8447
109/200, train_loss: 0.8309
110/200, train_loss: 1.0255
111/200, train_loss: 0.9606
112/200, train_loss: 1.0055
113/200, train_loss: 0.8822
114/200, train_loss: 1.0366
115/200, train_loss: 1.1189
116/200, train_loss: 1.0411
117/200, train_loss: 1.0388
118/200, train_loss: 0.9347
119/200, train_loss: 1.1051
120/200, train_loss: 0.9663
121/200, train_loss: 1.1185
122/200, train_loss: 0.9262
123/200, train_loss: 1.1210
124/200, train_loss: 0.9243
125/200, train_loss: 0.9673
126/200, train_loss: 1.0772
127/200, train_loss: 1.1960
128/200, train_loss: 1.0943
129/200, train_loss: 0.8782
130/200, train_loss: 1.0998
131/200, train_loss: 1.1461
132/200, train_loss: 0.9919
133/200, train_loss: 0.9925
134/200, train_loss: 1.1170
135/200, train_loss: 1.0204
136/200, train_loss: 1.1694
137/200, train_loss: 0.9868
138/200, train_loss: 1.0501
139/200, train_loss: 0.9300
140/200, train_loss: 1.2223
141/200, train_loss: 1.0649
142/200, train_loss: 0.9187
143/200, train_loss: 1.0199
144/200, train_loss: 1.1668
145/200, train_loss: 0.9633
146/200, train_loss: 0.9736
147/200, train_loss: 1.0462
148/200, train_loss: 1.0498
149/200, train_loss: 1.0569
150/200, train_loss: 0.9228
151/200, train_loss: 1.3962
152/200, train_loss: 0.9806
153/200, train_loss: 0.9557
154/200, train_loss: 1.0312
155/200, train_loss: 1.2537
156/200, train_loss: 1.0220
157/200, train_loss: 0.9500
158/200, train_loss: 0.9275
159/200, train_loss: 0.9720
160/200, train_loss: 0.9895
161/200, train_loss: 1.1650
162/200, train_loss: 0.9226
163/200, train_loss: 1.1844
164/200, train_loss: 0.8829
165/200, train_loss: 1.0807
166/200, train_loss: 1.0655
167/200, train_loss: 1.0504
168/200, train_loss: 1.0108
169/200, train_loss: 0.9855
170/200, train_loss: 1.1351
171/200, train_loss: 0.9250
172/200, train_loss: 0.8743
173/200, train_loss: 1.1127
174/200, train_loss: 1.1226
175/200, train_loss: 1.0323
176/200, train_loss: 1.0697
177/200, train_loss: 0.9047
178/200, train_loss: 1.0854
179/200, train_loss: 0.9073
180/200, train_loss: 0.9092
181/200, train_loss: 1.1081
182/200, train_loss: 1.0419
183/200, train_loss: 1.0533
184/200, train_loss: 1.0595
185/200, train_loss: 1.3295
186/200, train_loss: 1.0405
187/200, train_loss: 1.2203
188/200, train_loss: 0.9619
189/200, train_loss: 0.9391
190/200, train_loss: 0.9657
191/200, train_loss: 1.2143
192/200, train_loss: 0.8133
193/200, train_loss: 1.1582
194/200, train_loss: 1.0563
195/200, train_loss: 1.2841
196/200, train_loss: 1.1140
197/200, train_loss: 0.9993
198/200, train_loss: 0.9301
199/200, train_loss: 1.0161
200/200, train_loss: 0.9623
epoch 10 average loss: 1.0235
current epoch: 10 current mean dice: 0.3522 1: 0.3502 2: 0.3535
best mean dice: 0.3588 at epoch: 9
Epoch 10 completed
time consuming of epoch 10 is: 598.5322
----------
Epoch 11/50
1/200, train_loss: 1.1141
2/200, train_loss: 1.0738
3/200, train_loss: 0.9088
4/200, train_loss: 1.1988
5/200, train_loss: 1.0980
6/200, train_loss: 1.0033
7/200, train_loss: 0.9568
8/200, train_loss: 1.0561
9/200, train_loss: 0.8734
10/200, train_loss: 0.9190
11/200, train_loss: 1.1025
12/200, train_loss: 1.0310
13/200, train_loss: 0.9564
14/200, train_loss: 1.0998
15/200, train_loss: 1.0940
16/200, train_loss: 1.1101
17/200, train_loss: 0.8858
18/200, train_loss: 1.1575
19/200, train_loss: 1.1332
20/200, train_loss: 1.0407
21/200, train_loss: 0.9333
22/200, train_loss: 1.2387
23/200, train_loss: 0.8876
24/200, train_loss: 1.0971
25/200, train_loss: 0.9366
26/200, train_loss: 0.8396
27/200, train_loss: 0.9836
28/200, train_loss: 0.9585
29/200, train_loss: 1.1112
30/200, train_loss: 1.1090
31/200, train_loss: 1.1112
32/200, train_loss: 0.9115
33/200, train_loss: 0.9743
34/200, train_loss: 1.0077
35/200, train_loss: 0.9583
36/200, train_loss: 1.0424
37/200, train_loss: 1.0212
38/200, train_loss: 1.0118
39/200, train_loss: 1.1185
40/200, train_loss: 1.0920
41/200, train_loss: 1.0301
42/200, train_loss: 1.1577
43/200, train_loss: 1.0499
44/200, train_loss: 1.0429
45/200, train_loss: 1.1125
46/200, train_loss: 1.0849
47/200, train_loss: 0.9047
48/200, train_loss: 1.1852
49/200, train_loss: 1.0865
50/200, train_loss: 1.0613
51/200, train_loss: 1.0828
52/200, train_loss: 1.0773
53/200, train_loss: 1.3050
54/200, train_loss: 1.0381
55/200, train_loss: 1.0173
56/200, train_loss: 1.0442
57/200, train_loss: 1.0888
58/200, train_loss: 1.1317
59/200, train_loss: 0.9695
60/200, train_loss: 1.0074
61/200, train_loss: 1.1114
62/200, train_loss: 1.0121
63/200, train_loss: 1.1013
64/200, train_loss: 0.9575
65/200, train_loss: 1.0687
66/200, train_loss: 1.1429
67/200, train_loss: 1.1612
68/200, train_loss: 1.1240
69/200, train_loss: 1.1195
70/200, train_loss: 1.0862
71/200, train_loss: 1.1101
72/200, train_loss: 1.5291
73/200, train_loss: 1.1983
74/200, train_loss: 1.0606
75/200, train_loss: 0.8945
76/200, train_loss: 1.1589
77/200, train_loss: 1.0135
78/200, train_loss: 1.2299
79/200, train_loss: 0.9959
80/200, train_loss: 1.1003
81/200, train_loss: 1.0509
82/200, train_loss: 1.0769
83/200, train_loss: 0.9144
84/200, train_loss: 1.0683
85/200, train_loss: 0.9738
86/200, train_loss: 1.0438
87/200, train_loss: 1.1158
88/200, train_loss: 1.1568
89/200, train_loss: 1.0166
90/200, train_loss: 1.1783
91/200, train_loss: 0.9502
92/200, train_loss: 1.0099
93/200, train_loss: 1.0128
94/200, train_loss: 0.9110
95/200, train_loss: 0.9735
96/200, train_loss: 1.0440
97/200, train_loss: 1.0942
98/200, train_loss: 0.9324
99/200, train_loss: 1.0929
100/200, train_loss: 1.0413
101/200, train_loss: 1.1431
102/200, train_loss: 1.0013
103/200, train_loss: 0.8783
104/200, train_loss: 1.3177
105/200, train_loss: 0.9791
106/200, train_loss: 1.0504
107/200, train_loss: 1.0432
108/200, train_loss: 1.1095
109/200, train_loss: 0.9725
110/200, train_loss: 0.9582
111/200, train_loss: 0.9765
112/200, train_loss: 0.9472
113/200, train_loss: 1.0057
114/200, train_loss: 1.0036
115/200, train_loss: 1.0825
116/200, train_loss: 1.0264
117/200, train_loss: 1.0829
118/200, train_loss: 1.1106
119/200, train_loss: 0.9705
120/200, train_loss: 0.8584
121/200, train_loss: 0.9060
122/200, train_loss: 1.1813
123/200, train_loss: 1.0567
124/200, train_loss: 0.8313
125/200, train_loss: 0.9326
126/200, train_loss: 1.0106
127/200, train_loss: 1.1256
128/200, train_loss: 0.8480
129/200, train_loss: 1.2499
130/200, train_loss: 1.0992
131/200, train_loss: 1.0138
132/200, train_loss: 0.9426
133/200, train_loss: 1.0105
134/200, train_loss: 1.0059
135/200, train_loss: 0.9677
136/200, train_loss: 0.8744
137/200, train_loss: 0.9319
138/200, train_loss: 1.0188
139/200, train_loss: 0.9360
140/200, train_loss: 1.0025
141/200, train_loss: 0.9844
142/200, train_loss: 0.9437
143/200, train_loss: 1.1296
144/200, train_loss: 1.0855
145/200, train_loss: 0.9544
146/200, train_loss: 0.9615
147/200, train_loss: 0.9505
148/200, train_loss: 0.9075
149/200, train_loss: 0.9293
150/200, train_loss: 0.9961
151/200, train_loss: 1.0696
152/200, train_loss: 0.9444
153/200, train_loss: 0.9364
154/200, train_loss: 0.9217
155/200, train_loss: 0.8903
156/200, train_loss: 1.2418
157/200, train_loss: 1.1803
158/200, train_loss: 0.9527
159/200, train_loss: 1.0947
160/200, train_loss: 1.0508
161/200, train_loss: 1.1668
162/200, train_loss: 1.1801
163/200, train_loss: 0.9815
164/200, train_loss: 1.1012
165/200, train_loss: 1.1615
166/200, train_loss: 1.0369
167/200, train_loss: 0.9710
168/200, train_loss: 1.0531
169/200, train_loss: 0.9880
170/200, train_loss: 0.9842
171/200, train_loss: 0.9800
172/200, train_loss: 1.1110
173/200, train_loss: 1.1454
174/200, train_loss: 0.9891
175/200, train_loss: 0.8915
176/200, train_loss: 0.9754
177/200, train_loss: 1.0039
178/200, train_loss: 0.9424
179/200, train_loss: 1.0937
180/200, train_loss: 0.8502
181/200, train_loss: 1.0769
182/200, train_loss: 1.0813
183/200, train_loss: 0.9496
184/200, train_loss: 0.9502
185/200, train_loss: 1.0631
186/200, train_loss: 0.8726
187/200, train_loss: 1.1249
188/200, train_loss: 1.2885
189/200, train_loss: 1.0845
190/200, train_loss: 1.1125
191/200, train_loss: 1.0062
192/200, train_loss: 0.9329
193/200, train_loss: 0.9819
194/200, train_loss: 1.0532
195/200, train_loss: 1.1223
196/200, train_loss: 1.0657
197/200, train_loss: 1.1678
198/200, train_loss: 1.0101
199/200, train_loss: 1.1248
200/200, train_loss: 1.1181
epoch 11 average loss: 1.0393
current epoch: 11 current mean dice: 0.3197 1: 0.3876 2: 0.2422
best mean dice: 0.3588 at epoch: 9
Epoch 11 completed
time consuming of epoch 11 is: 589.3266
----------
Epoch 12/50
1/200, train_loss: 0.9571
2/200, train_loss: 0.9922
3/200, train_loss: 1.0499
4/200, train_loss: 0.9863
5/200, train_loss: 1.1585
6/200, train_loss: 1.1774
7/200, train_loss: 1.0184
8/200, train_loss: 1.0568
9/200, train_loss: 1.0763
10/200, train_loss: 1.1760
11/200, train_loss: 1.0594
12/200, train_loss: 1.0714
13/200, train_loss: 0.9124
14/200, train_loss: 0.8779
15/200, train_loss: 1.1832
16/200, train_loss: 0.9103
17/200, train_loss: 0.9495
18/200, train_loss: 0.8629
19/200, train_loss: 1.0375
20/200, train_loss: 0.9923
21/200, train_loss: 1.0220
22/200, train_loss: 1.0823
23/200, train_loss: 1.1262
24/200, train_loss: 1.0787
25/200, train_loss: 1.0364
26/200, train_loss: 1.0261
27/200, train_loss: 1.0728
28/200, train_loss: 1.1304
29/200, train_loss: 0.9889
30/200, train_loss: 1.0269
31/200, train_loss: 0.9852
32/200, train_loss: 1.0309
33/200, train_loss: 1.0179
34/200, train_loss: 1.2740
35/200, train_loss: 0.8470
36/200, train_loss: 0.9994
37/200, train_loss: 0.9475
38/200, train_loss: 1.0159
39/200, train_loss: 1.0719
40/200, train_loss: 0.8511
41/200, train_loss: 1.2098
42/200, train_loss: 1.1726
43/200, train_loss: 0.8583
44/200, train_loss: 0.9991
45/200, train_loss: 1.0625
46/200, train_loss: 1.0217
47/200, train_loss: 1.1428
48/200, train_loss: 0.9766
49/200, train_loss: 0.9729
50/200, train_loss: 1.0093
51/200, train_loss: 0.9893
52/200, train_loss: 0.9374
53/200, train_loss: 1.1870
54/200, train_loss: 1.0987
55/200, train_loss: 0.8981
56/200, train_loss: 1.0608
57/200, train_loss: 1.0645
58/200, train_loss: 1.1327
59/200, train_loss: 1.0654
60/200, train_loss: 1.1257
61/200, train_loss: 0.9388
62/200, train_loss: 1.1719
63/200, train_loss: 1.0440
64/200, train_loss: 0.9414
65/200, train_loss: 1.0838
66/200, train_loss: 0.9423
67/200, train_loss: 0.9029
68/200, train_loss: 0.8645
69/200, train_loss: 1.0605
70/200, train_loss: 1.0310
71/200, train_loss: 1.0998
72/200, train_loss: 1.0063
73/200, train_loss: 1.0208
74/200, train_loss: 0.9455
75/200, train_loss: 1.1266
76/200, train_loss: 0.7968
77/200, train_loss: 0.8765
78/200, train_loss: 1.1161
79/200, train_loss: 0.9569
80/200, train_loss: 1.1145
81/200, train_loss: 1.1259
82/200, train_loss: 0.9788
83/200, train_loss: 0.9471
84/200, train_loss: 0.8417
85/200, train_loss: 0.8241
86/200, train_loss: 1.1437
87/200, train_loss: 0.9865
88/200, train_loss: 0.9091
89/200, train_loss: 0.9911
90/200, train_loss: 1.1129
91/200, train_loss: 0.9356
92/200, train_loss: 1.0378
93/200, train_loss: 1.0012
94/200, train_loss: 1.0031
95/200, train_loss: 1.0417
96/200, train_loss: 1.1142
97/200, train_loss: 1.0849
98/200, train_loss: 0.9409
99/200, train_loss: 0.9561
100/200, train_loss: 1.0182
101/200, train_loss: 1.0189
102/200, train_loss: 0.9109
103/200, train_loss: 1.1134
104/200, train_loss: 1.0605
105/200, train_loss: 1.2365
106/200, train_loss: 0.9933
107/200, train_loss: 0.9564
108/200, train_loss: 1.0409
109/200, train_loss: 0.9736
110/200, train_loss: 1.0733
111/200, train_loss: 0.8185
112/200, train_loss: 0.9788
113/200, train_loss: 1.0863
114/200, train_loss: 0.8756
115/200, train_loss: 1.0451
116/200, train_loss: 1.1542
117/200, train_loss: 1.0068
118/200, train_loss: 0.9584
119/200, train_loss: 1.0431
120/200, train_loss: 1.0878
121/200, train_loss: 1.0249
122/200, train_loss: 1.0372
123/200, train_loss: 1.0717
124/200, train_loss: 0.9748
125/200, train_loss: 1.0323
126/200, train_loss: 1.0168
127/200, train_loss: 0.8216
128/200, train_loss: 0.9357
129/200, train_loss: 1.1027
130/200, train_loss: 1.0472
131/200, train_loss: 0.9817
132/200, train_loss: 1.0167
133/200, train_loss: 0.9282
134/200, train_loss: 0.8123
135/200, train_loss: 0.9229
136/200, train_loss: 0.9140
137/200, train_loss: 1.3885
138/200, train_loss: 1.1238
139/200, train_loss: 0.9173
140/200, train_loss: 0.9292
141/200, train_loss: 1.2248
142/200, train_loss: 1.0089
143/200, train_loss: 0.9798
144/200, train_loss: 1.0534
145/200, train_loss: 1.0746
146/200, train_loss: 1.0134
147/200, train_loss: 1.0052
148/200, train_loss: 1.0777
149/200, train_loss: 0.9671
150/200, train_loss: 0.9945
151/200, train_loss: 0.9567
152/200, train_loss: 1.0472
153/200, train_loss: 0.8778
154/200, train_loss: 1.0264
155/200, train_loss: 0.9284
156/200, train_loss: 1.1543
157/200, train_loss: 1.0173
158/200, train_loss: 1.0020
159/200, train_loss: 1.1038
160/200, train_loss: 0.9519
161/200, train_loss: 1.0548
162/200, train_loss: 0.9161
163/200, train_loss: 1.1248
164/200, train_loss: 1.0156
165/200, train_loss: 1.1656
166/200, train_loss: 0.9562
167/200, train_loss: 0.8459
168/200, train_loss: 1.1412
169/200, train_loss: 0.8705
170/200, train_loss: 1.0602
171/200, train_loss: 1.0923
172/200, train_loss: 1.0401
173/200, train_loss: 0.8619
174/200, train_loss: 1.0421
175/200, train_loss: 0.9544
176/200, train_loss: 0.9182
177/200, train_loss: 0.7683
178/200, train_loss: 1.0303
179/200, train_loss: 1.0125
180/200, train_loss: 1.1993
181/200, train_loss: 1.0334
182/200, train_loss: 1.2024
183/200, train_loss: 1.0587
184/200, train_loss: 0.9795
185/200, train_loss: 1.1457
186/200, train_loss: 1.2580
187/200, train_loss: 0.9975
188/200, train_loss: 0.9008
189/200, train_loss: 1.0013
190/200, train_loss: 0.8974
191/200, train_loss: 0.9636
192/200, train_loss: 1.0549
193/200, train_loss: 0.9368
194/200, train_loss: 0.9555
195/200, train_loss: 1.0266
196/200, train_loss: 0.9213
197/200, train_loss: 0.8095
198/200, train_loss: 1.1628
199/200, train_loss: 1.1155
200/200, train_loss: 1.1087
epoch 12 average loss: 1.0183
saved new best metric model
current epoch: 12 current mean dice: 0.3650 1: 0.3192 2: 0.4140
best mean dice: 0.3650 at epoch: 12
Epoch 12 completed
time consuming of epoch 12 is: 606.4782
----------
Epoch 13/50
1/200, train_loss: 0.9522
2/200, train_loss: 0.9751
3/200, train_loss: 0.9366
4/200, train_loss: 1.0892
5/200, train_loss: 1.1797
6/200, train_loss: 1.0070
7/200, train_loss: 1.0540
8/200, train_loss: 1.1559
9/200, train_loss: 1.0123
10/200, train_loss: 1.1266
11/200, train_loss: 1.0442
12/200, train_loss: 0.9332
13/200, train_loss: 1.1780
14/200, train_loss: 1.0947
15/200, train_loss: 0.7838
16/200, train_loss: 1.0195
17/200, train_loss: 0.9032
18/200, train_loss: 0.8966
19/200, train_loss: 0.9633
20/200, train_loss: 0.8959
21/200, train_loss: 0.9653
22/200, train_loss: 1.0849
23/200, train_loss: 0.9840
24/200, train_loss: 0.8388
25/200, train_loss: 1.0252
26/200, train_loss: 0.9952
27/200, train_loss: 1.1027
28/200, train_loss: 1.1846
29/200, train_loss: 1.0527
30/200, train_loss: 1.0537
31/200, train_loss: 1.1004
32/200, train_loss: 1.0274
33/200, train_loss: 1.0775
34/200, train_loss: 1.1375
35/200, train_loss: 0.9032
36/200, train_loss: 1.0018
37/200, train_loss: 1.1113
38/200, train_loss: 1.0484
39/200, train_loss: 0.8939
40/200, train_loss: 0.9161
41/200, train_loss: 0.9780
42/200, train_loss: 0.9756
43/200, train_loss: 1.0563
44/200, train_loss: 1.0405
45/200, train_loss: 1.1262
46/200, train_loss: 1.0840
47/200, train_loss: 0.8341
48/200, train_loss: 0.9378
49/200, train_loss: 1.3091
50/200, train_loss: 0.8684
51/200, train_loss: 0.8447
52/200, train_loss: 1.0565
53/200, train_loss: 1.0586
54/200, train_loss: 1.0158
55/200, train_loss: 0.9275
56/200, train_loss: 1.0989
57/200, train_loss: 1.1716
58/200, train_loss: 1.0258
59/200, train_loss: 0.9456
60/200, train_loss: 0.9275
61/200, train_loss: 0.9644
62/200, train_loss: 1.1181
63/200, train_loss: 1.0381
64/200, train_loss: 1.1859
65/200, train_loss: 1.1312
66/200, train_loss: 0.9970
67/200, train_loss: 1.1701
68/200, train_loss: 1.1456
69/200, train_loss: 1.0255
70/200, train_loss: 0.9391
71/200, train_loss: 0.9268
72/200, train_loss: 0.8773
73/200, train_loss: 1.0720
74/200, train_loss: 0.8919
75/200, train_loss: 1.0555
76/200, train_loss: 0.9368
77/200, train_loss: 0.8863
78/200, train_loss: 1.0321
79/200, train_loss: 0.9034
80/200, train_loss: 0.9745
81/200, train_loss: 0.8217
82/200, train_loss: 1.2201
83/200, train_loss: 0.9636
84/200, train_loss: 1.1707
85/200, train_loss: 0.9885
86/200, train_loss: 1.0258
87/200, train_loss: 0.9280
88/200, train_loss: 1.0195
89/200, train_loss: 1.0696
90/200, train_loss: 0.9287
91/200, train_loss: 1.0579
92/200, train_loss: 0.9874
93/200, train_loss: 0.9985
94/200, train_loss: 0.8976
95/200, train_loss: 0.9001
96/200, train_loss: 1.0064
97/200, train_loss: 1.0741
98/200, train_loss: 0.7733
99/200, train_loss: 1.0405
100/200, train_loss: 0.9654
101/200, train_loss: 1.0490
102/200, train_loss: 1.0513
103/200, train_loss: 0.9432
104/200, train_loss: 1.1898
105/200, train_loss: 1.0742
106/200, train_loss: 1.2081
107/200, train_loss: 1.1090
108/200, train_loss: 0.8947
109/200, train_loss: 0.9918
110/200, train_loss: 1.0614
111/200, train_loss: 1.0865
112/200, train_loss: 0.9094
113/200, train_loss: 1.0765
114/200, train_loss: 0.9704
115/200, train_loss: 0.8707
116/200, train_loss: 1.0120
117/200, train_loss: 0.7763
118/200, train_loss: 0.9511
119/200, train_loss: 1.0409
120/200, train_loss: 0.9040
121/200, train_loss: 0.8889
122/200, train_loss: 1.1264
123/200, train_loss: 0.9160
124/200, train_loss: 1.0806
125/200, train_loss: 1.0662
126/200, train_loss: 1.1104
127/200, train_loss: 0.8445
128/200, train_loss: 0.9611
129/200, train_loss: 1.0415
130/200, train_loss: 1.3029
131/200, train_loss: 1.0709
132/200, train_loss: 0.9980
133/200, train_loss: 1.0134
134/200, train_loss: 0.9834
135/200, train_loss: 1.0821
136/200, train_loss: 1.1710
137/200, train_loss: 0.9488
138/200, train_loss: 1.0010
139/200, train_loss: 0.9334
140/200, train_loss: 1.1075
141/200, train_loss: 0.9861
142/200, train_loss: 1.1457
143/200, train_loss: 1.0954
144/200, train_loss: 0.9309
145/200, train_loss: 0.9963
146/200, train_loss: 1.0501
147/200, train_loss: 1.1429
148/200, train_loss: 0.9765
149/200, train_loss: 1.0280
150/200, train_loss: 0.9236
151/200, train_loss: 0.8843
152/200, train_loss: 0.9666
153/200, train_loss: 0.9567
154/200, train_loss: 0.9561
155/200, train_loss: 0.8955
156/200, train_loss: 1.0708
157/200, train_loss: 0.9686
158/200, train_loss: 1.1752
159/200, train_loss: 1.0237
160/200, train_loss: 0.8252
161/200, train_loss: 1.0651
162/200, train_loss: 1.0093
163/200, train_loss: 0.8745
164/200, train_loss: 1.1322
165/200, train_loss: 1.0582
166/200, train_loss: 1.2106
167/200, train_loss: 0.9688
168/200, train_loss: 1.0240
169/200, train_loss: 1.0810
170/200, train_loss: 0.9595
171/200, train_loss: 1.0263
172/200, train_loss: 1.0922
173/200, train_loss: 1.0365
174/200, train_loss: 1.0876
175/200, train_loss: 0.9820
176/200, train_loss: 1.0339
177/200, train_loss: 0.9915
178/200, train_loss: 0.9534
179/200, train_loss: 1.0389
180/200, train_loss: 1.0583
181/200, train_loss: 1.1047
182/200, train_loss: 0.9777
183/200, train_loss: 0.8805
184/200, train_loss: 1.0350
185/200, train_loss: 1.1170
186/200, train_loss: 1.1613
187/200, train_loss: 1.0654
188/200, train_loss: 1.0520
189/200, train_loss: 1.1356
190/200, train_loss: 0.9657
191/200, train_loss: 1.1699
192/200, train_loss: 1.0095
193/200, train_loss: 0.9061
194/200, train_loss: 0.9348
195/200, train_loss: 0.9116
196/200, train_loss: 1.1832
197/200, train_loss: 0.9314
198/200, train_loss: 0.9290
199/200, train_loss: 1.0293
200/200, train_loss: 0.9408
epoch 13 average loss: 1.0152
saved new best metric model
current epoch: 13 current mean dice: 0.3858 1: 0.3504 2: 0.4238
best mean dice: 0.3858 at epoch: 13
Epoch 13 completed
time consuming of epoch 13 is: 605.4985
----------
Epoch 14/50
1/200, train_loss: 0.9790
2/200, train_loss: 0.9888
3/200, train_loss: 0.9756
4/200, train_loss: 0.9787
5/200, train_loss: 1.1401
6/200, train_loss: 0.8124
7/200, train_loss: 1.0966
8/200, train_loss: 1.1776
9/200, train_loss: 0.9343
10/200, train_loss: 1.1412
11/200, train_loss: 0.8196
12/200, train_loss: 1.0260
13/200, train_loss: 1.1448
14/200, train_loss: 1.0185
15/200, train_loss: 1.0172
16/200, train_loss: 1.0536
17/200, train_loss: 1.0273
18/200, train_loss: 1.0297
19/200, train_loss: 0.9939
20/200, train_loss: 0.8790
21/200, train_loss: 0.9733
22/200, train_loss: 1.0223
23/200, train_loss: 1.1116
24/200, train_loss: 1.2165
25/200, train_loss: 1.0857
26/200, train_loss: 0.9297
27/200, train_loss: 1.0715
28/200, train_loss: 0.9135
29/200, train_loss: 1.0122
30/200, train_loss: 1.1255
31/200, train_loss: 0.8949
32/200, train_loss: 1.0382
33/200, train_loss: 1.0629
34/200, train_loss: 0.9722
35/200, train_loss: 0.9506
36/200, train_loss: 1.1474
37/200, train_loss: 1.0384
38/200, train_loss: 0.9641
39/200, train_loss: 1.0704
40/200, train_loss: 0.9425
41/200, train_loss: 1.1163
42/200, train_loss: 1.0110
43/200, train_loss: 1.0047
44/200, train_loss: 0.9746
45/200, train_loss: 0.9293
46/200, train_loss: 0.9204
47/200, train_loss: 1.0192
48/200, train_loss: 0.9696
49/200, train_loss: 0.9926
50/200, train_loss: 0.9809
51/200, train_loss: 1.1822
52/200, train_loss: 1.2186
53/200, train_loss: 0.9561
54/200, train_loss: 0.8919
55/200, train_loss: 0.8575
56/200, train_loss: 1.1641
57/200, train_loss: 0.9057
58/200, train_loss: 0.8801
59/200, train_loss: 1.0142
60/200, train_loss: 1.0677
61/200, train_loss: 0.9885
62/200, train_loss: 1.0089
63/200, train_loss: 1.0323
64/200, train_loss: 0.9031
65/200, train_loss: 0.8626
66/200, train_loss: 1.0051
67/200, train_loss: 1.0760
68/200, train_loss: 0.9458
69/200, train_loss: 0.8539
70/200, train_loss: 1.2912
71/200, train_loss: 1.0769
72/200, train_loss: 0.9646
73/200, train_loss: 0.9267
74/200, train_loss: 0.8870
75/200, train_loss: 0.9363
76/200, train_loss: 1.1103
77/200, train_loss: 0.9919
78/200, train_loss: 0.8968
79/200, train_loss: 1.0166
80/200, train_loss: 1.0477
81/200, train_loss: 1.1334
82/200, train_loss: 1.0990
83/200, train_loss: 0.9569
84/200, train_loss: 1.0333
85/200, train_loss: 1.0246
86/200, train_loss: 0.9722
87/200, train_loss: 1.0813
88/200, train_loss: 1.2125
89/200, train_loss: 1.1228
90/200, train_loss: 0.9240
91/200, train_loss: 0.9328
92/200, train_loss: 0.9644
93/200, train_loss: 0.9795
94/200, train_loss: 0.9314
95/200, train_loss: 0.8487
96/200, train_loss: 0.9470
97/200, train_loss: 1.0763
98/200, train_loss: 0.9861
99/200, train_loss: 1.1409
100/200, train_loss: 1.1178
101/200, train_loss: 0.9907
102/200, train_loss: 1.0390
103/200, train_loss: 0.9691
104/200, train_loss: 1.0732
105/200, train_loss: 1.0190
106/200, train_loss: 0.9214
107/200, train_loss: 1.0571
108/200, train_loss: 0.9094
109/200, train_loss: 1.0462
110/200, train_loss: 1.0050
111/200, train_loss: 1.0640
112/200, train_loss: 0.8660
113/200, train_loss: 0.9851
114/200, train_loss: 0.9879
115/200, train_loss: 1.1541
116/200, train_loss: 0.9569
117/200, train_loss: 0.9098
118/200, train_loss: 1.0920
119/200, train_loss: 0.8987
120/200, train_loss: 0.9719
121/200, train_loss: 1.0302
122/200, train_loss: 1.0832
123/200, train_loss: 1.0039
124/200, train_loss: 1.0220
125/200, train_loss: 1.0229
126/200, train_loss: 1.0060
127/200, train_loss: 1.0624
128/200, train_loss: 1.0479
129/200, train_loss: 1.1349
130/200, train_loss: 0.9478
131/200, train_loss: 0.9638
132/200, train_loss: 0.9981
133/200, train_loss: 0.8797
134/200, train_loss: 0.9168
135/200, train_loss: 1.0360
136/200, train_loss: 0.9089
137/200, train_loss: 0.9629
138/200, train_loss: 0.9427
139/200, train_loss: 0.9274
140/200, train_loss: 1.1619
141/200, train_loss: 0.8541
142/200, train_loss: 1.2023
143/200, train_loss: 1.0743
144/200, train_loss: 1.0364
145/200, train_loss: 0.9878
146/200, train_loss: 0.9952
147/200, train_loss: 1.1640
148/200, train_loss: 1.0933
149/200, train_loss: 1.1304
150/200, train_loss: 1.0518
151/200, train_loss: 1.0674
152/200, train_loss: 1.1005
153/200, train_loss: 0.8958
154/200, train_loss: 1.1276
155/200, train_loss: 1.0546
156/200, train_loss: 0.9692
157/200, train_loss: 1.0742
158/200, train_loss: 1.0904
159/200, train_loss: 0.9880
160/200, train_loss: 1.1077
161/200, train_loss: 0.9029
162/200, train_loss: 1.1652
163/200, train_loss: 1.1164
164/200, train_loss: 1.0882
165/200, train_loss: 0.9920
166/200, train_loss: 1.0727
167/200, train_loss: 0.8828
168/200, train_loss: 1.0553
169/200, train_loss: 0.9633
170/200, train_loss: 1.1409
171/200, train_loss: 1.0099
172/200, train_loss: 1.1201
173/200, train_loss: 1.0750
174/200, train_loss: 1.0217
175/200, train_loss: 0.8446
176/200, train_loss: 0.8809
177/200, train_loss: 1.0303
178/200, train_loss: 1.2190
179/200, train_loss: 1.0367
180/200, train_loss: 1.0722
181/200, train_loss: 1.0244
182/200, train_loss: 1.2036
183/200, train_loss: 1.0218
184/200, train_loss: 1.2055
185/200, train_loss: 1.0636
186/200, train_loss: 1.1650
187/200, train_loss: 1.0218
188/200, train_loss: 0.9106
189/200, train_loss: 1.0968
190/200, train_loss: 1.0291
191/200, train_loss: 0.9676
192/200, train_loss: 0.9740
193/200, train_loss: 0.8300
194/200, train_loss: 0.9160
195/200, train_loss: 1.1022
196/200, train_loss: 0.9250
197/200, train_loss: 0.9770
198/200, train_loss: 0.8739
199/200, train_loss: 1.1718
200/200, train_loss: 0.8298
epoch 14 average loss: 1.0159
current epoch: 14 current mean dice: 0.3414 1: 0.2954 2: 0.3903
best mean dice: 0.3858 at epoch: 13
Epoch 14 completed
time consuming of epoch 14 is: 583.9616
----------
Epoch 15/50
1/200, train_loss: 0.9835
2/200, train_loss: 0.9924
3/200, train_loss: 1.0985
4/200, train_loss: 1.1217
5/200, train_loss: 1.0164
6/200, train_loss: 1.0566
7/200, train_loss: 1.0114
8/200, train_loss: 1.0323
9/200, train_loss: 1.1687
10/200, train_loss: 1.1981
11/200, train_loss: 1.0192
12/200, train_loss: 0.9426
13/200, train_loss: 0.9262
14/200, train_loss: 1.0742
15/200, train_loss: 1.0198
16/200, train_loss: 1.1772
17/200, train_loss: 0.9303
18/200, train_loss: 1.2243
19/200, train_loss: 0.8799
20/200, train_loss: 1.0730
21/200, train_loss: 0.8938
22/200, train_loss: 1.0605
23/200, train_loss: 1.0009
24/200, train_loss: 0.8476
25/200, train_loss: 0.9634
26/200, train_loss: 0.9259
27/200, train_loss: 1.2114
28/200, train_loss: 0.8679
29/200, train_loss: 0.9985
30/200, train_loss: 1.2655
31/200, train_loss: 0.7929
32/200, train_loss: 1.0134
33/200, train_loss: 1.4047
34/200, train_loss: 0.8782
35/200, train_loss: 0.9241
36/200, train_loss: 0.9991
37/200, train_loss: 1.1114
38/200, train_loss: 0.8830
39/200, train_loss: 0.8543
40/200, train_loss: 0.9212
41/200, train_loss: 0.9206
42/200, train_loss: 0.9433
43/200, train_loss: 1.1560
44/200, train_loss: 1.1269
45/200, train_loss: 0.8070
46/200, train_loss: 0.9446
47/200, train_loss: 1.0029
48/200, train_loss: 1.0908
49/200, train_loss: 0.9377
50/200, train_loss: 0.9934
51/200, train_loss: 1.0102
52/200, train_loss: 1.0055
53/200, train_loss: 1.2673
54/200, train_loss: 1.0162
55/200, train_loss: 1.0889
56/200, train_loss: 1.0508
57/200, train_loss: 1.0000
58/200, train_loss: 0.9448
59/200, train_loss: 0.9744
60/200, train_loss: 0.9389
61/200, train_loss: 1.1306
62/200, train_loss: 0.8165
63/200, train_loss: 0.9840
64/200, train_loss: 1.0819
65/200, train_loss: 1.0585
66/200, train_loss: 1.0721
67/200, train_loss: 0.9453
68/200, train_loss: 0.8965
69/200, train_loss: 1.0213
70/200, train_loss: 0.8789
71/200, train_loss: 0.8750
72/200, train_loss: 1.1569
73/200, train_loss: 0.9792
74/200, train_loss: 1.1245
75/200, train_loss: 1.1772
76/200, train_loss: 0.9629
77/200, train_loss: 0.9536
78/200, train_loss: 0.8750
79/200, train_loss: 0.9055
80/200, train_loss: 1.0570
81/200, train_loss: 0.8344
82/200, train_loss: 0.8621
83/200, train_loss: 1.1956
84/200, train_loss: 1.0385
85/200, train_loss: 1.0612
86/200, train_loss: 1.1782
87/200, train_loss: 0.9565
88/200, train_loss: 1.0404
89/200, train_loss: 0.9714
90/200, train_loss: 0.9114
91/200, train_loss: 1.1008
92/200, train_loss: 1.1524
93/200, train_loss: 0.9821
94/200, train_loss: 1.1074
95/200, train_loss: 1.0578
96/200, train_loss: 1.0253
97/200, train_loss: 0.9743
98/200, train_loss: 1.0993
99/200, train_loss: 0.8410
100/200, train_loss: 1.0999
101/200, train_loss: 1.0288
102/200, train_loss: 0.8243
103/200, train_loss: 1.0537
104/200, train_loss: 0.9374
105/200, train_loss: 0.8377
106/200, train_loss: 0.9627
107/200, train_loss: 1.0544
108/200, train_loss: 0.9987
109/200, train_loss: 0.9911
110/200, train_loss: 0.9524
111/200, train_loss: 1.2001
112/200, train_loss: 1.0173
113/200, train_loss: 0.9653
114/200, train_loss: 0.9318
115/200, train_loss: 0.9394
116/200, train_loss: 1.0769
117/200, train_loss: 0.9806
118/200, train_loss: 1.1976
119/200, train_loss: 1.1137
120/200, train_loss: 1.1247
121/200, train_loss: 0.9635
122/200, train_loss: 1.0226
123/200, train_loss: 0.8346
124/200, train_loss: 1.0091
125/200, train_loss: 1.1126
126/200, train_loss: 1.0717
127/200, train_loss: 0.9521
128/200, train_loss: 1.0787
129/200, train_loss: 0.9172
130/200, train_loss: 1.1845
131/200, train_loss: 0.9112
132/200, train_loss: 0.9989
133/200, train_loss: 0.9928
134/200, train_loss: 1.0027
135/200, train_loss: 0.9337
136/200, train_loss: 1.0649
137/200, train_loss: 0.9750
138/200, train_loss: 1.0704
139/200, train_loss: 0.8166
140/200, train_loss: 0.9730
141/200, train_loss: 1.0648
142/200, train_loss: 1.0077
143/200, train_loss: 1.1244
144/200, train_loss: 1.1726
145/200, train_loss: 1.0122
146/200, train_loss: 0.9812
147/200, train_loss: 0.9920
148/200, train_loss: 0.9169
149/200, train_loss: 1.1320
150/200, train_loss: 0.9129
151/200, train_loss: 0.9420
152/200, train_loss: 0.9278
153/200, train_loss: 1.2030
154/200, train_loss: 0.8466
155/200, train_loss: 1.0033
156/200, train_loss: 0.9774
157/200, train_loss: 0.9454
158/200, train_loss: 1.0184
159/200, train_loss: 1.0374
160/200, train_loss: 0.9652
161/200, train_loss: 0.8079
162/200, train_loss: 0.9028
163/200, train_loss: 0.9869
164/200, train_loss: 1.0397
165/200, train_loss: 0.8534
166/200, train_loss: 0.9646
167/200, train_loss: 1.0576
168/200, train_loss: 0.9432
169/200, train_loss: 1.1159
170/200, train_loss: 0.8395
171/200, train_loss: 1.0894
172/200, train_loss: 1.0668
173/200, train_loss: 0.8908
174/200, train_loss: 0.9112
175/200, train_loss: 1.0769
176/200, train_loss: 0.9127
177/200, train_loss: 1.0356
178/200, train_loss: 0.9132
179/200, train_loss: 0.9332
180/200, train_loss: 1.2091
181/200, train_loss: 1.1071
182/200, train_loss: 1.0124
183/200, train_loss: 1.0667
184/200, train_loss: 0.9002
185/200, train_loss: 1.0190
186/200, train_loss: 1.0267
187/200, train_loss: 0.8922
188/200, train_loss: 1.0372
189/200, train_loss: 0.8995
190/200, train_loss: 0.9735
191/200, train_loss: 0.9442
192/200, train_loss: 1.0154
193/200, train_loss: 1.0353
194/200, train_loss: 1.0031
195/200, train_loss: 0.9212
196/200, train_loss: 0.9992
197/200, train_loss: 1.0435
198/200, train_loss: 1.0733
199/200, train_loss: 1.0019
200/200, train_loss: 1.0462
epoch 15 average loss: 1.0063
current epoch: 15 current mean dice: 0.3675 1: 0.3585 2: 0.3776
best mean dice: 0.3858 at epoch: 13
Epoch 15 completed
time consuming of epoch 15 is: 583.9227
----------
Epoch 16/50
1/200, train_loss: 1.0193
2/200, train_loss: 0.9469
3/200, train_loss: 0.9097
4/200, train_loss: 1.0625
5/200, train_loss: 0.9954
6/200, train_loss: 0.9524
7/200, train_loss: 1.0921
8/200, train_loss: 0.9803
9/200, train_loss: 1.0642
10/200, train_loss: 0.9892
11/200, train_loss: 0.8039
12/200, train_loss: 1.0368
13/200, train_loss: 1.1277
14/200, train_loss: 1.0193
15/200, train_loss: 1.0637
16/200, train_loss: 0.8617
17/200, train_loss: 1.0052
18/200, train_loss: 0.9093
19/200, train_loss: 0.9488
20/200, train_loss: 0.7972
21/200, train_loss: 1.2565
22/200, train_loss: 0.9520
23/200, train_loss: 0.9429
24/200, train_loss: 0.9831
25/200, train_loss: 0.8895
26/200, train_loss: 1.0043
27/200, train_loss: 1.0157
28/200, train_loss: 1.1249
29/200, train_loss: 0.9426
30/200, train_loss: 0.9529
31/200, train_loss: 0.8828
32/200, train_loss: 1.0377
33/200, train_loss: 0.7897
34/200, train_loss: 0.9332
35/200, train_loss: 1.0278
36/200, train_loss: 0.9143
37/200, train_loss: 0.9205
38/200, train_loss: 0.9805
39/200, train_loss: 0.9810
40/200, train_loss: 1.0803
41/200, train_loss: 0.9845
42/200, train_loss: 0.9900
43/200, train_loss: 0.9372
44/200, train_loss: 1.1259
45/200, train_loss: 0.9549
46/200, train_loss: 1.0325
47/200, train_loss: 0.8692
48/200, train_loss: 0.9314
49/200, train_loss: 0.8861
50/200, train_loss: 0.9846
51/200, train_loss: 1.0286
52/200, train_loss: 0.7982
53/200, train_loss: 0.9091
54/200, train_loss: 0.9967
55/200, train_loss: 1.0627
56/200, train_loss: 1.2244
57/200, train_loss: 0.9318
58/200, train_loss: 1.0333
59/200, train_loss: 1.0270
60/200, train_loss: 1.2074
61/200, train_loss: 0.9903
62/200, train_loss: 0.9464
63/200, train_loss: 1.2099
64/200, train_loss: 0.9657
65/200, train_loss: 1.0213
66/200, train_loss: 0.9506
67/200, train_loss: 0.9945
68/200, train_loss: 1.0803
69/200, train_loss: 0.8395
70/200, train_loss: 0.8458
71/200, train_loss: 1.0972
72/200, train_loss: 0.9223
73/200, train_loss: 1.0478
74/200, train_loss: 0.8908
75/200, train_loss: 1.0319
76/200, train_loss: 0.8954
77/200, train_loss: 0.9707
78/200, train_loss: 1.1058
79/200, train_loss: 1.0563
80/200, train_loss: 1.1274
81/200, train_loss: 0.9797
82/200, train_loss: 0.8600
83/200, train_loss: 0.8950
84/200, train_loss: 1.1287
85/200, train_loss: 1.0339
86/200, train_loss: 0.9087
87/200, train_loss: 0.8976
88/200, train_loss: 1.1185
89/200, train_loss: 1.1683
90/200, train_loss: 0.9449
91/200, train_loss: 1.1407
92/200, train_loss: 1.1461
93/200, train_loss: 1.1802
94/200, train_loss: 0.9737
95/200, train_loss: 1.1312
96/200, train_loss: 0.8867
97/200, train_loss: 0.9686
98/200, train_loss: 1.1459
99/200, train_loss: 0.9205
100/200, train_loss: 0.9081
101/200, train_loss: 1.0301
102/200, train_loss: 1.1119
103/200, train_loss: 1.0746
104/200, train_loss: 1.0110
105/200, train_loss: 0.9132
106/200, train_loss: 1.0437
107/200, train_loss: 1.0984
108/200, train_loss: 1.1489
109/200, train_loss: 0.9674
110/200, train_loss: 0.9536
111/200, train_loss: 1.0561
112/200, train_loss: 1.0244
113/200, train_loss: 1.2401
114/200, train_loss: 0.8943
115/200, train_loss: 1.1172
116/200, train_loss: 0.8125
117/200, train_loss: 1.1021
118/200, train_loss: 0.9321
119/200, train_loss: 0.9752
120/200, train_loss: 0.9241
121/200, train_loss: 0.9816
122/200, train_loss: 1.1885
123/200, train_loss: 1.0570
124/200, train_loss: 0.9057
125/200, train_loss: 0.9642
126/200, train_loss: 0.9597
127/200, train_loss: 0.8493
128/200, train_loss: 1.0813
129/200, train_loss: 0.9441
130/200, train_loss: 1.0307
131/200, train_loss: 0.9796
132/200, train_loss: 0.9924
133/200, train_loss: 0.8903
134/200, train_loss: 1.0789
135/200, train_loss: 0.8990
136/200, train_loss: 1.0617
137/200, train_loss: 0.9304
138/200, train_loss: 0.9401
139/200, train_loss: 1.0153
140/200, train_loss: 0.9330
141/200, train_loss: 1.0024
142/200, train_loss: 1.1100
143/200, train_loss: 0.9946
144/200, train_loss: 1.0430
145/200, train_loss: 0.8371
146/200, train_loss: 0.9894
147/200, train_loss: 1.1352
148/200, train_loss: 0.8959
149/200, train_loss: 1.0067
150/200, train_loss: 0.9205
151/200, train_loss: 0.8908
152/200, train_loss: 1.0037
153/200, train_loss: 0.9286
154/200, train_loss: 1.1112
155/200, train_loss: 0.8875
156/200, train_loss: 0.9134
157/200, train_loss: 1.0593
158/200, train_loss: 1.1816
159/200, train_loss: 0.9615
160/200, train_loss: 0.8430
161/200, train_loss: 0.9323
162/200, train_loss: 0.9174
163/200, train_loss: 0.9565
164/200, train_loss: 1.1925
165/200, train_loss: 1.0484
166/200, train_loss: 1.0309
167/200, train_loss: 0.8669
168/200, train_loss: 1.0341
169/200, train_loss: 0.8985
170/200, train_loss: 0.9176
171/200, train_loss: 0.9890
172/200, train_loss: 0.9802
173/200, train_loss: 1.0559
174/200, train_loss: 1.0143
175/200, train_loss: 1.0046
176/200, train_loss: 0.9168
177/200, train_loss: 1.0268
178/200, train_loss: 0.8770
179/200, train_loss: 1.0469
180/200, train_loss: 1.2092
181/200, train_loss: 1.2318
182/200, train_loss: 0.9064
183/200, train_loss: 1.0092
184/200, train_loss: 0.9974
185/200, train_loss: 0.8526
186/200, train_loss: 1.0075
187/200, train_loss: 0.9850
188/200, train_loss: 0.9342
189/200, train_loss: 0.7861
190/200, train_loss: 1.1278
191/200, train_loss: 0.9553
192/200, train_loss: 0.9084
193/200, train_loss: 1.0548
194/200, train_loss: 0.9762
195/200, train_loss: 1.0131
196/200, train_loss: 0.9504
197/200, train_loss: 1.0371
198/200, train_loss: 1.0862
199/200, train_loss: 0.9699
200/200, train_loss: 0.8651
epoch 16 average loss: 0.9942
current epoch: 16 current mean dice: 0.3826 1: 0.3076 2: 0.4621
best mean dice: 0.3858 at epoch: 13
Epoch 16 completed
time consuming of epoch 16 is: 581.9438
----------
Epoch 17/50
1/200, train_loss: 1.0732
2/200, train_loss: 0.9152
3/200, train_loss: 1.1404
4/200, train_loss: 1.0670
5/200, train_loss: 0.9434
6/200, train_loss: 0.9704
7/200, train_loss: 1.0710
8/200, train_loss: 0.9560
9/200, train_loss: 0.9646
10/200, train_loss: 0.8002
11/200, train_loss: 1.0245
12/200, train_loss: 1.0437
13/200, train_loss: 1.0936
14/200, train_loss: 1.1401
15/200, train_loss: 0.9902
16/200, train_loss: 1.0091
17/200, train_loss: 0.9925
18/200, train_loss: 0.8987
19/200, train_loss: 0.8428
20/200, train_loss: 0.9075
21/200, train_loss: 0.9337
22/200, train_loss: 0.9894
23/200, train_loss: 0.8578
24/200, train_loss: 0.9836
25/200, train_loss: 0.9190
26/200, train_loss: 1.0895
27/200, train_loss: 1.1382
28/200, train_loss: 0.7946
29/200, train_loss: 1.1520
30/200, train_loss: 1.0561
31/200, train_loss: 1.1326
32/200, train_loss: 0.9220
33/200, train_loss: 0.9705
34/200, train_loss: 1.0869
35/200, train_loss: 0.8026
36/200, train_loss: 0.9453
37/200, train_loss: 0.7587
38/200, train_loss: 1.1433
39/200, train_loss: 0.9768
40/200, train_loss: 1.1219
41/200, train_loss: 0.8993
42/200, train_loss: 1.0223
43/200, train_loss: 1.0536
44/200, train_loss: 0.9513
45/200, train_loss: 0.9428
46/200, train_loss: 0.9713
47/200, train_loss: 1.0912
48/200, train_loss: 0.9871
49/200, train_loss: 0.9718
50/200, train_loss: 0.9229
51/200, train_loss: 1.1420
52/200, train_loss: 0.8743
53/200, train_loss: 1.0176
54/200, train_loss: 1.0606
55/200, train_loss: 0.9860
56/200, train_loss: 0.9746
57/200, train_loss: 0.9556
58/200, train_loss: 0.8333
59/200, train_loss: 0.8860
60/200, train_loss: 0.9730
61/200, train_loss: 0.9537
62/200, train_loss: 1.0602
63/200, train_loss: 0.9615
64/200, train_loss: 1.0258
65/200, train_loss: 1.0215
66/200, train_loss: 1.2269
67/200, train_loss: 1.1784
68/200, train_loss: 1.4636
69/200, train_loss: 0.8153
70/200, train_loss: 0.9585
71/200, train_loss: 1.0180
72/200, train_loss: 0.9542
73/200, train_loss: 1.1135
74/200, train_loss: 1.0049
75/200, train_loss: 1.0657
76/200, train_loss: 1.0929
77/200, train_loss: 1.1511
78/200, train_loss: 1.0833
79/200, train_loss: 0.9568
80/200, train_loss: 0.8315
81/200, train_loss: 0.9371
82/200, train_loss: 0.9371
83/200, train_loss: 1.0133
84/200, train_loss: 0.9709
85/200, train_loss: 0.9802
86/200, train_loss: 1.0081
87/200, train_loss: 1.0603
88/200, train_loss: 1.0372
89/200, train_loss: 1.1018
90/200, train_loss: 0.8898
91/200, train_loss: 0.9838
92/200, train_loss: 0.9273
93/200, train_loss: 1.1127
94/200, train_loss: 1.1900
95/200, train_loss: 0.9778
96/200, train_loss: 1.1135
97/200, train_loss: 1.0052
98/200, train_loss: 1.0024
99/200, train_loss: 1.2915
100/200, train_loss: 0.8745
101/200, train_loss: 0.8046
102/200, train_loss: 0.8692
103/200, train_loss: 0.9911
104/200, train_loss: 0.9409
105/200, train_loss: 1.1459
106/200, train_loss: 0.8997
107/200, train_loss: 1.0574
108/200, train_loss: 1.1087
109/200, train_loss: 1.0852
110/200, train_loss: 0.9966
111/200, train_loss: 1.0392
112/200, train_loss: 0.9564
113/200, train_loss: 1.0244
114/200, train_loss: 0.8984
115/200, train_loss: 0.8326
116/200, train_loss: 1.0265
117/200, train_loss: 1.0015
118/200, train_loss: 1.0127
119/200, train_loss: 1.0419
120/200, train_loss: 0.8301
121/200, train_loss: 0.9165
122/200, train_loss: 0.9472
123/200, train_loss: 1.0312
124/200, train_loss: 0.9587
125/200, train_loss: 1.0930
126/200, train_loss: 1.0325
127/200, train_loss: 0.9705
128/200, train_loss: 1.0341
129/200, train_loss: 0.9517
130/200, train_loss: 1.0740
131/200, train_loss: 0.9747
132/200, train_loss: 0.9369
133/200, train_loss: 1.0018
134/200, train_loss: 1.0293
135/200, train_loss: 1.2031
136/200, train_loss: 0.9397
137/200, train_loss: 0.9928
138/200, train_loss: 0.9441
139/200, train_loss: 1.0319
140/200, train_loss: 1.1409
141/200, train_loss: 1.0417
142/200, train_loss: 1.0475
143/200, train_loss: 1.0598
144/200, train_loss: 1.1376
145/200, train_loss: 0.9252
146/200, train_loss: 1.0540
147/200, train_loss: 1.0009
148/200, train_loss: 1.0023
149/200, train_loss: 0.9714
150/200, train_loss: 1.0748
151/200, train_loss: 1.0590
152/200, train_loss: 0.8322
153/200, train_loss: 1.1726
154/200, train_loss: 1.0810
155/200, train_loss: 1.0552
156/200, train_loss: 1.0264
157/200, train_loss: 1.1568
158/200, train_loss: 0.9866
159/200, train_loss: 1.0858
160/200, train_loss: 0.8680
161/200, train_loss: 0.8647
162/200, train_loss: 1.0301
163/200, train_loss: 1.0969
164/200, train_loss: 1.1420
165/200, train_loss: 1.0413
166/200, train_loss: 0.8973
167/200, train_loss: 0.9436
168/200, train_loss: 0.8983
169/200, train_loss: 0.8447
170/200, train_loss: 0.9518
171/200, train_loss: 0.9520
172/200, train_loss: 0.9055
173/200, train_loss: 1.0030
174/200, train_loss: 1.1195
175/200, train_loss: 0.7998
176/200, train_loss: 1.0610
177/200, train_loss: 0.9084
178/200, train_loss: 1.0088
179/200, train_loss: 1.0237
180/200, train_loss: 0.9979
181/200, train_loss: 1.1585
182/200, train_loss: 1.1311
183/200, train_loss: 0.8908
184/200, train_loss: 0.9188
185/200, train_loss: 0.8406
186/200, train_loss: 1.0316
187/200, train_loss: 1.0422
188/200, train_loss: 1.0701
189/200, train_loss: 0.9767
190/200, train_loss: 1.0640
191/200, train_loss: 1.2008
192/200, train_loss: 1.0024
193/200, train_loss: 0.8217
194/200, train_loss: 0.9791
195/200, train_loss: 0.8895
196/200, train_loss: 0.9006
197/200, train_loss: 0.8756
198/200, train_loss: 1.0477
199/200, train_loss: 0.9982
200/200, train_loss: 0.9896
epoch 17 average loss: 1.0011
current epoch: 17 current mean dice: 0.3798 1: 0.3460 2: 0.4177
best mean dice: 0.3858 at epoch: 13
Epoch 17 completed
time consuming of epoch 17 is: 582.0864
----------
Epoch 18/50
1/200, train_loss: 0.9631
2/200, train_loss: 0.8640
3/200, train_loss: 0.8840
4/200, train_loss: 0.9656
5/200, train_loss: 1.0118
6/200, train_loss: 0.8473
7/200, train_loss: 1.3721
8/200, train_loss: 0.9935
9/200, train_loss: 1.0668
10/200, train_loss: 0.9806
11/200, train_loss: 0.8890
12/200, train_loss: 0.8776
13/200, train_loss: 1.0781
14/200, train_loss: 1.0298
15/200, train_loss: 1.0451
16/200, train_loss: 0.9184
17/200, train_loss: 1.0386
18/200, train_loss: 0.9273
19/200, train_loss: 0.8975
20/200, train_loss: 0.9754
21/200, train_loss: 1.0176
22/200, train_loss: 0.8677
23/200, train_loss: 0.9511
24/200, train_loss: 1.1488
25/200, train_loss: 0.9993
26/200, train_loss: 1.0107
27/200, train_loss: 0.9663
28/200, train_loss: 0.9868
29/200, train_loss: 1.0142
30/200, train_loss: 0.9938
31/200, train_loss: 0.8767
32/200, train_loss: 0.9686
33/200, train_loss: 1.1241
34/200, train_loss: 1.0961
35/200, train_loss: 0.8951
36/200, train_loss: 0.9830
37/200, train_loss: 1.0353
38/200, train_loss: 0.9562
39/200, train_loss: 0.9423
40/200, train_loss: 0.9764
41/200, train_loss: 1.0389
42/200, train_loss: 0.9418
43/200, train_loss: 0.9768
44/200, train_loss: 0.9617
45/200, train_loss: 0.9870
46/200, train_loss: 0.9985
47/200, train_loss: 1.0149
48/200, train_loss: 1.1733
49/200, train_loss: 0.9550
50/200, train_loss: 0.8550
51/200, train_loss: 0.9469
52/200, train_loss: 1.2527
53/200, train_loss: 1.0154
54/200, train_loss: 1.2239
55/200, train_loss: 0.9195
56/200, train_loss: 0.9322
57/200, train_loss: 1.0338
58/200, train_loss: 0.8650
59/200, train_loss: 0.8561
60/200, train_loss: 1.0137
61/200, train_loss: 0.9460
62/200, train_loss: 0.9078
63/200, train_loss: 0.8291
64/200, train_loss: 1.1399
65/200, train_loss: 1.0730
66/200, train_loss: 1.0555
67/200, train_loss: 1.1259
68/200, train_loss: 0.9912
69/200, train_loss: 0.9099
70/200, train_loss: 1.0525
71/200, train_loss: 0.9326
72/200, train_loss: 0.9700
73/200, train_loss: 1.0448
74/200, train_loss: 1.0152
75/200, train_loss: 1.3178
76/200, train_loss: 1.0377
77/200, train_loss: 0.9976
78/200, train_loss: 0.8793
79/200, train_loss: 1.0588
80/200, train_loss: 1.1596
81/200, train_loss: 0.9525
82/200, train_loss: 1.0184
83/200, train_loss: 0.9916
84/200, train_loss: 0.9060
85/200, train_loss: 1.2302
86/200, train_loss: 1.1110
87/200, train_loss: 0.9838
88/200, train_loss: 1.0367
89/200, train_loss: 1.0140
90/200, train_loss: 0.8297
91/200, train_loss: 0.9883
92/200, train_loss: 0.7985
93/200, train_loss: 0.9100
94/200, train_loss: 1.0978
95/200, train_loss: 0.9300
96/200, train_loss: 0.8164
97/200, train_loss: 0.8394
98/200, train_loss: 0.9631
99/200, train_loss: 0.8823
100/200, train_loss: 0.8969
101/200, train_loss: 0.9942
102/200, train_loss: 0.9326
103/200, train_loss: 1.0010
104/200, train_loss: 0.9161
105/200, train_loss: 0.8748
106/200, train_loss: 0.8758
107/200, train_loss: 1.0645
108/200, train_loss: 1.1174
109/200, train_loss: 0.9524
110/200, train_loss: 0.9020
111/200, train_loss: 1.1268
112/200, train_loss: 1.0443
113/200, train_loss: 1.0292
114/200, train_loss: 0.9412
115/200, train_loss: 0.9038
116/200, train_loss: 0.9070
117/200, train_loss: 0.8287
118/200, train_loss: 0.9387
119/200, train_loss: 1.1233
120/200, train_loss: 0.9764
121/200, train_loss: 0.9318
122/200, train_loss: 0.9239
123/200, train_loss: 0.9778
124/200, train_loss: 0.7882
125/200, train_loss: 0.8782
126/200, train_loss: 1.0082
127/200, train_loss: 0.9579
128/200, train_loss: 0.9576
129/200, train_loss: 1.1361
130/200, train_loss: 1.2321
131/200, train_loss: 1.0138
132/200, train_loss: 1.0608
133/200, train_loss: 1.0042
134/200, train_loss: 1.0330
135/200, train_loss: 1.0261
136/200, train_loss: 1.3014
137/200, train_loss: 1.0910
138/200, train_loss: 1.0681
139/200, train_loss: 0.8946
140/200, train_loss: 1.0314
141/200, train_loss: 0.9944
142/200, train_loss: 0.9378
143/200, train_loss: 1.1100
144/200, train_loss: 1.1866
145/200, train_loss: 0.8533
146/200, train_loss: 0.9560
147/200, train_loss: 0.9541
148/200, train_loss: 0.8837
149/200, train_loss: 0.9565
150/200, train_loss: 1.0078
151/200, train_loss: 1.0539
152/200, train_loss: 1.0957
153/200, train_loss: 0.9729
154/200, train_loss: 1.0244
155/200, train_loss: 1.0366
156/200, train_loss: 0.9458
157/200, train_loss: 0.9059
158/200, train_loss: 0.9056
159/200, train_loss: 1.0731
160/200, train_loss: 0.9164
161/200, train_loss: 1.0992
162/200, train_loss: 1.0728
163/200, train_loss: 0.9383
164/200, train_loss: 1.0234
165/200, train_loss: 1.0046
166/200, train_loss: 0.9107
167/200, train_loss: 1.1170
168/200, train_loss: 1.0948
169/200, train_loss: 1.1335
170/200, train_loss: 1.0582
171/200, train_loss: 0.9925
172/200, train_loss: 1.0495
173/200, train_loss: 0.8763
174/200, train_loss: 1.0672
175/200, train_loss: 1.1045
176/200, train_loss: 1.1175
177/200, train_loss: 1.0192
178/200, train_loss: 1.1043
179/200, train_loss: 0.9580
180/200, train_loss: 0.9993
181/200, train_loss: 0.8286
182/200, train_loss: 1.1126
183/200, train_loss: 1.2553
184/200, train_loss: 0.9449
185/200, train_loss: 1.0075
186/200, train_loss: 0.9134
187/200, train_loss: 1.0085
188/200, train_loss: 1.0607
189/200, train_loss: 0.9637
190/200, train_loss: 1.0026
191/200, train_loss: 0.9846
192/200, train_loss: 1.0206
193/200, train_loss: 1.1009
194/200, train_loss: 1.0106
195/200, train_loss: 0.9875
196/200, train_loss: 1.0115
197/200, train_loss: 0.9179
198/200, train_loss: 0.8571
199/200, train_loss: 1.0996
200/200, train_loss: 1.0597
epoch 18 average loss: 0.9973
current epoch: 18 current mean dice: 0.3757 1: 0.3252 2: 0.4312
best mean dice: 0.3858 at epoch: 13
Epoch 18 completed
time consuming of epoch 18 is: 587.7448
----------
Epoch 19/50
1/200, train_loss: 0.8033
2/200, train_loss: 0.9391
3/200, train_loss: 0.8630
4/200, train_loss: 1.0863
5/200, train_loss: 1.1317
6/200, train_loss: 0.8945
7/200, train_loss: 1.0245
8/200, train_loss: 1.0143
9/200, train_loss: 1.0172
10/200, train_loss: 0.9333
11/200, train_loss: 0.9590
12/200, train_loss: 0.9802
13/200, train_loss: 0.8962
14/200, train_loss: 0.9946
15/200, train_loss: 1.1177
16/200, train_loss: 0.9175
17/200, train_loss: 1.1178
18/200, train_loss: 0.9354
19/200, train_loss: 1.2110
20/200, train_loss: 1.0470
21/200, train_loss: 1.0573
22/200, train_loss: 0.8736
23/200, train_loss: 0.9950
24/200, train_loss: 0.9847
25/200, train_loss: 0.9477
26/200, train_loss: 0.8337
27/200, train_loss: 1.1953
28/200, train_loss: 0.8820
29/200, train_loss: 1.0532
30/200, train_loss: 0.8359
31/200, train_loss: 1.1720
32/200, train_loss: 0.8893
33/200, train_loss: 0.8961
34/200, train_loss: 0.9784
35/200, train_loss: 1.0045
36/200, train_loss: 0.8713
37/200, train_loss: 1.0417
38/200, train_loss: 1.1706
39/200, train_loss: 1.0039
40/200, train_loss: 1.0429
41/200, train_loss: 0.8709
42/200, train_loss: 0.9419
43/200, train_loss: 0.9151
44/200, train_loss: 0.9030
45/200, train_loss: 0.9738
46/200, train_loss: 0.9061
47/200, train_loss: 0.9476
48/200, train_loss: 1.0657
49/200, train_loss: 0.9647
50/200, train_loss: 0.9061
51/200, train_loss: 0.8670
52/200, train_loss: 1.1083
53/200, train_loss: 1.0483
54/200, train_loss: 1.0041
55/200, train_loss: 1.0930
56/200, train_loss: 0.8397
57/200, train_loss: 1.1190
58/200, train_loss: 0.9229
59/200, train_loss: 1.0659
60/200, train_loss: 0.9193
61/200, train_loss: 1.0528
62/200, train_loss: 1.1974
63/200, train_loss: 0.9380
64/200, train_loss: 1.2293
65/200, train_loss: 1.0430
66/200, train_loss: 1.0974
67/200, train_loss: 1.1146
68/200, train_loss: 0.9705
69/200, train_loss: 1.0376
70/200, train_loss: 1.1783
71/200, train_loss: 1.0081
72/200, train_loss: 0.8264
73/200, train_loss: 1.1268
74/200, train_loss: 0.9964
75/200, train_loss: 0.9046
76/200, train_loss: 0.9801
77/200, train_loss: 1.1349
78/200, train_loss: 0.9627
79/200, train_loss: 1.0150
80/200, train_loss: 1.0194
81/200, train_loss: 0.8608
82/200, train_loss: 0.9054
83/200, train_loss: 0.8513
84/200, train_loss: 0.9132
85/200, train_loss: 0.9580
86/200, train_loss: 1.0219
87/200, train_loss: 0.8410
88/200, train_loss: 0.9204
89/200, train_loss: 0.8286
90/200, train_loss: 1.1398
91/200, train_loss: 0.9137
92/200, train_loss: 1.1671
93/200, train_loss: 1.0270
94/200, train_loss: 0.9136
95/200, train_loss: 1.0276
96/200, train_loss: 0.8578
97/200, train_loss: 0.9899
98/200, train_loss: 1.0253
99/200, train_loss: 1.0419
100/200, train_loss: 1.0629
101/200, train_loss: 0.9927
102/200, train_loss: 0.9200
103/200, train_loss: 0.9301
104/200, train_loss: 1.0375
105/200, train_loss: 0.9778
106/200, train_loss: 1.0681
107/200, train_loss: 1.0843
108/200, train_loss: 1.0139
109/200, train_loss: 1.1249
110/200, train_loss: 0.9685
111/200, train_loss: 0.7079
112/200, train_loss: 0.9152
113/200, train_loss: 0.9507
114/200, train_loss: 0.9863
115/200, train_loss: 0.8941
116/200, train_loss: 1.0284
117/200, train_loss: 0.8486
118/200, train_loss: 0.9219
119/200, train_loss: 0.8653
120/200, train_loss: 0.9772
121/200, train_loss: 0.9814
122/200, train_loss: 0.9467
123/200, train_loss: 0.9477
124/200, train_loss: 1.0802
125/200, train_loss: 1.1452
126/200, train_loss: 0.8531
127/200, train_loss: 0.8961
128/200, train_loss: 0.9959
129/200, train_loss: 0.8737
130/200, train_loss: 0.9402
131/200, train_loss: 0.8631
132/200, train_loss: 1.0760
133/200, train_loss: 1.1501
134/200, train_loss: 0.8572
135/200, train_loss: 1.0185
136/200, train_loss: 1.2280
137/200, train_loss: 0.9404
138/200, train_loss: 1.0469
139/200, train_loss: 1.1163
140/200, train_loss: 1.0891
141/200, train_loss: 1.0343
142/200, train_loss: 0.8724
143/200, train_loss: 0.9619
144/200, train_loss: 0.7865
145/200, train_loss: 0.8596
146/200, train_loss: 1.1071
147/200, train_loss: 0.9156
148/200, train_loss: 0.9895
149/200, train_loss: 1.1369
150/200, train_loss: 1.1338
151/200, train_loss: 1.1322
152/200, train_loss: 1.0686
153/200, train_loss: 1.2586
154/200, train_loss: 0.8065
155/200, train_loss: 1.0315
156/200, train_loss: 0.9596
157/200, train_loss: 0.8572
158/200, train_loss: 0.8988
159/200, train_loss: 0.8680
160/200, train_loss: 1.1367
161/200, train_loss: 0.9808
162/200, train_loss: 0.8901
163/200, train_loss: 0.9724
164/200, train_loss: 1.0068
165/200, train_loss: 1.0110
166/200, train_loss: 0.9989
167/200, train_loss: 0.9808
168/200, train_loss: 1.2268
169/200, train_loss: 0.9305
170/200, train_loss: 0.9384
171/200, train_loss: 1.1399
172/200, train_loss: 0.9205
173/200, train_loss: 1.1235
174/200, train_loss: 1.1762
175/200, train_loss: 0.9523
176/200, train_loss: 1.0233
177/200, train_loss: 1.0160
178/200, train_loss: 0.8231
179/200, train_loss: 1.0660
180/200, train_loss: 1.0158
181/200, train_loss: 0.8718
182/200, train_loss: 1.1229
183/200, train_loss: 0.9855
184/200, train_loss: 1.0515
185/200, train_loss: 0.9996
186/200, train_loss: 0.9999
187/200, train_loss: 1.0078
188/200, train_loss: 0.9931
189/200, train_loss: 1.0458
190/200, train_loss: 0.7304
191/200, train_loss: 1.0200
192/200, train_loss: 1.0157
193/200, train_loss: 0.9342
194/200, train_loss: 1.0885
195/200, train_loss: 1.1505
196/200, train_loss: 1.0556
197/200, train_loss: 0.9518
198/200, train_loss: 0.9407
199/200, train_loss: 0.8727
200/200, train_loss: 1.0581
epoch 19 average loss: 0.9913
saved new best metric model
current epoch: 19 current mean dice: 0.3868 1: 0.3525 2: 0.4243
best mean dice: 0.3868 at epoch: 19
Epoch 19 completed
time consuming of epoch 19 is: 608.2803
----------
Epoch 20/50
1/200, train_loss: 0.8213
2/200, train_loss: 1.1404
3/200, train_loss: 1.0010
4/200, train_loss: 1.1060
5/200, train_loss: 1.0151
6/200, train_loss: 1.2035
7/200, train_loss: 1.0439
8/200, train_loss: 0.8314
9/200, train_loss: 1.0822
10/200, train_loss: 0.9328
11/200, train_loss: 1.0592
12/200, train_loss: 0.9266
13/200, train_loss: 1.0289
14/200, train_loss: 1.1676
15/200, train_loss: 0.9782
16/200, train_loss: 1.0850
17/200, train_loss: 1.0023
18/200, train_loss: 0.9622
19/200, train_loss: 0.8058
20/200, train_loss: 0.9959
21/200, train_loss: 0.9945
22/200, train_loss: 1.0588
23/200, train_loss: 0.9702
24/200, train_loss: 0.9927
25/200, train_loss: 0.8309
26/200, train_loss: 0.9763
27/200, train_loss: 1.0017
28/200, train_loss: 0.9883
29/200, train_loss: 0.8549
30/200, train_loss: 1.1493
31/200, train_loss: 0.9031
32/200, train_loss: 1.0753
33/200, train_loss: 0.9778
34/200, train_loss: 1.0520
35/200, train_loss: 0.9877
36/200, train_loss: 1.0981
37/200, train_loss: 0.8546
38/200, train_loss: 1.0397
39/200, train_loss: 0.9385
40/200, train_loss: 0.8996
41/200, train_loss: 0.9881
42/200, train_loss: 0.8968
43/200, train_loss: 1.0225
44/200, train_loss: 0.8802
45/200, train_loss: 0.9669
46/200, train_loss: 0.8777
47/200, train_loss: 0.9290
48/200, train_loss: 1.2062
49/200, train_loss: 0.9447
50/200, train_loss: 1.0129
51/200, train_loss: 0.7986
52/200, train_loss: 0.7891
53/200, train_loss: 0.8973
54/200, train_loss: 0.9467
55/200, train_loss: 1.0200
56/200, train_loss: 1.0179
57/200, train_loss: 1.0985
58/200, train_loss: 1.0103
59/200, train_loss: 0.8703
60/200, train_loss: 0.9231
61/200, train_loss: 1.1160
62/200, train_loss: 0.9671
63/200, train_loss: 0.9561
64/200, train_loss: 1.1032
65/200, train_loss: 0.8419
66/200, train_loss: 0.9373
67/200, train_loss: 1.0852
68/200, train_loss: 1.0599
69/200, train_loss: 0.9884
70/200, train_loss: 1.0533
71/200, train_loss: 0.8741
72/200, train_loss: 1.2251
73/200, train_loss: 1.0108
74/200, train_loss: 0.8573
75/200, train_loss: 1.0118
76/200, train_loss: 0.8784
77/200, train_loss: 0.9843
78/200, train_loss: 1.0380
79/200, train_loss: 0.8616
80/200, train_loss: 1.0246
81/200, train_loss: 1.0483
82/200, train_loss: 1.0619
83/200, train_loss: 1.0280
84/200, train_loss: 1.0621
85/200, train_loss: 0.8906
86/200, train_loss: 1.1740
87/200, train_loss: 0.9553
88/200, train_loss: 0.9850
89/200, train_loss: 0.9068
90/200, train_loss: 0.8352
91/200, train_loss: 0.7764
92/200, train_loss: 0.8638
93/200, train_loss: 0.9403
94/200, train_loss: 0.9043
95/200, train_loss: 1.0414
96/200, train_loss: 1.0381
97/200, train_loss: 1.0793
98/200, train_loss: 1.0405
99/200, train_loss: 0.9534
100/200, train_loss: 0.9440
101/200, train_loss: 0.8728
102/200, train_loss: 0.8794
103/200, train_loss: 1.0222
104/200, train_loss: 1.1620
105/200, train_loss: 1.0248
106/200, train_loss: 0.9549
107/200, train_loss: 1.2436
108/200, train_loss: 1.0673
109/200, train_loss: 1.0028
110/200, train_loss: 0.9203
111/200, train_loss: 0.9753
112/200, train_loss: 0.9006
113/200, train_loss: 0.8754
114/200, train_loss: 1.0022
115/200, train_loss: 1.0804
116/200, train_loss: 0.8876
117/200, train_loss: 1.0885
118/200, train_loss: 0.9129
119/200, train_loss: 0.9791
120/200, train_loss: 0.8681
121/200, train_loss: 1.0690
122/200, train_loss: 0.8522
123/200, train_loss: 0.9026
124/200, train_loss: 1.0942
125/200, train_loss: 1.0638
126/200, train_loss: 0.8542
127/200, train_loss: 0.9586
128/200, train_loss: 1.1746
129/200, train_loss: 1.0077
130/200, train_loss: 0.9157
131/200, train_loss: 0.9662
132/200, train_loss: 0.9133
133/200, train_loss: 1.0666
134/200, train_loss: 1.0965
135/200, train_loss: 0.9904
136/200, train_loss: 1.0341
137/200, train_loss: 0.9194
138/200, train_loss: 1.1830
139/200, train_loss: 0.9907
140/200, train_loss: 1.0144
141/200, train_loss: 0.9974
142/200, train_loss: 0.8834
143/200, train_loss: 1.0330
144/200, train_loss: 0.9254
145/200, train_loss: 1.0900
146/200, train_loss: 0.9724
147/200, train_loss: 1.2118
148/200, train_loss: 1.0075
149/200, train_loss: 0.9044
150/200, train_loss: 1.0955
151/200, train_loss: 0.9801
152/200, train_loss: 1.0930
153/200, train_loss: 0.8384
154/200, train_loss: 1.0876
155/200, train_loss: 1.0704
156/200, train_loss: 0.8251
157/200, train_loss: 0.9416
158/200, train_loss: 1.0464
159/200, train_loss: 1.0041
160/200, train_loss: 0.9627
161/200, train_loss: 1.0723
162/200, train_loss: 0.9666
163/200, train_loss: 0.9336
164/200, train_loss: 0.7993
165/200, train_loss: 0.8444
166/200, train_loss: 1.0211
167/200, train_loss: 0.8622
168/200, train_loss: 1.0116
169/200, train_loss: 1.0294
170/200, train_loss: 1.0065
171/200, train_loss: 1.2494
172/200, train_loss: 1.0124
173/200, train_loss: 1.0192
174/200, train_loss: 0.9629
175/200, train_loss: 0.9169
176/200, train_loss: 0.9982
177/200, train_loss: 0.9564
178/200, train_loss: 0.9829
179/200, train_loss: 0.9305
180/200, train_loss: 1.0684
181/200, train_loss: 1.0057
182/200, train_loss: 1.0491
183/200, train_loss: 1.0258
184/200, train_loss: 0.9167
185/200, train_loss: 0.9760
186/200, train_loss: 1.1829
187/200, train_loss: 0.8100
188/200, train_loss: 1.0295
189/200, train_loss: 0.7697
190/200, train_loss: 1.0534
191/200, train_loss: 0.8578
192/200, train_loss: 0.9936
193/200, train_loss: 1.1197
194/200, train_loss: 1.0191
195/200, train_loss: 1.1333
196/200, train_loss: 1.0406
197/200, train_loss: 1.0847
198/200, train_loss: 0.9128
199/200, train_loss: 0.9352
200/200, train_loss: 1.0460
epoch 20 average loss: 0.9885
current epoch: 20 current mean dice: 0.3749 1: 0.3850 2: 0.3656
best mean dice: 0.3868 at epoch: 19
Epoch 20 completed
time consuming of epoch 20 is: 589.6558
----------
Epoch 21/50
1/200, train_loss: 0.9638
2/200, train_loss: 1.0036
3/200, train_loss: 0.9907
4/200, train_loss: 0.9993
5/200, train_loss: 0.9355
6/200, train_loss: 1.0609
7/200, train_loss: 1.0641
8/200, train_loss: 1.0414
9/200, train_loss: 1.0393
10/200, train_loss: 0.9549
11/200, train_loss: 1.1512
12/200, train_loss: 1.0262
13/200, train_loss: 0.9072
14/200, train_loss: 0.9693
15/200, train_loss: 0.9215
16/200, train_loss: 0.8400
17/200, train_loss: 1.0822
18/200, train_loss: 0.8204
19/200, train_loss: 0.8421
20/200, train_loss: 0.8707
21/200, train_loss: 0.8400
22/200, train_loss: 0.8383
23/200, train_loss: 0.8790
24/200, train_loss: 1.0658
25/200, train_loss: 0.9542
26/200, train_loss: 0.8673
27/200, train_loss: 0.9224
28/200, train_loss: 0.8462
29/200, train_loss: 1.0489
30/200, train_loss: 0.9817
31/200, train_loss: 0.9809
32/200, train_loss: 1.0396
33/200, train_loss: 0.9933
34/200, train_loss: 0.9129
35/200, train_loss: 0.9281
36/200, train_loss: 1.1536
37/200, train_loss: 1.0351
38/200, train_loss: 0.8685
39/200, train_loss: 0.8687
40/200, train_loss: 0.9789
41/200, train_loss: 0.8520
42/200, train_loss: 1.1298
43/200, train_loss: 0.9067
44/200, train_loss: 0.9707
45/200, train_loss: 0.8271
46/200, train_loss: 1.1693
47/200, train_loss: 0.9547
48/200, train_loss: 1.0128
49/200, train_loss: 0.9455
50/200, train_loss: 1.0193
51/200, train_loss: 1.0168
52/200, train_loss: 1.0885
53/200, train_loss: 1.1524
54/200, train_loss: 1.0832
55/200, train_loss: 1.0515
56/200, train_loss: 1.1667
57/200, train_loss: 0.9794
58/200, train_loss: 0.8253
59/200, train_loss: 0.9654
60/200, train_loss: 0.8851
61/200, train_loss: 0.9582
62/200, train_loss: 1.0179
63/200, train_loss: 1.0632
64/200, train_loss: 0.9061
65/200, train_loss: 1.0791
66/200, train_loss: 1.1048
67/200, train_loss: 0.9542
68/200, train_loss: 1.0514
69/200, train_loss: 0.9188
70/200, train_loss: 0.9353
71/200, train_loss: 0.9928
72/200, train_loss: 1.0707
73/200, train_loss: 0.8611
74/200, train_loss: 0.8538
75/200, train_loss: 1.1759
76/200, train_loss: 0.9581
77/200, train_loss: 0.9824
78/200, train_loss: 0.9256
79/200, train_loss: 1.2141
80/200, train_loss: 0.9392
81/200, train_loss: 1.0596
82/200, train_loss: 1.0418
83/200, train_loss: 0.9201
84/200, train_loss: 1.0493
85/200, train_loss: 0.9080
86/200, train_loss: 1.0968
87/200, train_loss: 0.9679
88/200, train_loss: 1.1499
89/200, train_loss: 1.0952
90/200, train_loss: 0.9893
91/200, train_loss: 0.9509
92/200, train_loss: 0.9708
93/200, train_loss: 1.1713
94/200, train_loss: 0.8119
95/200, train_loss: 0.9733
96/200, train_loss: 0.8570
97/200, train_loss: 1.1207
98/200, train_loss: 0.8487
99/200, train_loss: 0.9908
100/200, train_loss: 0.9431
101/200, train_loss: 1.0506
102/200, train_loss: 1.0348
103/200, train_loss: 0.7689
104/200, train_loss: 0.9356
105/200, train_loss: 0.9387
106/200, train_loss: 1.0434
107/200, train_loss: 0.9427
108/200, train_loss: 0.9070
109/200, train_loss: 1.2184
110/200, train_loss: 0.9886
111/200, train_loss: 1.1024
112/200, train_loss: 0.9582
113/200, train_loss: 1.1277
114/200, train_loss: 1.1104
115/200, train_loss: 1.1489
116/200, train_loss: 1.0417
117/200, train_loss: 0.9883
118/200, train_loss: 1.2172
119/200, train_loss: 0.8616
120/200, train_loss: 1.1239
121/200, train_loss: 1.1763
122/200, train_loss: 0.9021
123/200, train_loss: 1.0367
124/200, train_loss: 0.9466
125/200, train_loss: 1.1166
126/200, train_loss: 0.9615
127/200, train_loss: 0.9408
128/200, train_loss: 0.9008
129/200, train_loss: 0.9186
130/200, train_loss: 0.8924
131/200, train_loss: 0.8875
132/200, train_loss: 0.7893
133/200, train_loss: 1.0259
134/200, train_loss: 0.9837
135/200, train_loss: 0.8633
136/200, train_loss: 1.2829
137/200, train_loss: 0.9825
138/200, train_loss: 1.1444
139/200, train_loss: 1.0461
140/200, train_loss: 1.0387
141/200, train_loss: 1.0362
142/200, train_loss: 0.8085
143/200, train_loss: 0.9664
144/200, train_loss: 0.9591
145/200, train_loss: 0.9282
146/200, train_loss: 0.9613
147/200, train_loss: 1.0338
148/200, train_loss: 0.9438
149/200, train_loss: 1.0079
150/200, train_loss: 0.9900
151/200, train_loss: 0.9481
152/200, train_loss: 0.9720
153/200, train_loss: 0.8957
154/200, train_loss: 1.0425
155/200, train_loss: 1.1026
156/200, train_loss: 0.9180
157/200, train_loss: 0.9625
158/200, train_loss: 1.0357
159/200, train_loss: 0.9910
160/200, train_loss: 0.9664
161/200, train_loss: 0.9165
162/200, train_loss: 1.0051
163/200, train_loss: 1.0499
164/200, train_loss: 1.1251
165/200, train_loss: 0.9355
166/200, train_loss: 1.1356
167/200, train_loss: 0.8664
168/200, train_loss: 0.9380
169/200, train_loss: 0.9648
170/200, train_loss: 1.0853
171/200, train_loss: 0.8733
172/200, train_loss: 0.9274
173/200, train_loss: 0.8753
174/200, train_loss: 1.0023
175/200, train_loss: 1.1969
176/200, train_loss: 0.9889
177/200, train_loss: 0.9013
178/200, train_loss: 0.8152
179/200, train_loss: 1.1296
180/200, train_loss: 1.0083
181/200, train_loss: 1.0149
182/200, train_loss: 0.9107
183/200, train_loss: 0.9390
184/200, train_loss: 0.9275
185/200, train_loss: 0.7953
186/200, train_loss: 0.8168
187/200, train_loss: 1.0525
188/200, train_loss: 1.1744
189/200, train_loss: 0.9122
190/200, train_loss: 0.8026
191/200, train_loss: 0.8821
192/200, train_loss: 1.0982
193/200, train_loss: 0.9176
194/200, train_loss: 0.9394
195/200, train_loss: 1.0716
196/200, train_loss: 0.9210
197/200, train_loss: 0.9210
198/200, train_loss: 1.0078
199/200, train_loss: 1.0707
200/200, train_loss: 0.9425
epoch 21 average loss: 0.9852
saved new best metric model
current epoch: 21 current mean dice: 0.3910 1: 0.3404 2: 0.4478
best mean dice: 0.3910 at epoch: 21
Epoch 21 completed
time consuming of epoch 21 is: 597.9027
----------
Epoch 22/50
1/200, train_loss: 0.9464
2/200, train_loss: 0.9347
3/200, train_loss: 0.9361
4/200, train_loss: 0.8756
5/200, train_loss: 0.9182
6/200, train_loss: 0.9036
7/200, train_loss: 0.8184
8/200, train_loss: 0.8567
9/200, train_loss: 1.1958
10/200, train_loss: 0.8669
11/200, train_loss: 1.0392
12/200, train_loss: 0.9150
13/200, train_loss: 1.1521
14/200, train_loss: 1.2056
15/200, train_loss: 1.0054
16/200, train_loss: 1.0664
17/200, train_loss: 0.9806
18/200, train_loss: 1.0920
19/200, train_loss: 0.9343
20/200, train_loss: 1.0452
21/200, train_loss: 0.8934
22/200, train_loss: 1.1433
23/200, train_loss: 0.8036
24/200, train_loss: 0.9967
25/200, train_loss: 0.7317
26/200, train_loss: 0.8913
27/200, train_loss: 1.0531
28/200, train_loss: 1.0832
29/200, train_loss: 0.8790
30/200, train_loss: 1.2280
31/200, train_loss: 0.9561
32/200, train_loss: 1.0917
33/200, train_loss: 1.0658
34/200, train_loss: 1.0696
35/200, train_loss: 0.7935
36/200, train_loss: 1.2373
37/200, train_loss: 0.9279
38/200, train_loss: 0.9642
39/200, train_loss: 0.8487
40/200, train_loss: 0.8924
41/200, train_loss: 0.9523
42/200, train_loss: 0.9506
43/200, train_loss: 0.9819
44/200, train_loss: 0.9394
45/200, train_loss: 0.9232
46/200, train_loss: 1.0617
47/200, train_loss: 0.9522
48/200, train_loss: 0.8674
49/200, train_loss: 1.1172
50/200, train_loss: 0.9413
51/200, train_loss: 0.9710
52/200, train_loss: 0.9988
53/200, train_loss: 1.1046
54/200, train_loss: 0.8947
55/200, train_loss: 0.9263
56/200, train_loss: 0.8757
57/200, train_loss: 1.0177
58/200, train_loss: 0.8051
59/200, train_loss: 1.0038
60/200, train_loss: 0.8514
61/200, train_loss: 0.9267
62/200, train_loss: 1.0083
63/200, train_loss: 1.0113
64/200, train_loss: 0.8354
65/200, train_loss: 0.9115
66/200, train_loss: 1.0695
67/200, train_loss: 1.0547
68/200, train_loss: 1.0337
69/200, train_loss: 0.7884
70/200, train_loss: 1.0229
71/200, train_loss: 1.0754
72/200, train_loss: 1.0683
73/200, train_loss: 0.8567
74/200, train_loss: 0.9743
75/200, train_loss: 1.0269
76/200, train_loss: 0.9071
77/200, train_loss: 0.9437
78/200, train_loss: 1.0809
79/200, train_loss: 1.0832
80/200, train_loss: 1.1131
81/200, train_loss: 0.8591
82/200, train_loss: 1.0216
83/200, train_loss: 0.8282
84/200, train_loss: 1.0269
85/200, train_loss: 1.0524
86/200, train_loss: 1.0063
87/200, train_loss: 1.0003
88/200, train_loss: 0.8714
89/200, train_loss: 1.1709
90/200, train_loss: 0.9566
91/200, train_loss: 1.0447
92/200, train_loss: 0.9936
93/200, train_loss: 0.9858
94/200, train_loss: 0.8221
95/200, train_loss: 0.9094
96/200, train_loss: 1.1314
97/200, train_loss: 1.0334
98/200, train_loss: 1.0974
99/200, train_loss: 1.0824
100/200, train_loss: 1.1418
101/200, train_loss: 0.9086
102/200, train_loss: 1.1129
103/200, train_loss: 1.0245
104/200, train_loss: 0.8800
105/200, train_loss: 0.9910
106/200, train_loss: 0.8962
107/200, train_loss: 1.0409
108/200, train_loss: 0.8334
109/200, train_loss: 0.9399
110/200, train_loss: 1.1015
111/200, train_loss: 1.0120
112/200, train_loss: 1.0033
113/200, train_loss: 0.9011
114/200, train_loss: 1.0733
115/200, train_loss: 0.8573
116/200, train_loss: 0.9069
117/200, train_loss: 1.0756
118/200, train_loss: 1.0198
119/200, train_loss: 0.9843
120/200, train_loss: 0.9974
121/200, train_loss: 1.0551
122/200, train_loss: 0.9337
123/200, train_loss: 1.1208
124/200, train_loss: 0.8748
125/200, train_loss: 0.8371
126/200, train_loss: 0.9533
127/200, train_loss: 1.1568
128/200, train_loss: 0.9345
129/200, train_loss: 0.8858
130/200, train_loss: 1.0854
131/200, train_loss: 1.2145
132/200, train_loss: 0.8829
133/200, train_loss: 1.0647
134/200, train_loss: 1.0705
135/200, train_loss: 1.1243
136/200, train_loss: 1.0419
137/200, train_loss: 0.9206
138/200, train_loss: 1.1031
139/200, train_loss: 1.0665
140/200, train_loss: 1.0112
141/200, train_loss: 0.9829
142/200, train_loss: 0.9233
143/200, train_loss: 0.9997
144/200, train_loss: 0.8561
145/200, train_loss: 0.9633
146/200, train_loss: 1.2219
147/200, train_loss: 1.2189
148/200, train_loss: 0.9960
149/200, train_loss: 0.8664
150/200, train_loss: 1.0208
151/200, train_loss: 0.8969
152/200, train_loss: 0.9071
153/200, train_loss: 1.0252
154/200, train_loss: 1.0427
155/200, train_loss: 1.0271
156/200, train_loss: 0.9454
157/200, train_loss: 1.1079
158/200, train_loss: 1.0037
159/200, train_loss: 1.0404
160/200, train_loss: 0.7536
161/200, train_loss: 1.1250
162/200, train_loss: 0.9062
163/200, train_loss: 1.0028
164/200, train_loss: 0.9422
165/200, train_loss: 0.9354
166/200, train_loss: 1.0383
167/200, train_loss: 1.0615
168/200, train_loss: 0.9310
169/200, train_loss: 1.1319
170/200, train_loss: 0.9939
171/200, train_loss: 1.0246
172/200, train_loss: 0.9759
173/200, train_loss: 1.0125
174/200, train_loss: 1.1085
175/200, train_loss: 1.1432
176/200, train_loss: 1.0384
177/200, train_loss: 1.0508
178/200, train_loss: 0.8841
179/200, train_loss: 1.0250
180/200, train_loss: 1.2759
181/200, train_loss: 0.9227
182/200, train_loss: 0.8400
183/200, train_loss: 1.0723
184/200, train_loss: 0.8943
185/200, train_loss: 0.9407
186/200, train_loss: 0.9896
187/200, train_loss: 0.9481
188/200, train_loss: 1.1056
189/200, train_loss: 1.2101
190/200, train_loss: 1.0626
191/200, train_loss: 1.0446
192/200, train_loss: 0.9864
193/200, train_loss: 1.2616
194/200, train_loss: 0.9090
195/200, train_loss: 1.0328
196/200, train_loss: 0.9426
197/200, train_loss: 0.7836
198/200, train_loss: 0.8727
199/200, train_loss: 0.9524
200/200, train_loss: 0.9257
epoch 22 average loss: 0.9910
current epoch: 22 current mean dice: 0.3891 1: 0.3331 2: 0.4489
best mean dice: 0.3910 at epoch: 21
Epoch 22 completed
time consuming of epoch 22 is: 577.3802
----------
Epoch 23/50
1/200, train_loss: 0.9836
2/200, train_loss: 0.9069
3/200, train_loss: 1.0316
4/200, train_loss: 0.9963
5/200, train_loss: 0.9238
6/200, train_loss: 0.8944
7/200, train_loss: 0.9642
8/200, train_loss: 1.1210
9/200, train_loss: 0.8789
10/200, train_loss: 0.9408
11/200, train_loss: 1.0506
12/200, train_loss: 0.9147
13/200, train_loss: 0.9835
14/200, train_loss: 1.0442
15/200, train_loss: 0.9648
16/200, train_loss: 0.9068
17/200, train_loss: 0.8405
18/200, train_loss: 1.0582
19/200, train_loss: 0.9638
20/200, train_loss: 1.0756
21/200, train_loss: 1.1416
22/200, train_loss: 1.0762
23/200, train_loss: 0.8784
24/200, train_loss: 0.9224
25/200, train_loss: 1.2200
26/200, train_loss: 0.9965
27/200, train_loss: 1.0851
28/200, train_loss: 0.7682
29/200, train_loss: 1.0822
30/200, train_loss: 0.9056
31/200, train_loss: 1.0181
32/200, train_loss: 0.7962
33/200, train_loss: 1.0257
34/200, train_loss: 0.9878
35/200, train_loss: 1.1278
36/200, train_loss: 1.0281
37/200, train_loss: 1.0815
38/200, train_loss: 0.8978
39/200, train_loss: 0.9226
40/200, train_loss: 0.9619
41/200, train_loss: 0.9208
42/200, train_loss: 0.9909
43/200, train_loss: 0.9798
44/200, train_loss: 0.8695
45/200, train_loss: 0.8510
46/200, train_loss: 1.1577
47/200, train_loss: 0.9105
48/200, train_loss: 0.8251
49/200, train_loss: 1.1153
50/200, train_loss: 0.8401
51/200, train_loss: 1.0186
52/200, train_loss: 1.0539
53/200, train_loss: 0.9451
54/200, train_loss: 0.9186
55/200, train_loss: 1.0132
56/200, train_loss: 0.9486
57/200, train_loss: 0.9973
58/200, train_loss: 0.9603
59/200, train_loss: 1.0567
60/200, train_loss: 1.0330
61/200, train_loss: 1.0044
62/200, train_loss: 1.0092
63/200, train_loss: 0.9024
64/200, train_loss: 1.0117
65/200, train_loss: 1.0430
66/200, train_loss: 1.0045
67/200, train_loss: 1.1463
68/200, train_loss: 0.9286
69/200, train_loss: 0.8732
70/200, train_loss: 0.8113
71/200, train_loss: 1.0667
72/200, train_loss: 1.0876
73/200, train_loss: 1.1992
74/200, train_loss: 1.0081
75/200, train_loss: 0.9548
76/200, train_loss: 0.8549
77/200, train_loss: 0.9104
78/200, train_loss: 0.9024
79/200, train_loss: 1.0166
80/200, train_loss: 1.0905
81/200, train_loss: 0.8384
82/200, train_loss: 1.0800
83/200, train_loss: 0.8915
84/200, train_loss: 1.1424
85/200, train_loss: 0.8717
86/200, train_loss: 1.0851
87/200, train_loss: 1.0895
88/200, train_loss: 0.9461
89/200, train_loss: 0.9256
90/200, train_loss: 0.9502
91/200, train_loss: 0.9902
92/200, train_loss: 0.8625
93/200, train_loss: 0.8854
94/200, train_loss: 1.1072
95/200, train_loss: 0.8725
96/200, train_loss: 1.0503
97/200, train_loss: 0.8868
98/200, train_loss: 0.8237
99/200, train_loss: 1.0285
100/200, train_loss: 0.8819
101/200, train_loss: 0.9618
102/200, train_loss: 1.0985
103/200, train_loss: 0.9883
104/200, train_loss: 1.1352
105/200, train_loss: 1.1434
106/200, train_loss: 1.0451
107/200, train_loss: 0.8818
108/200, train_loss: 0.9409
109/200, train_loss: 1.0627
110/200, train_loss: 0.9349
111/200, train_loss: 0.9273
112/200, train_loss: 1.1013
113/200, train_loss: 0.8078
114/200, train_loss: 1.0555
115/200, train_loss: 0.9870
116/200, train_loss: 0.8943
117/200, train_loss: 0.8587
118/200, train_loss: 1.0312
119/200, train_loss: 1.0199
120/200, train_loss: 1.0683
121/200, train_loss: 0.8794
122/200, train_loss: 0.9536
123/200, train_loss: 0.9947
124/200, train_loss: 0.8253
125/200, train_loss: 1.0575
126/200, train_loss: 0.9932
127/200, train_loss: 1.0812
128/200, train_loss: 1.0398
129/200, train_loss: 0.8769
130/200, train_loss: 0.8946
131/200, train_loss: 1.1305
132/200, train_loss: 1.0388
133/200, train_loss: 1.1485
134/200, train_loss: 0.9513
135/200, train_loss: 0.8968
136/200, train_loss: 0.8862
137/200, train_loss: 1.1511
138/200, train_loss: 0.8426
139/200, train_loss: 0.9492
140/200, train_loss: 1.0153
141/200, train_loss: 0.9374
142/200, train_loss: 0.8106
143/200, train_loss: 0.8017
144/200, train_loss: 1.0601
145/200, train_loss: 0.8776
146/200, train_loss: 0.9374
147/200, train_loss: 1.0070
148/200, train_loss: 0.9911
149/200, train_loss: 0.9882
150/200, train_loss: 1.0047
151/200, train_loss: 0.8505
152/200, train_loss: 1.0214
153/200, train_loss: 0.8803
154/200, train_loss: 1.1316
155/200, train_loss: 1.0119
156/200, train_loss: 1.0848
157/200, train_loss: 0.8961
158/200, train_loss: 0.9046
159/200, train_loss: 0.9701
160/200, train_loss: 1.0625
161/200, train_loss: 1.0610
162/200, train_loss: 0.9531
163/200, train_loss: 0.9423
164/200, train_loss: 0.8269
165/200, train_loss: 0.9566
166/200, train_loss: 1.2821
167/200, train_loss: 1.0901
168/200, train_loss: 0.8813
169/200, train_loss: 0.8841
170/200, train_loss: 1.0860
171/200, train_loss: 1.0585
172/200, train_loss: 1.1266
173/200, train_loss: 0.9022
174/200, train_loss: 0.9972
175/200, train_loss: 0.9036
176/200, train_loss: 1.0434
177/200, train_loss: 0.9157
178/200, train_loss: 0.9219
179/200, train_loss: 1.0131
180/200, train_loss: 1.0016
181/200, train_loss: 0.8803
182/200, train_loss: 1.0783
183/200, train_loss: 0.8504
184/200, train_loss: 1.0791
185/200, train_loss: 0.8908
186/200, train_loss: 0.9337
187/200, train_loss: 0.8683
188/200, train_loss: 0.9548
189/200, train_loss: 0.8680
190/200, train_loss: 1.0060
191/200, train_loss: 0.8880
192/200, train_loss: 0.8505
193/200, train_loss: 0.8801
194/200, train_loss: 1.0333
195/200, train_loss: 0.9011
196/200, train_loss: 1.1014
197/200, train_loss: 1.0222
198/200, train_loss: 0.8346
199/200, train_loss: 0.8096
200/200, train_loss: 0.8623
epoch 23 average loss: 0.9751
current epoch: 23 current mean dice: 0.3766 1: 0.3423 2: 0.4140
best mean dice: 0.3910 at epoch: 21
Epoch 23 completed
time consuming of epoch 23 is: 588.1517
----------
Epoch 24/50
1/200, train_loss: 0.8091
2/200, train_loss: 1.0199
3/200, train_loss: 0.9030
4/200, train_loss: 1.1506
5/200, train_loss: 0.9399
6/200, train_loss: 1.1670
7/200, train_loss: 1.2188
8/200, train_loss: 0.9263
9/200, train_loss: 0.9872
10/200, train_loss: 0.9121
11/200, train_loss: 1.0544
12/200, train_loss: 0.9841
13/200, train_loss: 1.1996
14/200, train_loss: 0.7729
15/200, train_loss: 0.8487
16/200, train_loss: 1.0092
17/200, train_loss: 1.0811
18/200, train_loss: 0.9423
19/200, train_loss: 1.0728
20/200, train_loss: 1.1221
21/200, train_loss: 1.0115
22/200, train_loss: 0.8936
23/200, train_loss: 0.8156
24/200, train_loss: 0.9944
25/200, train_loss: 0.9474
26/200, train_loss: 0.8281
27/200, train_loss: 0.8862
28/200, train_loss: 1.0180
29/200, train_loss: 0.8437
30/200, train_loss: 0.8925
31/200, train_loss: 1.0270
32/200, train_loss: 1.0840
33/200, train_loss: 0.7214
34/200, train_loss: 1.0772
35/200, train_loss: 0.9653
36/200, train_loss: 1.1692
37/200, train_loss: 1.0462
38/200, train_loss: 0.7422
39/200, train_loss: 1.0894
40/200, train_loss: 1.1233
41/200, train_loss: 1.0445
42/200, train_loss: 1.0847
43/200, train_loss: 0.8872
44/200, train_loss: 1.0900
45/200, train_loss: 1.0401
46/200, train_loss: 1.1210
47/200, train_loss: 0.9657
48/200, train_loss: 0.9795
49/200, train_loss: 0.8704
50/200, train_loss: 1.0282
51/200, train_loss: 0.9728
52/200, train_loss: 1.0657
53/200, train_loss: 0.9433
54/200, train_loss: 1.0821
55/200, train_loss: 1.1037
56/200, train_loss: 1.0024
57/200, train_loss: 0.8787
58/200, train_loss: 1.0496
59/200, train_loss: 1.0634
60/200, train_loss: 1.0328
61/200, train_loss: 1.0265
62/200, train_loss: 0.7653
63/200, train_loss: 0.9274
64/200, train_loss: 0.9542
65/200, train_loss: 0.9654
66/200, train_loss: 1.2158
67/200, train_loss: 1.0681
68/200, train_loss: 0.8369
69/200, train_loss: 0.9732
70/200, train_loss: 0.8288
71/200, train_loss: 1.0933
72/200, train_loss: 0.8852
73/200, train_loss: 0.9912
74/200, train_loss: 1.1055
75/200, train_loss: 1.1582
76/200, train_loss: 0.9877
77/200, train_loss: 0.8556
78/200, train_loss: 0.9400
79/200, train_loss: 1.0938
80/200, train_loss: 1.1291
81/200, train_loss: 0.8740
82/200, train_loss: 0.7852
83/200, train_loss: 0.9109
84/200, train_loss: 0.8732
85/200, train_loss: 0.9213
86/200, train_loss: 0.8524
87/200, train_loss: 0.8080
88/200, train_loss: 1.0129
89/200, train_loss: 0.9889
90/200, train_loss: 1.0388
91/200, train_loss: 1.0884
92/200, train_loss: 1.0747
93/200, train_loss: 0.7628
94/200, train_loss: 1.1193
95/200, train_loss: 0.8724
96/200, train_loss: 0.9815
97/200, train_loss: 1.0199
98/200, train_loss: 1.0675
99/200, train_loss: 1.0582
100/200, train_loss: 0.8942
101/200, train_loss: 0.9803
102/200, train_loss: 0.8964
103/200, train_loss: 0.9865
104/200, train_loss: 1.0198
105/200, train_loss: 1.0445
106/200, train_loss: 1.1290
107/200, train_loss: 0.8864
108/200, train_loss: 0.9098
109/200, train_loss: 1.0631
110/200, train_loss: 0.9065
111/200, train_loss: 1.0338
112/200, train_loss: 0.9039
113/200, train_loss: 0.8123
114/200, train_loss: 1.0786
115/200, train_loss: 0.7764
116/200, train_loss: 0.9364
117/200, train_loss: 1.0029
118/200, train_loss: 0.9802
119/200, train_loss: 1.2368
120/200, train_loss: 0.9075
121/200, train_loss: 1.0431
122/200, train_loss: 0.9217
123/200, train_loss: 1.1422
124/200, train_loss: 0.9373
125/200, train_loss: 1.0580
126/200, train_loss: 1.0856
127/200, train_loss: 1.0046
128/200, train_loss: 0.9941
129/200, train_loss: 0.9091
130/200, train_loss: 1.0376
131/200, train_loss: 0.8885
132/200, train_loss: 0.8773
133/200, train_loss: 0.8901
134/200, train_loss: 1.1176
135/200, train_loss: 0.9340
136/200, train_loss: 0.9068
137/200, train_loss: 1.0516
138/200, train_loss: 0.8277
139/200, train_loss: 1.0833
140/200, train_loss: 0.9656
141/200, train_loss: 0.9064
142/200, train_loss: 1.0897
143/200, train_loss: 1.0170
144/200, train_loss: 0.8983
145/200, train_loss: 1.0722
146/200, train_loss: 1.1574
147/200, train_loss: 0.9370
148/200, train_loss: 1.0015
149/200, train_loss: 0.9055
150/200, train_loss: 0.9616
151/200, train_loss: 0.8303
152/200, train_loss: 0.9630
153/200, train_loss: 0.8426
154/200, train_loss: 0.8060
155/200, train_loss: 0.8942
156/200, train_loss: 1.0353
157/200, train_loss: 0.9969
158/200, train_loss: 0.9032
159/200, train_loss: 0.9950
160/200, train_loss: 1.0850
161/200, train_loss: 0.8869
162/200, train_loss: 1.2086
163/200, train_loss: 0.7952
164/200, train_loss: 0.9269
165/200, train_loss: 1.1905
166/200, train_loss: 0.9797
167/200, train_loss: 1.0213
168/200, train_loss: 0.8281
169/200, train_loss: 0.8698
170/200, train_loss: 1.0660
171/200, train_loss: 1.0364
172/200, train_loss: 1.0506
173/200, train_loss: 0.9118
174/200, train_loss: 0.9572
175/200, train_loss: 0.8977
176/200, train_loss: 1.0718
177/200, train_loss: 0.8854
178/200, train_loss: 1.0546
179/200, train_loss: 1.0244
180/200, train_loss: 1.0476
181/200, train_loss: 0.9420
182/200, train_loss: 1.0860
183/200, train_loss: 0.8657
184/200, train_loss: 0.8986
185/200, train_loss: 1.0411
186/200, train_loss: 0.9782
187/200, train_loss: 0.9310
188/200, train_loss: 0.8977
189/200, train_loss: 0.9374
190/200, train_loss: 0.9686
191/200, train_loss: 1.0022
192/200, train_loss: 1.0041
193/200, train_loss: 1.0193
194/200, train_loss: 0.9803
195/200, train_loss: 1.0898
196/200, train_loss: 1.0696
197/200, train_loss: 0.9347
198/200, train_loss: 0.9548
199/200, train_loss: 1.0085
200/200, train_loss: 0.8565
epoch 24 average loss: 0.9803
current epoch: 24 current mean dice: 0.3909 1: 0.3542 2: 0.4323
best mean dice: 0.3910 at epoch: 21
Epoch 24 completed
time consuming of epoch 24 is: 590.2499
----------
Epoch 25/50
1/200, train_loss: 0.8690
2/200, train_loss: 1.0763
3/200, train_loss: 0.9038
4/200, train_loss: 0.8121
5/200, train_loss: 0.8749
6/200, train_loss: 0.9487
7/200, train_loss: 0.9283
8/200, train_loss: 1.0541
9/200, train_loss: 0.9586
10/200, train_loss: 0.8936
11/200, train_loss: 1.0608
12/200, train_loss: 1.0154
13/200, train_loss: 0.9762
14/200, train_loss: 1.0250
15/200, train_loss: 1.0606
16/200, train_loss: 1.0015
17/200, train_loss: 1.0246
18/200, train_loss: 0.8346
19/200, train_loss: 0.9730
20/200, train_loss: 0.9013
21/200, train_loss: 0.7579
22/200, train_loss: 0.9667
23/200, train_loss: 1.0418
24/200, train_loss: 0.9779
25/200, train_loss: 1.0038
26/200, train_loss: 1.0162
27/200, train_loss: 1.0231
28/200, train_loss: 1.0236
29/200, train_loss: 0.8370
30/200, train_loss: 1.0128
31/200, train_loss: 0.8942
32/200, train_loss: 1.0313
33/200, train_loss: 1.0304
34/200, train_loss: 0.8542
35/200, train_loss: 1.1074
36/200, train_loss: 1.0529
37/200, train_loss: 0.9123
38/200, train_loss: 1.1216
39/200, train_loss: 0.8879
40/200, train_loss: 0.7962
41/200, train_loss: 0.8573
42/200, train_loss: 1.0543
43/200, train_loss: 1.1010
44/200, train_loss: 0.9923
45/200, train_loss: 0.9486
46/200, train_loss: 1.1735
47/200, train_loss: 0.9802
48/200, train_loss: 0.9310
49/200, train_loss: 1.0056
50/200, train_loss: 0.9267
51/200, train_loss: 0.9332
52/200, train_loss: 1.0432
53/200, train_loss: 0.9191
54/200, train_loss: 1.0210
55/200, train_loss: 1.0110
56/200, train_loss: 1.0100
57/200, train_loss: 0.8537
58/200, train_loss: 0.9674
59/200, train_loss: 0.8866
60/200, train_loss: 0.9895
61/200, train_loss: 0.7849
62/200, train_loss: 1.0077
63/200, train_loss: 1.1573
64/200, train_loss: 1.0667
65/200, train_loss: 0.8975
66/200, train_loss: 1.1075
67/200, train_loss: 1.0124
68/200, train_loss: 1.1261
69/200, train_loss: 0.8959
70/200, train_loss: 1.0513
71/200, train_loss: 1.1378
72/200, train_loss: 1.0663
73/200, train_loss: 0.8913
74/200, train_loss: 0.9143
75/200, train_loss: 0.9439
76/200, train_loss: 0.9652
77/200, train_loss: 1.0641
78/200, train_loss: 0.9124
79/200, train_loss: 1.0503
80/200, train_loss: 1.1357
81/200, train_loss: 0.9811
82/200, train_loss: 0.8826
83/200, train_loss: 1.0397
84/200, train_loss: 1.0106
85/200, train_loss: 0.8956
86/200, train_loss: 0.8719
87/200, train_loss: 0.9167
88/200, train_loss: 1.0492
89/200, train_loss: 0.9443
90/200, train_loss: 0.9431
91/200, train_loss: 0.9293
92/200, train_loss: 1.1462
93/200, train_loss: 0.8622
94/200, train_loss: 0.8448
95/200, train_loss: 0.8667
96/200, train_loss: 1.0878
97/200, train_loss: 1.0068
98/200, train_loss: 0.8856
99/200, train_loss: 1.0591
100/200, train_loss: 0.8601
101/200, train_loss: 1.0799
102/200, train_loss: 0.8400
103/200, train_loss: 1.0693
104/200, train_loss: 1.0945
105/200, train_loss: 1.1051
106/200, train_loss: 1.0223
107/200, train_loss: 1.0744
108/200, train_loss: 1.1177
109/200, train_loss: 0.9702
110/200, train_loss: 1.1381
111/200, train_loss: 1.0289
112/200, train_loss: 0.8453
113/200, train_loss: 1.1349
114/200, train_loss: 1.0006
115/200, train_loss: 1.0032
116/200, train_loss: 1.0653
117/200, train_loss: 0.9451
118/200, train_loss: 0.9366
119/200, train_loss: 0.9964
120/200, train_loss: 1.1021
121/200, train_loss: 1.0190
122/200, train_loss: 1.0130
123/200, train_loss: 0.9593
124/200, train_loss: 0.9133
125/200, train_loss: 1.0896
126/200, train_loss: 0.9324
127/200, train_loss: 1.1057
128/200, train_loss: 0.9448
129/200, train_loss: 0.9176
130/200, train_loss: 1.0109
131/200, train_loss: 1.2084
132/200, train_loss: 1.0582
133/200, train_loss: 1.0569
134/200, train_loss: 1.0238
135/200, train_loss: 1.0654
136/200, train_loss: 0.8825
137/200, train_loss: 0.8304
138/200, train_loss: 0.7948
139/200, train_loss: 0.8210
140/200, train_loss: 0.9689
141/200, train_loss: 0.9381
142/200, train_loss: 0.9441
143/200, train_loss: 1.1566
144/200, train_loss: 1.0187
145/200, train_loss: 1.0817
146/200, train_loss: 1.0533
147/200, train_loss: 0.8987
148/200, train_loss: 0.9307
149/200, train_loss: 0.9906
150/200, train_loss: 1.0397
151/200, train_loss: 0.8803
152/200, train_loss: 1.0458
153/200, train_loss: 1.0224
154/200, train_loss: 1.0668
155/200, train_loss: 0.8095
156/200, train_loss: 1.0551
157/200, train_loss: 1.0444
158/200, train_loss: 1.1083
159/200, train_loss: 1.0848
160/200, train_loss: 1.0778
161/200, train_loss: 0.9087
162/200, train_loss: 1.0997
163/200, train_loss: 0.9382
164/200, train_loss: 1.0145
165/200, train_loss: 1.0659
166/200, train_loss: 0.7878
167/200, train_loss: 1.0483
168/200, train_loss: 0.8163
169/200, train_loss: 1.0258
170/200, train_loss: 0.8755
171/200, train_loss: 1.0896
172/200, train_loss: 0.9749
173/200, train_loss: 0.9457
174/200, train_loss: 1.1242
175/200, train_loss: 1.0237
176/200, train_loss: 0.8704
177/200, train_loss: 0.8072
178/200, train_loss: 0.9978
179/200, train_loss: 1.0163
180/200, train_loss: 0.9476
181/200, train_loss: 1.1315
182/200, train_loss: 1.2509
183/200, train_loss: 0.8458
184/200, train_loss: 0.9538
185/200, train_loss: 0.9391
186/200, train_loss: 0.9319
187/200, train_loss: 0.9576
188/200, train_loss: 0.8198
189/200, train_loss: 0.9570
190/200, train_loss: 0.8955
191/200, train_loss: 1.0012
192/200, train_loss: 0.9676
193/200, train_loss: 1.0097
194/200, train_loss: 0.9981
195/200, train_loss: 0.9344
196/200, train_loss: 0.9572
197/200, train_loss: 1.0625
198/200, train_loss: 0.8848
199/200, train_loss: 0.8925
200/200, train_loss: 0.9447
epoch 25 average loss: 0.9828
current epoch: 25 current mean dice: 0.3551 1: 0.3502 2: 0.3580
best mean dice: 0.3910 at epoch: 21
Epoch 25 completed
time consuming of epoch 25 is: 594.9036
----------
Epoch 26/50
1/200, train_loss: 0.9833
2/200, train_loss: 1.1355
3/200, train_loss: 1.0964
4/200, train_loss: 1.0948
5/200, train_loss: 0.9394
6/200, train_loss: 0.9185
7/200, train_loss: 1.1012
8/200, train_loss: 1.0537
9/200, train_loss: 0.9565
10/200, train_loss: 0.8322
11/200, train_loss: 0.8684
12/200, train_loss: 0.8835
13/200, train_loss: 0.8563
14/200, train_loss: 0.9081
15/200, train_loss: 0.8497
16/200, train_loss: 0.9452
17/200, train_loss: 0.9110
18/200, train_loss: 0.8894
19/200, train_loss: 1.1215
20/200, train_loss: 1.0193
21/200, train_loss: 1.0407
22/200, train_loss: 0.9359
23/200, train_loss: 1.1336
24/200, train_loss: 0.8972
25/200, train_loss: 1.0018
26/200, train_loss: 1.0516
27/200, train_loss: 0.9448
28/200, train_loss: 1.0216
29/200, train_loss: 0.9704
30/200, train_loss: 0.9498
31/200, train_loss: 0.8788
32/200, train_loss: 0.9573
33/200, train_loss: 1.0046
34/200, train_loss: 1.0401
35/200, train_loss: 0.9428
36/200, train_loss: 1.1199
37/200, train_loss: 0.8871
38/200, train_loss: 1.0187
39/200, train_loss: 0.7873
40/200, train_loss: 0.9396
41/200, train_loss: 1.0332
42/200, train_loss: 1.1343
43/200, train_loss: 1.1448
44/200, train_loss: 0.9582
45/200, train_loss: 0.9552
46/200, train_loss: 0.9369
47/200, train_loss: 0.9618
48/200, train_loss: 1.0490
49/200, train_loss: 0.9174
50/200, train_loss: 1.0484
51/200, train_loss: 0.8157
52/200, train_loss: 0.9079
53/200, train_loss: 0.9402
54/200, train_loss: 0.9619
55/200, train_loss: 1.1081
56/200, train_loss: 1.1546
57/200, train_loss: 1.1097
58/200, train_loss: 0.8343
59/200, train_loss: 0.9250
60/200, train_loss: 0.9893
61/200, train_loss: 1.0392
62/200, train_loss: 0.9693
63/200, train_loss: 1.0071
64/200, train_loss: 1.0169
65/200, train_loss: 0.9214
66/200, train_loss: 0.7714
67/200, train_loss: 0.8865
68/200, train_loss: 0.9035
69/200, train_loss: 0.9574
70/200, train_loss: 0.8965
71/200, train_loss: 1.0223
72/200, train_loss: 0.8130
73/200, train_loss: 0.9295
74/200, train_loss: 0.8094
75/200, train_loss: 1.0383
76/200, train_loss: 0.9116
77/200, train_loss: 1.0407
78/200, train_loss: 0.9691
79/200, train_loss: 1.0044
80/200, train_loss: 0.9467
81/200, train_loss: 0.8838
82/200, train_loss: 0.9918
83/200, train_loss: 1.0511
84/200, train_loss: 0.9316
85/200, train_loss: 0.9210
86/200, train_loss: 0.8856
87/200, train_loss: 1.0159
88/200, train_loss: 1.0196
89/200, train_loss: 0.8515
90/200, train_loss: 1.1219
91/200, train_loss: 1.1535
92/200, train_loss: 0.8563
93/200, train_loss: 1.0141
94/200, train_loss: 0.8101
95/200, train_loss: 0.9228
96/200, train_loss: 0.9309
97/200, train_loss: 1.0422
98/200, train_loss: 0.9582
99/200, train_loss: 0.9893
100/200, train_loss: 1.2103
101/200, train_loss: 0.9578
102/200, train_loss: 0.8166
103/200, train_loss: 1.0633
104/200, train_loss: 1.0266
105/200, train_loss: 0.9766
106/200, train_loss: 0.9553
107/200, train_loss: 1.1255
108/200, train_loss: 1.0354
109/200, train_loss: 0.9020
110/200, train_loss: 1.0694
111/200, train_loss: 0.9622
112/200, train_loss: 1.1425
113/200, train_loss: 0.7687
114/200, train_loss: 0.8537
115/200, train_loss: 0.9502
116/200, train_loss: 0.8514
117/200, train_loss: 1.2185
118/200, train_loss: 1.0421
119/200, train_loss: 0.9342
120/200, train_loss: 1.0113
121/200, train_loss: 0.8830
122/200, train_loss: 0.7933
123/200, train_loss: 0.8206
124/200, train_loss: 0.8773
125/200, train_loss: 1.0597
126/200, train_loss: 0.9278
127/200, train_loss: 1.1514
128/200, train_loss: 0.8709
129/200, train_loss: 0.9800
130/200, train_loss: 1.1563
131/200, train_loss: 1.1202
132/200, train_loss: 1.0430
133/200, train_loss: 0.9494
134/200, train_loss: 0.8870
135/200, train_loss: 0.9427
136/200, train_loss: 1.1024
137/200, train_loss: 0.8305
138/200, train_loss: 1.0043
139/200, train_loss: 0.9692
140/200, train_loss: 0.9852
141/200, train_loss: 1.0142
142/200, train_loss: 1.1112
143/200, train_loss: 1.0567
144/200, train_loss: 0.9196
145/200, train_loss: 1.0391
146/200, train_loss: 0.9012
147/200, train_loss: 0.9037
148/200, train_loss: 0.8991
149/200, train_loss: 0.8919
150/200, train_loss: 0.9968
151/200, train_loss: 0.9621
152/200, train_loss: 0.9142
153/200, train_loss: 0.9124
154/200, train_loss: 0.8705
155/200, train_loss: 0.9980
156/200, train_loss: 0.8321
157/200, train_loss: 0.9579
158/200, train_loss: 0.9857
159/200, train_loss: 0.9988
160/200, train_loss: 1.0001
161/200, train_loss: 0.8205
162/200, train_loss: 1.1138
163/200, train_loss: 0.9214
164/200, train_loss: 1.0899
165/200, train_loss: 0.9702
166/200, train_loss: 0.7548
167/200, train_loss: 1.0446
168/200, train_loss: 0.9132
169/200, train_loss: 0.9577
170/200, train_loss: 1.0098
171/200, train_loss: 0.9125
172/200, train_loss: 1.0403
173/200, train_loss: 1.0546
174/200, train_loss: 1.0871
175/200, train_loss: 0.9719
176/200, train_loss: 0.8288
177/200, train_loss: 0.8859
178/200, train_loss: 0.9047
179/200, train_loss: 0.8742
180/200, train_loss: 0.9551
181/200, train_loss: 0.8887
182/200, train_loss: 0.8660
183/200, train_loss: 0.8875
184/200, train_loss: 0.9057
185/200, train_loss: 0.9163
186/200, train_loss: 0.8694
187/200, train_loss: 1.1857
188/200, train_loss: 0.7628
189/200, train_loss: 0.9372
190/200, train_loss: 0.9991
191/200, train_loss: 1.1306
192/200, train_loss: 1.0121
193/200, train_loss: 1.1664
194/200, train_loss: 1.1018
195/200, train_loss: 1.0607
196/200, train_loss: 0.8717
197/200, train_loss: 0.9143
198/200, train_loss: 0.9864
199/200, train_loss: 0.9586
200/200, train_loss: 0.9949
epoch 26 average loss: 0.9695
current epoch: 26 current mean dice: 0.3754 1: 0.3555 2: 0.3982
best mean dice: 0.3910 at epoch: 21
Epoch 26 completed
time consuming of epoch 26 is: 589.0527
----------
Epoch 27/50
1/200, train_loss: 0.9772
2/200, train_loss: 1.1267
3/200, train_loss: 0.9836
4/200, train_loss: 1.0956
5/200, train_loss: 1.0130
6/200, train_loss: 1.0851
7/200, train_loss: 0.8461
8/200, train_loss: 1.1129
9/200, train_loss: 0.9639
10/200, train_loss: 1.0654
11/200, train_loss: 1.0417
12/200, train_loss: 1.0100
13/200, train_loss: 0.8410
14/200, train_loss: 0.9253
15/200, train_loss: 0.9529
16/200, train_loss: 1.1041
17/200, train_loss: 1.0006
18/200, train_loss: 0.8564
19/200, train_loss: 0.9727
20/200, train_loss: 0.9065
21/200, train_loss: 0.9855
22/200, train_loss: 0.9254
23/200, train_loss: 0.8729
24/200, train_loss: 0.9802
25/200, train_loss: 1.0499
26/200, train_loss: 0.9296
27/200, train_loss: 0.9849
28/200, train_loss: 0.9840
29/200, train_loss: 0.9107
30/200, train_loss: 0.9111
31/200, train_loss: 1.0520
32/200, train_loss: 1.0553
33/200, train_loss: 0.9346
34/200, train_loss: 0.7813
35/200, train_loss: 0.7828
36/200, train_loss: 0.9329
37/200, train_loss: 0.9920
38/200, train_loss: 1.0848
39/200, train_loss: 1.0611
40/200, train_loss: 1.0208
41/200, train_loss: 1.0218
42/200, train_loss: 1.1210
43/200, train_loss: 1.0512
44/200, train_loss: 1.0453
45/200, train_loss: 0.9192
46/200, train_loss: 1.0286
47/200, train_loss: 0.7876
48/200, train_loss: 1.0497
49/200, train_loss: 0.9666
50/200, train_loss: 0.8874
51/200, train_loss: 0.9671
52/200, train_loss: 0.8876
53/200, train_loss: 0.8694
54/200, train_loss: 1.0229
55/200, train_loss: 0.9448
56/200, train_loss: 0.8452
57/200, train_loss: 0.9629
58/200, train_loss: 1.0795
59/200, train_loss: 0.7983
60/200, train_loss: 1.1377
61/200, train_loss: 0.9306
62/200, train_loss: 0.9248
63/200, train_loss: 1.0528
64/200, train_loss: 0.9631
65/200, train_loss: 0.8574
66/200, train_loss: 0.9500
67/200, train_loss: 1.0727
68/200, train_loss: 1.0323
69/200, train_loss: 0.9393
70/200, train_loss: 1.1527
71/200, train_loss: 0.9598
72/200, train_loss: 0.8276
73/200, train_loss: 0.9725
74/200, train_loss: 1.0990
75/200, train_loss: 1.1042
76/200, train_loss: 1.0258
77/200, train_loss: 0.9226
78/200, train_loss: 0.9861
79/200, train_loss: 1.1447
80/200, train_loss: 0.9851
81/200, train_loss: 0.8942
82/200, train_loss: 0.8883
83/200, train_loss: 1.0447
84/200, train_loss: 1.0802
85/200, train_loss: 0.9176
86/200, train_loss: 0.8775
87/200, train_loss: 1.0548
88/200, train_loss: 0.8524
89/200, train_loss: 0.9547
90/200, train_loss: 0.8309
91/200, train_loss: 1.0799
92/200, train_loss: 0.8421
93/200, train_loss: 1.0656
94/200, train_loss: 0.9101
95/200, train_loss: 1.0713
96/200, train_loss: 0.9176
97/200, train_loss: 1.0925
98/200, train_loss: 0.9191
99/200, train_loss: 0.9892
100/200, train_loss: 0.8496
101/200, train_loss: 0.9028
102/200, train_loss: 0.9625
103/200, train_loss: 0.7892
104/200, train_loss: 1.0694
105/200, train_loss: 1.0391
106/200, train_loss: 0.8820
107/200, train_loss: 0.9957
108/200, train_loss: 0.8377
109/200, train_loss: 1.0891
110/200, train_loss: 0.7951
111/200, train_loss: 0.9636
112/200, train_loss: 1.0615
113/200, train_loss: 1.1510
114/200, train_loss: 0.9049
115/200, train_loss: 0.8102
116/200, train_loss: 1.0111
117/200, train_loss: 0.9054
118/200, train_loss: 0.9677
119/200, train_loss: 0.9274
120/200, train_loss: 1.0571
121/200, train_loss: 0.9593
122/200, train_loss: 0.8940
123/200, train_loss: 0.8638
124/200, train_loss: 0.9874
125/200, train_loss: 0.9814
126/200, train_loss: 1.0502
127/200, train_loss: 0.9894
128/200, train_loss: 1.0022
129/200, train_loss: 0.9538
130/200, train_loss: 0.8322
131/200, train_loss: 1.0626
132/200, train_loss: 0.9724
133/200, train_loss: 1.1317
134/200, train_loss: 0.7872
135/200, train_loss: 0.9418
136/200, train_loss: 0.8415
137/200, train_loss: 0.9238
138/200, train_loss: 0.9138
139/200, train_loss: 1.0178
140/200, train_loss: 0.8842
141/200, train_loss: 0.9725
142/200, train_loss: 0.8581
143/200, train_loss: 1.1293
144/200, train_loss: 1.0130
145/200, train_loss: 0.9372
146/200, train_loss: 0.8248
147/200, train_loss: 0.9941
148/200, train_loss: 1.0397
149/200, train_loss: 0.9132
150/200, train_loss: 1.0488
151/200, train_loss: 0.9789
152/200, train_loss: 0.8303
153/200, train_loss: 0.7931
154/200, train_loss: 0.8836
155/200, train_loss: 0.9638
156/200, train_loss: 0.8425
157/200, train_loss: 0.8742
158/200, train_loss: 1.0059
159/200, train_loss: 0.9366
160/200, train_loss: 1.0945
161/200, train_loss: 1.1423
162/200, train_loss: 1.0424
163/200, train_loss: 0.9880
164/200, train_loss: 0.9273
165/200, train_loss: 1.0847
166/200, train_loss: 0.8030
167/200, train_loss: 0.8906
168/200, train_loss: 0.7833
169/200, train_loss: 1.0313
170/200, train_loss: 0.9139
171/200, train_loss: 0.7965
172/200, train_loss: 1.0868
173/200, train_loss: 0.9723
174/200, train_loss: 0.8420
175/200, train_loss: 0.9270
176/200, train_loss: 1.0134
177/200, train_loss: 0.9997
178/200, train_loss: 1.0726
179/200, train_loss: 0.9940
180/200, train_loss: 0.7866
181/200, train_loss: 1.1451
182/200, train_loss: 1.0811
183/200, train_loss: 1.0722
184/200, train_loss: 0.8360
185/200, train_loss: 0.9197
186/200, train_loss: 0.9973
187/200, train_loss: 0.8998
188/200, train_loss: 0.9516
189/200, train_loss: 0.8715
190/200, train_loss: 0.8895
191/200, train_loss: 0.9337
192/200, train_loss: 0.9190
193/200, train_loss: 1.0083
194/200, train_loss: 0.9287
195/200, train_loss: 1.0615
196/200, train_loss: 0.7975
197/200, train_loss: 0.8801
198/200, train_loss: 1.0740
199/200, train_loss: 1.1069
200/200, train_loss: 1.1329
epoch 27 average loss: 0.9660
current epoch: 27 current mean dice: 0.3786 1: 0.3577 2: 0.4021
best mean dice: 0.3910 at epoch: 21
Epoch 27 completed
time consuming of epoch 27 is: 582.0137
----------
Epoch 28/50
1/200, train_loss: 0.9909
2/200, train_loss: 1.0097
3/200, train_loss: 1.0380
4/200, train_loss: 1.0208
5/200, train_loss: 0.7506
6/200, train_loss: 1.0399
7/200, train_loss: 1.0775
8/200, train_loss: 0.9494
9/200, train_loss: 0.9506
10/200, train_loss: 0.8259
11/200, train_loss: 0.8784
12/200, train_loss: 1.0092
13/200, train_loss: 0.9168
14/200, train_loss: 0.8786
15/200, train_loss: 0.8802
16/200, train_loss: 1.1187
17/200, train_loss: 0.9238
18/200, train_loss: 0.9190
19/200, train_loss: 0.9840
20/200, train_loss: 0.9489
21/200, train_loss: 1.1414
22/200, train_loss: 0.9214
23/200, train_loss: 0.8555
24/200, train_loss: 1.0151
25/200, train_loss: 0.9299
26/200, train_loss: 0.9844
27/200, train_loss: 1.0102
28/200, train_loss: 0.9201
29/200, train_loss: 0.8588
30/200, train_loss: 1.0891
31/200, train_loss: 0.8780
32/200, train_loss: 1.0110
33/200, train_loss: 1.0254
34/200, train_loss: 0.9424
35/200, train_loss: 0.9741
36/200, train_loss: 0.9144
37/200, train_loss: 0.9382
38/200, train_loss: 0.8793
39/200, train_loss: 0.8515
40/200, train_loss: 0.9089
41/200, train_loss: 1.1153
42/200, train_loss: 1.0621
43/200, train_loss: 1.0334
44/200, train_loss: 1.1575
45/200, train_loss: 1.1506
46/200, train_loss: 0.9310
47/200, train_loss: 1.0969
48/200, train_loss: 0.8792
49/200, train_loss: 1.0255
50/200, train_loss: 0.9737
51/200, train_loss: 1.0037
52/200, train_loss: 0.8730
53/200, train_loss: 0.8833
54/200, train_loss: 1.1381
55/200, train_loss: 0.9795
56/200, train_loss: 1.1120
57/200, train_loss: 1.0364
58/200, train_loss: 1.0292
59/200, train_loss: 1.0616
60/200, train_loss: 0.9320
61/200, train_loss: 0.8740
62/200, train_loss: 0.7962
63/200, train_loss: 1.0650
64/200, train_loss: 0.9822
65/200, train_loss: 0.7783
66/200, train_loss: 1.1063
67/200, train_loss: 1.1824
68/200, train_loss: 1.0115
69/200, train_loss: 1.0941
70/200, train_loss: 0.8495
71/200, train_loss: 0.9668
72/200, train_loss: 0.8753
73/200, train_loss: 0.8425
74/200, train_loss: 0.9075
75/200, train_loss: 1.0141
76/200, train_loss: 1.0657
77/200, train_loss: 0.8728
78/200, train_loss: 0.7674
79/200, train_loss: 1.0413
80/200, train_loss: 0.9497
81/200, train_loss: 0.8638
82/200, train_loss: 1.0381
83/200, train_loss: 1.0327
84/200, train_loss: 0.9911
85/200, train_loss: 0.9242
86/200, train_loss: 1.1660
87/200, train_loss: 1.1255
88/200, train_loss: 0.9569
89/200, train_loss: 0.9802
90/200, train_loss: 1.1039
91/200, train_loss: 1.0318
92/200, train_loss: 0.7729
93/200, train_loss: 1.0067
94/200, train_loss: 0.9779
95/200, train_loss: 0.8924
96/200, train_loss: 1.0140
97/200, train_loss: 0.8565
98/200, train_loss: 1.1314
99/200, train_loss: 1.1141
100/200, train_loss: 0.8746
101/200, train_loss: 1.0878
102/200, train_loss: 0.9768
103/200, train_loss: 0.9745
104/200, train_loss: 0.8650
105/200, train_loss: 0.8556
106/200, train_loss: 0.9668
107/200, train_loss: 0.9086
108/200, train_loss: 0.9268
109/200, train_loss: 0.9814
110/200, train_loss: 0.9545
111/200, train_loss: 0.9090
112/200, train_loss: 0.9558
113/200, train_loss: 0.9608
114/200, train_loss: 1.0759
115/200, train_loss: 0.9569
116/200, train_loss: 0.8675
117/200, train_loss: 0.9750
118/200, train_loss: 0.8285
119/200, train_loss: 1.0476
120/200, train_loss: 0.8820
121/200, train_loss: 0.8766
122/200, train_loss: 1.1842
123/200, train_loss: 1.1470
124/200, train_loss: 0.8399
125/200, train_loss: 1.0743
126/200, train_loss: 0.8769
127/200, train_loss: 1.1113
128/200, train_loss: 0.9982
129/200, train_loss: 1.0016
130/200, train_loss: 1.3431
131/200, train_loss: 1.2064
132/200, train_loss: 0.9603
133/200, train_loss: 1.1692
134/200, train_loss: 0.9422
135/200, train_loss: 1.0558
136/200, train_loss: 0.9317
137/200, train_loss: 1.0730
138/200, train_loss: 1.0395
139/200, train_loss: 1.0095
140/200, train_loss: 1.0418
141/200, train_loss: 0.8101
142/200, train_loss: 1.0526
143/200, train_loss: 1.0148
144/200, train_loss: 1.0234
145/200, train_loss: 1.0446
146/200, train_loss: 0.9624
147/200, train_loss: 1.0106
148/200, train_loss: 0.9671
149/200, train_loss: 1.0051
150/200, train_loss: 0.8739
151/200, train_loss: 0.9663
152/200, train_loss: 0.9531
153/200, train_loss: 0.7795
154/200, train_loss: 1.0633
155/200, train_loss: 1.0605
156/200, train_loss: 0.8925
157/200, train_loss: 1.0138
158/200, train_loss: 0.9423
159/200, train_loss: 0.9700
160/200, train_loss: 0.8535
161/200, train_loss: 0.8810
162/200, train_loss: 0.8819
163/200, train_loss: 1.0194
164/200, train_loss: 0.8473
165/200, train_loss: 1.0271
166/200, train_loss: 0.9945
167/200, train_loss: 1.0965
168/200, train_loss: 1.1444
169/200, train_loss: 1.0175
170/200, train_loss: 0.9463
171/200, train_loss: 0.9970
172/200, train_loss: 0.9495
173/200, train_loss: 0.9902
174/200, train_loss: 1.0039
175/200, train_loss: 0.8312
176/200, train_loss: 0.9845
177/200, train_loss: 0.9681
178/200, train_loss: 0.9219
179/200, train_loss: 0.9311
180/200, train_loss: 0.8993
181/200, train_loss: 0.9746
182/200, train_loss: 1.0933
183/200, train_loss: 0.9133
184/200, train_loss: 0.9750
185/200, train_loss: 0.8574
186/200, train_loss: 0.9539
187/200, train_loss: 0.9715
188/200, train_loss: 1.1111
189/200, train_loss: 0.9362
190/200, train_loss: 0.9806
191/200, train_loss: 1.0763
192/200, train_loss: 0.9630
193/200, train_loss: 0.8858
194/200, train_loss: 0.9578
195/200, train_loss: 0.9366
196/200, train_loss: 0.9636
197/200, train_loss: 1.1280
198/200, train_loss: 0.9505
199/200, train_loss: 0.8479
200/200, train_loss: 0.9248
epoch 28 average loss: 0.9768
saved new best metric model
current epoch: 28 current mean dice: 0.3924 1: 0.3846 2: 0.4019
best mean dice: 0.3924 at epoch: 28
Epoch 28 completed
time consuming of epoch 28 is: 608.0912
----------
Epoch 29/50
1/200, train_loss: 1.1723
2/200, train_loss: 0.7749
3/200, train_loss: 0.8045
4/200, train_loss: 0.9619
5/200, train_loss: 0.9239
6/200, train_loss: 0.7422
7/200, train_loss: 0.9455
8/200, train_loss: 0.9080
9/200, train_loss: 1.0068
10/200, train_loss: 0.9873
11/200, train_loss: 0.7495
12/200, train_loss: 1.0420
13/200, train_loss: 1.1121
14/200, train_loss: 1.0791
15/200, train_loss: 1.0346
16/200, train_loss: 0.8937
17/200, train_loss: 1.0316
18/200, train_loss: 1.0500
19/200, train_loss: 0.9295
20/200, train_loss: 0.9889
21/200, train_loss: 1.0742
22/200, train_loss: 1.0206
23/200, train_loss: 1.0915
24/200, train_loss: 0.9149
25/200, train_loss: 0.8833
26/200, train_loss: 1.0282
27/200, train_loss: 1.0295
28/200, train_loss: 0.9655
29/200, train_loss: 0.9561
30/200, train_loss: 0.9594
31/200, train_loss: 0.8937
32/200, train_loss: 0.8163
33/200, train_loss: 0.8531
34/200, train_loss: 1.0831
35/200, train_loss: 0.9423
36/200, train_loss: 0.7516
37/200, train_loss: 1.1107
38/200, train_loss: 0.7817
39/200, train_loss: 1.0196
40/200, train_loss: 0.7888
41/200, train_loss: 0.8683
42/200, train_loss: 1.0215
43/200, train_loss: 1.0031
44/200, train_loss: 1.0702
45/200, train_loss: 1.0462
46/200, train_loss: 0.8836
47/200, train_loss: 0.9164
48/200, train_loss: 0.8847
49/200, train_loss: 0.9891
50/200, train_loss: 0.8314
51/200, train_loss: 0.7709
52/200, train_loss: 0.9071
53/200, train_loss: 1.1208
54/200, train_loss: 0.8560
55/200, train_loss: 1.0967
56/200, train_loss: 0.9573
57/200, train_loss: 0.9800
58/200, train_loss: 0.9070
59/200, train_loss: 1.1909
60/200, train_loss: 1.1222
61/200, train_loss: 0.9103
62/200, train_loss: 1.0055
63/200, train_loss: 1.0616
64/200, train_loss: 0.7964
65/200, train_loss: 1.0905
66/200, train_loss: 0.7609
67/200, train_loss: 1.0839
68/200, train_loss: 0.9502
69/200, train_loss: 0.8729
70/200, train_loss: 0.8950
71/200, train_loss: 1.1204
72/200, train_loss: 0.9598
73/200, train_loss: 0.8035
74/200, train_loss: 0.9765
75/200, train_loss: 0.9213
76/200, train_loss: 1.0428
77/200, train_loss: 1.0667
78/200, train_loss: 0.7795
79/200, train_loss: 1.0186
80/200, train_loss: 0.9251
81/200, train_loss: 0.8713
82/200, train_loss: 1.0101
83/200, train_loss: 1.0555
84/200, train_loss: 0.7919
85/200, train_loss: 1.0143
86/200, train_loss: 1.0487
87/200, train_loss: 0.9798
88/200, train_loss: 1.0101
89/200, train_loss: 0.8946
90/200, train_loss: 0.9389
91/200, train_loss: 1.0738
92/200, train_loss: 1.2242
93/200, train_loss: 1.0380
94/200, train_loss: 0.9668
95/200, train_loss: 1.0509
96/200, train_loss: 0.9674
97/200, train_loss: 1.1505
98/200, train_loss: 0.9788
99/200, train_loss: 1.0951
100/200, train_loss: 0.8932
101/200, train_loss: 0.9326
102/200, train_loss: 0.8851
103/200, train_loss: 1.1095
104/200, train_loss: 1.0803
105/200, train_loss: 1.1644
106/200, train_loss: 0.8778
107/200, train_loss: 1.1395
108/200, train_loss: 0.9369
109/200, train_loss: 0.7801
110/200, train_loss: 0.9655
111/200, train_loss: 0.8880
112/200, train_loss: 0.9508
113/200, train_loss: 1.0082
114/200, train_loss: 0.9818
115/200, train_loss: 0.8777
116/200, train_loss: 0.9566
117/200, train_loss: 0.9372
118/200, train_loss: 0.9534
119/200, train_loss: 1.0052
120/200, train_loss: 1.0266
121/200, train_loss: 0.8007
122/200, train_loss: 0.8289
123/200, train_loss: 1.0263
124/200, train_loss: 0.9497
125/200, train_loss: 1.0371
126/200, train_loss: 1.0601
127/200, train_loss: 1.0300
128/200, train_loss: 0.8425
129/200, train_loss: 0.9762
130/200, train_loss: 1.0177
131/200, train_loss: 1.0245
132/200, train_loss: 1.0403
133/200, train_loss: 0.9312
134/200, train_loss: 0.7901
135/200, train_loss: 1.0334
136/200, train_loss: 0.9021
137/200, train_loss: 0.8214
138/200, train_loss: 1.0325
139/200, train_loss: 0.9786
140/200, train_loss: 0.8101
141/200, train_loss: 1.0125
142/200, train_loss: 0.9447
143/200, train_loss: 0.9813
144/200, train_loss: 0.9955
145/200, train_loss: 0.9525
146/200, train_loss: 0.7739
147/200, train_loss: 0.9886
148/200, train_loss: 0.8904
149/200, train_loss: 0.9483
150/200, train_loss: 0.9557
151/200, train_loss: 0.8427
152/200, train_loss: 0.8823
153/200, train_loss: 0.9382
154/200, train_loss: 0.9077
155/200, train_loss: 0.7701
156/200, train_loss: 1.1582
157/200, train_loss: 0.9469
158/200, train_loss: 0.8712
159/200, train_loss: 0.9836
160/200, train_loss: 0.8907
161/200, train_loss: 0.9111
162/200, train_loss: 0.9723
163/200, train_loss: 0.8788
164/200, train_loss: 1.1365
165/200, train_loss: 1.0322
166/200, train_loss: 1.1231
167/200, train_loss: 1.0944
168/200, train_loss: 1.0494
169/200, train_loss: 0.9155
170/200, train_loss: 0.9582
171/200, train_loss: 1.0277
172/200, train_loss: 1.0236
173/200, train_loss: 0.9575
174/200, train_loss: 0.9309
175/200, train_loss: 1.1092
176/200, train_loss: 0.8836
177/200, train_loss: 0.9632
178/200, train_loss: 1.2060
179/200, train_loss: 0.8981
180/200, train_loss: 1.2491
181/200, train_loss: 0.9812
182/200, train_loss: 0.9262
183/200, train_loss: 1.0267
184/200, train_loss: 1.0905
185/200, train_loss: 1.0289
186/200, train_loss: 1.0358
187/200, train_loss: 1.0710
188/200, train_loss: 0.8918
189/200, train_loss: 1.1023
190/200, train_loss: 0.9133
191/200, train_loss: 0.9991
192/200, train_loss: 0.9502
193/200, train_loss: 1.1131
194/200, train_loss: 0.8667
195/200, train_loss: 0.9426
196/200, train_loss: 0.9182
197/200, train_loss: 1.0853
198/200, train_loss: 0.9963
199/200, train_loss: 0.8300
200/200, train_loss: 1.1738
epoch 29 average loss: 0.9695
current epoch: 29 current mean dice: 0.3799 1: 0.3774 2: 0.3828
best mean dice: 0.3924 at epoch: 28
Epoch 29 completed
time consuming of epoch 29 is: 584.5950
----------
Epoch 30/50
1/200, train_loss: 0.9020
2/200, train_loss: 0.9626
3/200, train_loss: 0.7817
4/200, train_loss: 1.0796
5/200, train_loss: 1.0851
6/200, train_loss: 1.0011
7/200, train_loss: 0.8367
8/200, train_loss: 0.9253
9/200, train_loss: 1.0095
10/200, train_loss: 0.9287
11/200, train_loss: 0.8501
12/200, train_loss: 0.9813
13/200, train_loss: 1.0509
14/200, train_loss: 1.0145
15/200, train_loss: 0.8601
16/200, train_loss: 0.8439
17/200, train_loss: 0.8653
18/200, train_loss: 0.9083
19/200, train_loss: 0.8283
20/200, train_loss: 0.7867
21/200, train_loss: 0.8904
22/200, train_loss: 1.1015
23/200, train_loss: 1.0062
24/200, train_loss: 0.9722
25/200, train_loss: 1.0272
26/200, train_loss: 1.1616
27/200, train_loss: 0.9495
28/200, train_loss: 0.9905
29/200, train_loss: 0.9961
30/200, train_loss: 0.9717
31/200, train_loss: 0.8752
32/200, train_loss: 0.8971
33/200, train_loss: 0.9785
34/200, train_loss: 0.9328
35/200, train_loss: 0.9180
36/200, train_loss: 0.9091
37/200, train_loss: 0.8711
38/200, train_loss: 1.1277
39/200, train_loss: 0.9614
40/200, train_loss: 1.1011
41/200, train_loss: 1.0270
42/200, train_loss: 1.0431
43/200, train_loss: 1.0590
44/200, train_loss: 1.0852
45/200, train_loss: 1.0518
46/200, train_loss: 0.9050
47/200, train_loss: 0.9868
48/200, train_loss: 1.0544
49/200, train_loss: 0.8522
50/200, train_loss: 1.0085
51/200, train_loss: 0.9473
52/200, train_loss: 0.9516
53/200, train_loss: 0.7680
54/200, train_loss: 1.1473
55/200, train_loss: 0.9974
56/200, train_loss: 1.0729
57/200, train_loss: 1.2089
58/200, train_loss: 0.8624
59/200, train_loss: 0.8616
60/200, train_loss: 0.9338
61/200, train_loss: 0.9442
62/200, train_loss: 0.8628
63/200, train_loss: 1.0427
64/200, train_loss: 1.0494
65/200, train_loss: 0.9880
66/200, train_loss: 0.8050
67/200, train_loss: 1.1472
68/200, train_loss: 1.0100
69/200, train_loss: 0.8992
70/200, train_loss: 1.0927
71/200, train_loss: 0.8206
72/200, train_loss: 0.9129
73/200, train_loss: 0.9215
74/200, train_loss: 1.0702
75/200, train_loss: 0.8997
76/200, train_loss: 0.8485
77/200, train_loss: 1.1803
78/200, train_loss: 0.8994
79/200, train_loss: 0.8777
80/200, train_loss: 0.8843
81/200, train_loss: 0.8216
82/200, train_loss: 0.9957
83/200, train_loss: 0.8722
84/200, train_loss: 1.0112
85/200, train_loss: 0.9272
86/200, train_loss: 0.7732
87/200, train_loss: 0.9188
88/200, train_loss: 1.0066
89/200, train_loss: 0.9933
90/200, train_loss: 1.0149
91/200, train_loss: 0.9055
92/200, train_loss: 0.9048
93/200, train_loss: 1.0130
94/200, train_loss: 0.8276
95/200, train_loss: 0.8901
96/200, train_loss: 0.9957
97/200, train_loss: 0.8105
98/200, train_loss: 0.9460
99/200, train_loss: 0.8093
100/200, train_loss: 0.9425
101/200, train_loss: 1.1047
102/200, train_loss: 1.1641
103/200, train_loss: 0.8973
104/200, train_loss: 0.9236
105/200, train_loss: 0.9623
106/200, train_loss: 0.8936
107/200, train_loss: 0.9382
108/200, train_loss: 0.8028
109/200, train_loss: 0.8958
110/200, train_loss: 0.7652
111/200, train_loss: 1.2208
112/200, train_loss: 0.9516
113/200, train_loss: 0.8487
114/200, train_loss: 0.9731
115/200, train_loss: 0.9092
116/200, train_loss: 0.9630
117/200, train_loss: 1.0735
118/200, train_loss: 0.9375
119/200, train_loss: 0.9881
120/200, train_loss: 0.8313
121/200, train_loss: 0.9212
122/200, train_loss: 0.9929
123/200, train_loss: 1.0260
124/200, train_loss: 1.0115
125/200, train_loss: 0.9129
126/200, train_loss: 1.1010
127/200, train_loss: 0.9973
128/200, train_loss: 0.8546
129/200, train_loss: 0.9385
130/200, train_loss: 0.9227
131/200, train_loss: 1.0189
132/200, train_loss: 1.0050
133/200, train_loss: 1.0373
134/200, train_loss: 0.8846
135/200, train_loss: 1.0304
136/200, train_loss: 0.8860
137/200, train_loss: 0.8404
138/200, train_loss: 1.0617
139/200, train_loss: 1.0358
140/200, train_loss: 0.9326
141/200, train_loss: 0.9481
142/200, train_loss: 0.9138
143/200, train_loss: 0.8870
144/200, train_loss: 0.9197
145/200, train_loss: 1.0009
146/200, train_loss: 0.8586
147/200, train_loss: 1.0735
148/200, train_loss: 0.9353
149/200, train_loss: 0.9131
150/200, train_loss: 0.8600
151/200, train_loss: 1.0094
152/200, train_loss: 0.9242
153/200, train_loss: 0.9478
154/200, train_loss: 0.8165
155/200, train_loss: 1.1515
156/200, train_loss: 0.8901
157/200, train_loss: 0.8072
158/200, train_loss: 0.8798
159/200, train_loss: 1.1367
160/200, train_loss: 0.9419
161/200, train_loss: 0.9978
162/200, train_loss: 1.0430
163/200, train_loss: 0.7627
164/200, train_loss: 1.0117
165/200, train_loss: 0.9756
166/200, train_loss: 1.0236
167/200, train_loss: 0.9781
168/200, train_loss: 0.8226
169/200, train_loss: 0.8821
170/200, train_loss: 0.9889
171/200, train_loss: 0.7799
172/200, train_loss: 0.8993
173/200, train_loss: 1.0294
174/200, train_loss: 0.8288
175/200, train_loss: 0.9602
176/200, train_loss: 0.9009
177/200, train_loss: 1.0959
178/200, train_loss: 1.1247
179/200, train_loss: 1.1032
180/200, train_loss: 0.9059
181/200, train_loss: 1.0549
182/200, train_loss: 1.0358
183/200, train_loss: 1.0331
184/200, train_loss: 0.9396
185/200, train_loss: 0.9101
186/200, train_loss: 1.0074
187/200, train_loss: 1.0203
188/200, train_loss: 0.8783
189/200, train_loss: 0.8608
190/200, train_loss: 0.9748
191/200, train_loss: 0.9057
192/200, train_loss: 0.8989
193/200, train_loss: 0.9803
194/200, train_loss: 0.9077
195/200, train_loss: 1.0559
196/200, train_loss: 1.0977
197/200, train_loss: 1.0407
198/200, train_loss: 0.9364
199/200, train_loss: 0.9326
200/200, train_loss: 1.1154
epoch 30 average loss: 0.9574
saved new best metric model
current epoch: 30 current mean dice: 0.3929 1: 0.3416 2: 0.4489
best mean dice: 0.3929 at epoch: 30
Epoch 30 completed
time consuming of epoch 30 is: 604.8911
----------
Epoch 31/50
1/200, train_loss: 0.8087
2/200, train_loss: 0.9422
3/200, train_loss: 1.2190
4/200, train_loss: 0.9223
5/200, train_loss: 0.8840
6/200, train_loss: 0.9946
7/200, train_loss: 0.8562
8/200, train_loss: 1.0205
9/200, train_loss: 0.9692
10/200, train_loss: 1.1529
11/200, train_loss: 0.8393
12/200, train_loss: 0.9296
13/200, train_loss: 1.0775
14/200, train_loss: 1.0251
15/200, train_loss: 0.9848
16/200, train_loss: 1.0449
17/200, train_loss: 1.1387
18/200, train_loss: 1.0855
19/200, train_loss: 0.8363
20/200, train_loss: 0.9066
21/200, train_loss: 0.8353
22/200, train_loss: 0.9366
23/200, train_loss: 0.8158
24/200, train_loss: 0.9562
25/200, train_loss: 1.0005
26/200, train_loss: 0.8850
27/200, train_loss: 0.9366
28/200, train_loss: 0.9532
29/200, train_loss: 0.9670
30/200, train_loss: 0.9507
31/200, train_loss: 0.9308
32/200, train_loss: 0.9130
33/200, train_loss: 1.0176
34/200, train_loss: 0.9793
35/200, train_loss: 0.8851
36/200, train_loss: 1.0661
37/200, train_loss: 0.9005
38/200, train_loss: 0.9537
39/200, train_loss: 0.9849
40/200, train_loss: 0.7988
41/200, train_loss: 1.0072
42/200, train_loss: 0.8759
43/200, train_loss: 0.9450
44/200, train_loss: 1.0135
45/200, train_loss: 1.0531
46/200, train_loss: 0.9820
47/200, train_loss: 1.0093
48/200, train_loss: 1.0453
49/200, train_loss: 0.8060
50/200, train_loss: 0.8097
51/200, train_loss: 0.8883
52/200, train_loss: 0.9076
53/200, train_loss: 0.9875
54/200, train_loss: 0.9944
55/200, train_loss: 0.9343
56/200, train_loss: 1.0600
57/200, train_loss: 0.9091
58/200, train_loss: 0.8046
59/200, train_loss: 0.9292
60/200, train_loss: 1.0058
61/200, train_loss: 0.8445
62/200, train_loss: 1.2170
63/200, train_loss: 0.8551
64/200, train_loss: 0.9650
65/200, train_loss: 1.0916
66/200, train_loss: 1.0554
67/200, train_loss: 0.7918
68/200, train_loss: 0.8311
69/200, train_loss: 1.0464
70/200, train_loss: 0.8644
71/200, train_loss: 0.9151
72/200, train_loss: 0.8398
73/200, train_loss: 0.9912
74/200, train_loss: 0.9071
75/200, train_loss: 0.9912
76/200, train_loss: 1.0301
77/200, train_loss: 1.1446
78/200, train_loss: 1.0225
79/200, train_loss: 0.9164
80/200, train_loss: 1.0954
81/200, train_loss: 0.9266
82/200, train_loss: 1.1722
83/200, train_loss: 0.9641
84/200, train_loss: 1.0271
85/200, train_loss: 0.9064
86/200, train_loss: 0.9389
87/200, train_loss: 1.1145
88/200, train_loss: 0.9164
89/200, train_loss: 0.9156
90/200, train_loss: 0.9029
91/200, train_loss: 0.9641
92/200, train_loss: 0.8373
93/200, train_loss: 0.8323
94/200, train_loss: 0.8306
95/200, train_loss: 0.9351
96/200, train_loss: 1.0239
97/200, train_loss: 0.9381
98/200, train_loss: 1.0644
99/200, train_loss: 0.9898
100/200, train_loss: 1.0660
101/200, train_loss: 0.9477
102/200, train_loss: 0.9990
103/200, train_loss: 1.0030
104/200, train_loss: 1.1337
105/200, train_loss: 0.9025
106/200, train_loss: 1.0199
107/200, train_loss: 0.8202
108/200, train_loss: 0.9368
109/200, train_loss: 0.9249
110/200, train_loss: 0.8138
111/200, train_loss: 0.9404
112/200, train_loss: 0.8214
113/200, train_loss: 0.9496
114/200, train_loss: 0.9862
115/200, train_loss: 1.0957
116/200, train_loss: 1.1331
117/200, train_loss: 0.9661
118/200, train_loss: 0.9291
119/200, train_loss: 0.9080
120/200, train_loss: 1.0217
121/200, train_loss: 0.7833
122/200, train_loss: 0.9311
123/200, train_loss: 1.1293
124/200, train_loss: 0.8080
125/200, train_loss: 0.7969
126/200, train_loss: 1.1270
127/200, train_loss: 0.7883
128/200, train_loss: 1.0267
129/200, train_loss: 0.9150
130/200, train_loss: 1.2017
131/200, train_loss: 1.1485
132/200, train_loss: 0.8569
133/200, train_loss: 1.0197
134/200, train_loss: 1.0163
135/200, train_loss: 0.9574
136/200, train_loss: 0.9937
137/200, train_loss: 0.8836
138/200, train_loss: 1.0851
139/200, train_loss: 0.7589
140/200, train_loss: 1.0489
141/200, train_loss: 1.0531
142/200, train_loss: 1.0064
143/200, train_loss: 0.8210
144/200, train_loss: 1.0529
145/200, train_loss: 0.9378
146/200, train_loss: 0.9978
147/200, train_loss: 1.0151
148/200, train_loss: 0.9350
149/200, train_loss: 0.9769
150/200, train_loss: 0.9896
151/200, train_loss: 0.9274
152/200, train_loss: 1.0662
153/200, train_loss: 0.9160
154/200, train_loss: 0.8440
155/200, train_loss: 0.9275
156/200, train_loss: 1.1231
157/200, train_loss: 0.8745
158/200, train_loss: 1.0325
159/200, train_loss: 0.9790
160/200, train_loss: 1.1546
161/200, train_loss: 1.0393
162/200, train_loss: 1.0385
163/200, train_loss: 0.9489
164/200, train_loss: 0.8548
165/200, train_loss: 0.8238
166/200, train_loss: 0.8166
167/200, train_loss: 0.8888
168/200, train_loss: 1.0147
169/200, train_loss: 1.0153
170/200, train_loss: 0.8475
171/200, train_loss: 1.1550
172/200, train_loss: 0.9342
173/200, train_loss: 0.9327
174/200, train_loss: 0.8378
175/200, train_loss: 0.9319
176/200, train_loss: 1.0130
177/200, train_loss: 1.0505
178/200, train_loss: 0.8159
179/200, train_loss: 1.0162
180/200, train_loss: 0.9975
181/200, train_loss: 1.0620
182/200, train_loss: 0.9245
183/200, train_loss: 1.0696
184/200, train_loss: 1.0702
185/200, train_loss: 0.9955
186/200, train_loss: 0.8628
187/200, train_loss: 0.8384
188/200, train_loss: 0.9384
189/200, train_loss: 0.9753
190/200, train_loss: 0.9240
191/200, train_loss: 0.8439
192/200, train_loss: 0.9796
193/200, train_loss: 0.9380
194/200, train_loss: 0.7974
195/200, train_loss: 0.8986
196/200, train_loss: 0.9221
197/200, train_loss: 1.0499
198/200, train_loss: 0.9151
199/200, train_loss: 1.0422
200/200, train_loss: 0.7949
epoch 31 average loss: 0.9596
current epoch: 31 current mean dice: 0.3817 1: 0.3470 2: 0.4202
best mean dice: 0.3929 at epoch: 30
Epoch 31 completed
time consuming of epoch 31 is: 585.0953
----------
Epoch 32/50
1/200, train_loss: 1.0553
2/200, train_loss: 0.9732
3/200, train_loss: 1.1381
4/200, train_loss: 0.8008
5/200, train_loss: 0.9517
6/200, train_loss: 1.0211
7/200, train_loss: 1.0581
8/200, train_loss: 1.0275
9/200, train_loss: 1.0399
10/200, train_loss: 0.9557
11/200, train_loss: 0.9630
12/200, train_loss: 1.0337
13/200, train_loss: 1.0394
14/200, train_loss: 1.0712
15/200, train_loss: 0.8485
16/200, train_loss: 1.0378
17/200, train_loss: 1.0667
18/200, train_loss: 0.8963
19/200, train_loss: 0.8387
20/200, train_loss: 0.9500
21/200, train_loss: 0.9666
22/200, train_loss: 0.8746
23/200, train_loss: 0.9245
24/200, train_loss: 0.8736
25/200, train_loss: 1.0332
26/200, train_loss: 1.0564
27/200, train_loss: 0.9334
28/200, train_loss: 0.9753
29/200, train_loss: 1.0636
30/200, train_loss: 0.9653
31/200, train_loss: 1.0909
32/200, train_loss: 0.9586
33/200, train_loss: 0.8452
34/200, train_loss: 0.9275
35/200, train_loss: 0.9285
36/200, train_loss: 0.9897
37/200, train_loss: 0.9517
38/200, train_loss: 0.9575
39/200, train_loss: 1.0280
40/200, train_loss: 0.8790
41/200, train_loss: 0.8010
42/200, train_loss: 1.0401
43/200, train_loss: 0.9018
44/200, train_loss: 0.9302
45/200, train_loss: 0.8680
46/200, train_loss: 0.9534
47/200, train_loss: 1.0587
48/200, train_loss: 0.8339
49/200, train_loss: 1.0746
50/200, train_loss: 0.8562
51/200, train_loss: 0.9684
52/200, train_loss: 0.9885
53/200, train_loss: 0.9859
54/200, train_loss: 1.1481
55/200, train_loss: 0.9233
56/200, train_loss: 0.9485
57/200, train_loss: 0.9109
58/200, train_loss: 0.8691
59/200, train_loss: 0.9096
60/200, train_loss: 1.0523
61/200, train_loss: 0.9475
62/200, train_loss: 0.8411
63/200, train_loss: 0.9699
64/200, train_loss: 0.9480
65/200, train_loss: 1.1258
66/200, train_loss: 0.9310
67/200, train_loss: 0.9920
68/200, train_loss: 1.0586
69/200, train_loss: 0.8036
70/200, train_loss: 0.9361
71/200, train_loss: 1.1089
72/200, train_loss: 0.9145
73/200, train_loss: 0.9212
74/200, train_loss: 0.9945
75/200, train_loss: 1.1440
76/200, train_loss: 0.8028
77/200, train_loss: 0.7432
78/200, train_loss: 0.9445
79/200, train_loss: 0.9327
80/200, train_loss: 0.9236
81/200, train_loss: 0.8082
82/200, train_loss: 0.9833
83/200, train_loss: 0.8292
84/200, train_loss: 0.9171
85/200, train_loss: 1.1377
86/200, train_loss: 1.0185
87/200, train_loss: 0.9358
88/200, train_loss: 1.0364
89/200, train_loss: 0.9611
90/200, train_loss: 1.0699
91/200, train_loss: 0.8656
92/200, train_loss: 1.0532
93/200, train_loss: 0.9209
94/200, train_loss: 0.8609
95/200, train_loss: 1.0804
96/200, train_loss: 0.8556
97/200, train_loss: 0.9401
98/200, train_loss: 1.1143
99/200, train_loss: 0.9785
100/200, train_loss: 0.8761
101/200, train_loss: 0.9498
102/200, train_loss: 1.0230
103/200, train_loss: 1.1798
104/200, train_loss: 0.9400
105/200, train_loss: 1.1295
106/200, train_loss: 1.0674
107/200, train_loss: 0.8131
108/200, train_loss: 0.8997
109/200, train_loss: 0.9400
110/200, train_loss: 1.1643
111/200, train_loss: 0.9087
112/200, train_loss: 0.9253
113/200, train_loss: 1.0227
114/200, train_loss: 1.0522
115/200, train_loss: 0.9445
116/200, train_loss: 1.0507
117/200, train_loss: 0.9745
118/200, train_loss: 1.0788
119/200, train_loss: 0.9117
120/200, train_loss: 0.9167
121/200, train_loss: 1.0240
122/200, train_loss: 0.9310
123/200, train_loss: 0.9288
124/200, train_loss: 0.8990
125/200, train_loss: 0.9683
126/200, train_loss: 1.0058
127/200, train_loss: 0.8325
128/200, train_loss: 1.0497
129/200, train_loss: 0.8994
130/200, train_loss: 0.9845
131/200, train_loss: 0.8757
132/200, train_loss: 1.1867
133/200, train_loss: 0.8243
134/200, train_loss: 1.0400
135/200, train_loss: 0.9120
136/200, train_loss: 0.9891
137/200, train_loss: 0.7681
138/200, train_loss: 1.0333
139/200, train_loss: 1.0734
140/200, train_loss: 0.8025
141/200, train_loss: 1.0141
142/200, train_loss: 1.0472
143/200, train_loss: 1.0799
144/200, train_loss: 0.9076
145/200, train_loss: 0.8454
146/200, train_loss: 1.0990
147/200, train_loss: 0.9808
148/200, train_loss: 0.8206
149/200, train_loss: 1.0577
150/200, train_loss: 0.9909
151/200, train_loss: 0.8636
152/200, train_loss: 0.9371
153/200, train_loss: 0.8703
154/200, train_loss: 0.9723
155/200, train_loss: 1.0375
156/200, train_loss: 1.0633
157/200, train_loss: 0.8268
158/200, train_loss: 1.1144
159/200, train_loss: 0.9155
160/200, train_loss: 0.8392
161/200, train_loss: 1.0432
162/200, train_loss: 0.9257
163/200, train_loss: 0.7699
164/200, train_loss: 0.9744
165/200, train_loss: 1.0708
166/200, train_loss: 1.0179
167/200, train_loss: 1.0883
168/200, train_loss: 0.8278
169/200, train_loss: 1.0144
170/200, train_loss: 1.0582
171/200, train_loss: 1.0694
172/200, train_loss: 1.0795
173/200, train_loss: 0.8749
174/200, train_loss: 1.0455
175/200, train_loss: 1.0021
176/200, train_loss: 0.8408
177/200, train_loss: 0.9885
178/200, train_loss: 1.0269
179/200, train_loss: 0.9420
180/200, train_loss: 0.8819
181/200, train_loss: 1.0416
182/200, train_loss: 1.1316
183/200, train_loss: 1.0575
184/200, train_loss: 0.8443
185/200, train_loss: 0.7917
186/200, train_loss: 1.0366
187/200, train_loss: 0.9561
188/200, train_loss: 0.9519
189/200, train_loss: 1.2097
190/200, train_loss: 0.9654
191/200, train_loss: 1.0801
192/200, train_loss: 0.8479
193/200, train_loss: 0.9303
194/200, train_loss: 0.7132
195/200, train_loss: 0.9964
196/200, train_loss: 0.9604
197/200, train_loss: 0.8916
198/200, train_loss: 0.9309
199/200, train_loss: 0.8954
200/200, train_loss: 1.3399
epoch 32 average loss: 0.9678
current epoch: 32 current mean dice: 0.3894 1: 0.3509 2: 0.4309
best mean dice: 0.3929 at epoch: 30
Epoch 32 completed
time consuming of epoch 32 is: 596.9718
----------
Epoch 33/50
1/200, train_loss: 0.9501
2/200, train_loss: 1.0297
3/200, train_loss: 0.7996
4/200, train_loss: 1.0017
5/200, train_loss: 0.9130
6/200, train_loss: 0.9301
7/200, train_loss: 0.8000
8/200, train_loss: 1.0304
9/200, train_loss: 0.7988
10/200, train_loss: 0.9132
11/200, train_loss: 0.7831
12/200, train_loss: 0.9174
13/200, train_loss: 0.9165
14/200, train_loss: 1.0218
15/200, train_loss: 0.9351
16/200, train_loss: 1.1343
17/200, train_loss: 0.7906
18/200, train_loss: 1.0281
19/200, train_loss: 0.8436
20/200, train_loss: 0.7991
21/200, train_loss: 1.0744
22/200, train_loss: 1.1133
23/200, train_loss: 1.0691
24/200, train_loss: 0.9109
25/200, train_loss: 0.8751
26/200, train_loss: 0.9215
27/200, train_loss: 1.0011
28/200, train_loss: 1.1074
29/200, train_loss: 0.9587
30/200, train_loss: 0.9274
31/200, train_loss: 1.0126
32/200, train_loss: 0.7525
33/200, train_loss: 1.0035
34/200, train_loss: 0.8824
35/200, train_loss: 0.8520
36/200, train_loss: 0.9680
37/200, train_loss: 0.9360
38/200, train_loss: 0.9275
39/200, train_loss: 0.7892
40/200, train_loss: 1.1189
41/200, train_loss: 1.0469
42/200, train_loss: 1.2485
43/200, train_loss: 0.8262
44/200, train_loss: 0.9963
45/200, train_loss: 1.1076
46/200, train_loss: 0.9082
47/200, train_loss: 0.8212
48/200, train_loss: 1.0827
49/200, train_loss: 0.9712
50/200, train_loss: 0.8557
51/200, train_loss: 1.0128
52/200, train_loss: 1.0796
53/200, train_loss: 1.0866
54/200, train_loss: 1.0711
55/200, train_loss: 0.8938
56/200, train_loss: 1.0552
57/200, train_loss: 0.9770
58/200, train_loss: 1.0667
59/200, train_loss: 1.0428
60/200, train_loss: 1.1042
61/200, train_loss: 1.1441
62/200, train_loss: 0.8884
63/200, train_loss: 0.8318
64/200, train_loss: 0.9227
65/200, train_loss: 0.7990
66/200, train_loss: 1.0261
67/200, train_loss: 1.1136
68/200, train_loss: 0.8006
69/200, train_loss: 0.8986
70/200, train_loss: 0.8686
71/200, train_loss: 1.0224
72/200, train_loss: 0.9843
73/200, train_loss: 0.8962
74/200, train_loss: 0.9442
75/200, train_loss: 0.9402
76/200, train_loss: 0.8408
77/200, train_loss: 1.0821
78/200, train_loss: 0.8216
79/200, train_loss: 0.9837
80/200, train_loss: 1.0348
81/200, train_loss: 1.0353
82/200, train_loss: 0.9295
83/200, train_loss: 1.0127
84/200, train_loss: 1.0267
85/200, train_loss: 1.1216
86/200, train_loss: 0.8382
87/200, train_loss: 0.9401
88/200, train_loss: 0.9950
89/200, train_loss: 0.9251
90/200, train_loss: 1.0402
91/200, train_loss: 0.7620
92/200, train_loss: 0.9856
93/200, train_loss: 1.0029
94/200, train_loss: 0.9914
95/200, train_loss: 1.0712
96/200, train_loss: 1.1732
97/200, train_loss: 0.9179
98/200, train_loss: 0.9117
99/200, train_loss: 0.9786
100/200, train_loss: 0.9575
101/200, train_loss: 0.9434
102/200, train_loss: 1.0771
103/200, train_loss: 0.9597
104/200, train_loss: 0.7517
105/200, train_loss: 1.1863
106/200, train_loss: 1.0609
107/200, train_loss: 1.0564
108/200, train_loss: 0.8975
109/200, train_loss: 0.8644
110/200, train_loss: 0.9796
111/200, train_loss: 1.0030
112/200, train_loss: 1.0157
113/200, train_loss: 0.9842
114/200, train_loss: 0.9182
115/200, train_loss: 0.8242
116/200, train_loss: 1.0180
117/200, train_loss: 0.8373
118/200, train_loss: 1.1069
119/200, train_loss: 0.9012
120/200, train_loss: 0.8393
121/200, train_loss: 0.9300
122/200, train_loss: 0.9520
123/200, train_loss: 0.8903
124/200, train_loss: 0.9037
125/200, train_loss: 0.8562
126/200, train_loss: 0.9221
127/200, train_loss: 0.8363
128/200, train_loss: 0.9422
129/200, train_loss: 0.8434
130/200, train_loss: 0.9176
131/200, train_loss: 0.9796
132/200, train_loss: 1.1142
133/200, train_loss: 1.0003
134/200, train_loss: 0.8107
135/200, train_loss: 0.9230
136/200, train_loss: 0.9092
137/200, train_loss: 0.8427
138/200, train_loss: 0.9144
139/200, train_loss: 0.9279
140/200, train_loss: 0.8488
141/200, train_loss: 0.9224
142/200, train_loss: 0.9319
143/200, train_loss: 0.9843
144/200, train_loss: 1.1501
145/200, train_loss: 0.9467
146/200, train_loss: 1.0110
147/200, train_loss: 1.0277
148/200, train_loss: 0.8233
149/200, train_loss: 0.9928
150/200, train_loss: 0.7445
151/200, train_loss: 1.0117
152/200, train_loss: 0.8447
153/200, train_loss: 0.9442
154/200, train_loss: 1.0853
155/200, train_loss: 0.9511
156/200, train_loss: 1.0970
157/200, train_loss: 0.9872
158/200, train_loss: 0.8923
159/200, train_loss: 0.8705
160/200, train_loss: 0.9344
161/200, train_loss: 0.9945
162/200, train_loss: 1.0898
163/200, train_loss: 1.1835
164/200, train_loss: 0.9192
165/200, train_loss: 0.7830
166/200, train_loss: 1.0494
167/200, train_loss: 1.0363
168/200, train_loss: 1.0103
169/200, train_loss: 0.9953
170/200, train_loss: 1.0082
171/200, train_loss: 0.9058
172/200, train_loss: 1.0687
173/200, train_loss: 1.0285
174/200, train_loss: 1.0412
175/200, train_loss: 1.0748
176/200, train_loss: 1.0916
177/200, train_loss: 0.7495
178/200, train_loss: 0.8804
179/200, train_loss: 1.0238
180/200, train_loss: 1.1105
181/200, train_loss: 1.0480
182/200, train_loss: 0.9259
183/200, train_loss: 0.9021
184/200, train_loss: 0.9014
185/200, train_loss: 0.7664
186/200, train_loss: 1.0132
187/200, train_loss: 0.9212
188/200, train_loss: 0.7965
189/200, train_loss: 1.1157
190/200, train_loss: 0.8839
191/200, train_loss: 1.1577
192/200, train_loss: 1.1223
193/200, train_loss: 1.0073
194/200, train_loss: 1.0992
195/200, train_loss: 0.9521
196/200, train_loss: 1.0448
197/200, train_loss: 0.9059
198/200, train_loss: 0.8763
199/200, train_loss: 0.9713
200/200, train_loss: 0.8987
epoch 33 average loss: 0.9612
saved new best metric model
current epoch: 33 current mean dice: 0.4031 1: 0.3627 2: 0.4480
best mean dice: 0.4031 at epoch: 33
Epoch 33 completed
time consuming of epoch 33 is: 607.7144
----------
Epoch 34/50
1/200, train_loss: 1.0950
2/200, train_loss: 0.8642
3/200, train_loss: 0.9354
4/200, train_loss: 0.8562
5/200, train_loss: 1.0261
6/200, train_loss: 0.7733
7/200, train_loss: 0.8900
8/200, train_loss: 0.9731
9/200, train_loss: 1.0273
10/200, train_loss: 0.8926
11/200, train_loss: 1.0578
12/200, train_loss: 0.7938
13/200, train_loss: 1.1105
14/200, train_loss: 0.9693
15/200, train_loss: 1.0729
16/200, train_loss: 1.0197
17/200, train_loss: 1.0648
18/200, train_loss: 0.8950
19/200, train_loss: 1.0375
20/200, train_loss: 1.0063
21/200, train_loss: 0.9404
22/200, train_loss: 1.0452
23/200, train_loss: 0.8944
24/200, train_loss: 1.0480
25/200, train_loss: 0.9883
26/200, train_loss: 0.7721
27/200, train_loss: 0.9164
28/200, train_loss: 1.2099
29/200, train_loss: 1.0346
30/200, train_loss: 0.9561
31/200, train_loss: 0.9719
32/200, train_loss: 0.8573
33/200, train_loss: 0.9097
34/200, train_loss: 0.9453
35/200, train_loss: 1.0292
36/200, train_loss: 0.9089
37/200, train_loss: 0.9275
38/200, train_loss: 0.9794
39/200, train_loss: 1.0788
40/200, train_loss: 0.8813
41/200, train_loss: 1.0132
42/200, train_loss: 0.8586
43/200, train_loss: 1.0111
44/200, train_loss: 1.0379
45/200, train_loss: 0.9492
46/200, train_loss: 0.9301
47/200, train_loss: 0.8893
48/200, train_loss: 1.0560
49/200, train_loss: 0.9844
50/200, train_loss: 0.8571
51/200, train_loss: 1.0453
52/200, train_loss: 0.9962
53/200, train_loss: 0.8696
54/200, train_loss: 1.1151
55/200, train_loss: 0.8777
56/200, train_loss: 0.9392
57/200, train_loss: 0.8621
58/200, train_loss: 0.9559
59/200, train_loss: 0.9063
60/200, train_loss: 0.9187
61/200, train_loss: 0.9954
62/200, train_loss: 0.9943
63/200, train_loss: 1.0468
64/200, train_loss: 1.1140
65/200, train_loss: 0.9224
66/200, train_loss: 0.8084
67/200, train_loss: 1.0677
68/200, train_loss: 1.0235
69/200, train_loss: 0.8847
70/200, train_loss: 1.2084
71/200, train_loss: 0.9713
72/200, train_loss: 1.0544
73/200, train_loss: 1.2089
74/200, train_loss: 0.9045
75/200, train_loss: 0.9604
76/200, train_loss: 0.8390
77/200, train_loss: 1.0420
78/200, train_loss: 1.0357
79/200, train_loss: 1.0258
80/200, train_loss: 0.8965
81/200, train_loss: 0.8634
82/200, train_loss: 1.0915
83/200, train_loss: 0.7474
84/200, train_loss: 0.9477
85/200, train_loss: 0.9205
86/200, train_loss: 0.9186
87/200, train_loss: 1.0032
88/200, train_loss: 0.9489
89/200, train_loss: 0.9862
90/200, train_loss: 0.9639
91/200, train_loss: 0.9252
92/200, train_loss: 1.0841
93/200, train_loss: 0.9039
94/200, train_loss: 0.7970
95/200, train_loss: 0.9714
96/200, train_loss: 0.9427
97/200, train_loss: 1.0457
98/200, train_loss: 0.7978
99/200, train_loss: 0.8241
100/200, train_loss: 0.8373
101/200, train_loss: 0.9571
102/200, train_loss: 1.0054
103/200, train_loss: 0.8825
104/200, train_loss: 1.0267
105/200, train_loss: 0.7594
106/200, train_loss: 0.8920
107/200, train_loss: 0.9039
108/200, train_loss: 1.0120
109/200, train_loss: 1.0678
110/200, train_loss: 0.9752
111/200, train_loss: 0.9468
112/200, train_loss: 0.9236
113/200, train_loss: 0.9990
114/200, train_loss: 0.9891
115/200, train_loss: 1.0787
116/200, train_loss: 0.8180
117/200, train_loss: 0.9687
118/200, train_loss: 1.0484
119/200, train_loss: 0.9839
120/200, train_loss: 0.8450
121/200, train_loss: 1.0433
122/200, train_loss: 1.0537
123/200, train_loss: 0.9168
124/200, train_loss: 1.0225
125/200, train_loss: 0.8800
126/200, train_loss: 1.1292
127/200, train_loss: 1.0023
128/200, train_loss: 1.2288
129/200, train_loss: 1.0405
130/200, train_loss: 0.9919
131/200, train_loss: 0.9386
132/200, train_loss: 1.0711
133/200, train_loss: 0.8092
134/200, train_loss: 1.1516
135/200, train_loss: 0.8924
136/200, train_loss: 1.1310
137/200, train_loss: 0.9599
138/200, train_loss: 0.9122
139/200, train_loss: 0.8931
140/200, train_loss: 1.0508
141/200, train_loss: 0.8569
142/200, train_loss: 0.7027
143/200, train_loss: 0.8412
144/200, train_loss: 0.9006
145/200, train_loss: 1.0274
146/200, train_loss: 0.9063
147/200, train_loss: 0.8846
148/200, train_loss: 0.9099
149/200, train_loss: 0.9969
150/200, train_loss: 1.0045
151/200, train_loss: 1.0002
152/200, train_loss: 1.0094
153/200, train_loss: 0.9790
154/200, train_loss: 1.1248
155/200, train_loss: 0.8927
156/200, train_loss: 0.9316
157/200, train_loss: 0.8724
158/200, train_loss: 0.8029
159/200, train_loss: 0.9406
160/200, train_loss: 1.1298
161/200, train_loss: 0.8625
162/200, train_loss: 0.8991
163/200, train_loss: 0.9831
164/200, train_loss: 0.9965
165/200, train_loss: 0.9049
166/200, train_loss: 0.8160
167/200, train_loss: 0.9186
168/200, train_loss: 1.0449
169/200, train_loss: 0.8741
170/200, train_loss: 0.9569
171/200, train_loss: 1.2021
172/200, train_loss: 0.9450
173/200, train_loss: 0.8318
174/200, train_loss: 0.9992
175/200, train_loss: 0.7511
176/200, train_loss: 0.9751
177/200, train_loss: 0.9197
178/200, train_loss: 0.9146
179/200, train_loss: 0.8310
180/200, train_loss: 0.9558
181/200, train_loss: 0.8058
182/200, train_loss: 1.0282
183/200, train_loss: 1.0233
184/200, train_loss: 1.0519
185/200, train_loss: 1.0198
186/200, train_loss: 0.9774
187/200, train_loss: 0.8032
188/200, train_loss: 1.0513
189/200, train_loss: 0.8168
190/200, train_loss: 0.8559
191/200, train_loss: 0.9060
192/200, train_loss: 0.8314
193/200, train_loss: 0.9334
194/200, train_loss: 1.0361
195/200, train_loss: 1.0733
196/200, train_loss: 0.9150
197/200, train_loss: 0.8408
198/200, train_loss: 0.8961
199/200, train_loss: 0.8993
200/200, train_loss: 1.0657
epoch 34 average loss: 0.9579
current epoch: 34 current mean dice: 0.3951 1: 0.3473 2: 0.4485
best mean dice: 0.4031 at epoch: 33
Epoch 34 completed
time consuming of epoch 34 is: 587.9373
----------
Epoch 35/50
1/200, train_loss: 0.8728
2/200, train_loss: 0.9719
3/200, train_loss: 0.8807
4/200, train_loss: 1.0154
5/200, train_loss: 0.8966
6/200, train_loss: 0.8882
7/200, train_loss: 0.8741
8/200, train_loss: 1.0645
9/200, train_loss: 0.8769
10/200, train_loss: 1.0154
11/200, train_loss: 1.0807
12/200, train_loss: 0.7573
13/200, train_loss: 1.0375
14/200, train_loss: 0.7159
15/200, train_loss: 0.9139
16/200, train_loss: 0.7958
17/200, train_loss: 0.8263
18/200, train_loss: 0.9777
19/200, train_loss: 0.8806
20/200, train_loss: 1.0488
21/200, train_loss: 0.8768
22/200, train_loss: 0.9279
23/200, train_loss: 0.7814
24/200, train_loss: 0.8522
25/200, train_loss: 0.8800
26/200, train_loss: 0.9992
27/200, train_loss: 1.0862
28/200, train_loss: 0.8386
29/200, train_loss: 1.1058
30/200, train_loss: 1.0080
31/200, train_loss: 0.9277
32/200, train_loss: 0.8672
33/200, train_loss: 1.0691
34/200, train_loss: 0.9705
35/200, train_loss: 1.0963
36/200, train_loss: 0.9221
37/200, train_loss: 0.8179
38/200, train_loss: 0.9541
39/200, train_loss: 1.0555
40/200, train_loss: 0.8528
41/200, train_loss: 0.9254
42/200, train_loss: 1.0267
43/200, train_loss: 0.8817
44/200, train_loss: 0.9422
45/200, train_loss: 1.0381
46/200, train_loss: 0.7932
47/200, train_loss: 0.7715
48/200, train_loss: 0.8722
49/200, train_loss: 1.0214
50/200, train_loss: 0.8848
51/200, train_loss: 0.8955
52/200, train_loss: 1.0619
53/200, train_loss: 1.0489
54/200, train_loss: 0.8504
55/200, train_loss: 0.8825
56/200, train_loss: 0.9648
57/200, train_loss: 1.1045
58/200, train_loss: 0.9183
59/200, train_loss: 0.9056
60/200, train_loss: 1.0707
61/200, train_loss: 0.9232
62/200, train_loss: 0.7789
63/200, train_loss: 0.9096
64/200, train_loss: 0.8308
65/200, train_loss: 1.0037
66/200, train_loss: 0.8292
67/200, train_loss: 0.9753
68/200, train_loss: 0.8513
69/200, train_loss: 1.0330
70/200, train_loss: 0.8621
71/200, train_loss: 0.9874
72/200, train_loss: 0.8880
73/200, train_loss: 0.8827
74/200, train_loss: 0.7826
75/200, train_loss: 0.8868
76/200, train_loss: 0.8898
77/200, train_loss: 0.9126
78/200, train_loss: 1.0081
79/200, train_loss: 1.0314
80/200, train_loss: 0.8343
81/200, train_loss: 1.0409
82/200, train_loss: 1.0479
83/200, train_loss: 0.8609
84/200, train_loss: 0.9890
85/200, train_loss: 0.8902
86/200, train_loss: 1.1655
87/200, train_loss: 0.9753
88/200, train_loss: 0.8720
89/200, train_loss: 0.9351
90/200, train_loss: 0.9482
91/200, train_loss: 1.0370
92/200, train_loss: 1.0275
93/200, train_loss: 0.9691
94/200, train_loss: 1.0175
95/200, train_loss: 0.9355
96/200, train_loss: 0.9321
97/200, train_loss: 1.2106
98/200, train_loss: 0.9468
99/200, train_loss: 0.8797
100/200, train_loss: 1.0123
101/200, train_loss: 0.8646
102/200, train_loss: 0.9467
103/200, train_loss: 0.9611
104/200, train_loss: 0.9407
105/200, train_loss: 1.0953
106/200, train_loss: 1.0327
107/200, train_loss: 0.7904
108/200, train_loss: 1.0405
109/200, train_loss: 0.8494
110/200, train_loss: 0.9137
111/200, train_loss: 0.9669
112/200, train_loss: 0.8771
113/200, train_loss: 0.8779
114/200, train_loss: 0.8862
115/200, train_loss: 1.0745
116/200, train_loss: 0.9799
117/200, train_loss: 0.8029
118/200, train_loss: 0.9900
119/200, train_loss: 0.9755
120/200, train_loss: 1.0839
121/200, train_loss: 0.9715
122/200, train_loss: 0.9247
123/200, train_loss: 1.0944
124/200, train_loss: 0.9241
125/200, train_loss: 0.9951
126/200, train_loss: 0.9457
127/200, train_loss: 1.0367
128/200, train_loss: 1.0509
129/200, train_loss: 1.0882
130/200, train_loss: 1.0674
131/200, train_loss: 0.9106
132/200, train_loss: 1.1572
133/200, train_loss: 0.8632
134/200, train_loss: 0.8146
135/200, train_loss: 0.8932
136/200, train_loss: 0.8417
137/200, train_loss: 1.1082
138/200, train_loss: 0.8584
139/200, train_loss: 0.9602
140/200, train_loss: 0.7569
141/200, train_loss: 1.2763
142/200, train_loss: 0.9195
143/200, train_loss: 0.9259
144/200, train_loss: 0.9822
145/200, train_loss: 1.0990
146/200, train_loss: 0.9997
147/200, train_loss: 0.8107
148/200, train_loss: 0.9784
149/200, train_loss: 0.8625
150/200, train_loss: 1.1282
151/200, train_loss: 0.9361
152/200, train_loss: 0.9323
153/200, train_loss: 1.0316
154/200, train_loss: 1.0971
155/200, train_loss: 0.9975
156/200, train_loss: 1.0459
157/200, train_loss: 1.0557
158/200, train_loss: 1.0037
159/200, train_loss: 1.0961
160/200, train_loss: 0.8246
161/200, train_loss: 0.8152
162/200, train_loss: 0.9764
163/200, train_loss: 0.9170
164/200, train_loss: 0.8264
165/200, train_loss: 1.1280
166/200, train_loss: 0.9254
167/200, train_loss: 1.0362
168/200, train_loss: 1.0965
169/200, train_loss: 1.1113
170/200, train_loss: 0.8130
171/200, train_loss: 0.9341
172/200, train_loss: 1.1003
173/200, train_loss: 0.9333
174/200, train_loss: 0.7432
175/200, train_loss: 0.9346
176/200, train_loss: 0.9744
177/200, train_loss: 1.0435
178/200, train_loss: 1.2128
179/200, train_loss: 0.9749
180/200, train_loss: 0.9914
181/200, train_loss: 0.9022
182/200, train_loss: 0.9764
183/200, train_loss: 0.8173
184/200, train_loss: 1.0556
185/200, train_loss: 0.9336
186/200, train_loss: 0.9403
187/200, train_loss: 1.0078
188/200, train_loss: 1.0781
189/200, train_loss: 1.1059
190/200, train_loss: 0.8812
191/200, train_loss: 0.8251
192/200, train_loss: 0.8754
193/200, train_loss: 1.1220
194/200, train_loss: 0.8681
195/200, train_loss: 0.8854
196/200, train_loss: 0.8502
197/200, train_loss: 0.8943
198/200, train_loss: 0.9120
199/200, train_loss: 0.9165
200/200, train_loss: 0.8936
epoch 35 average loss: 0.9519
saved new best metric model
current epoch: 35 current mean dice: 0.4054 1: 0.3613 2: 0.4547
best mean dice: 0.4054 at epoch: 35
Epoch 35 completed
time consuming of epoch 35 is: 605.5542
----------
Epoch 36/50
1/200, train_loss: 1.0575
2/200, train_loss: 0.8666
3/200, train_loss: 0.9759
4/200, train_loss: 0.9829
5/200, train_loss: 1.0825
6/200, train_loss: 1.0998
7/200, train_loss: 0.9393
8/200, train_loss: 0.7776
9/200, train_loss: 1.1084
10/200, train_loss: 0.9211
11/200, train_loss: 0.8999
12/200, train_loss: 0.8037
13/200, train_loss: 0.9937
14/200, train_loss: 0.8837
15/200, train_loss: 0.9634
16/200, train_loss: 0.6755
17/200, train_loss: 0.9391
18/200, train_loss: 1.0217
19/200, train_loss: 0.9791
20/200, train_loss: 0.9634
21/200, train_loss: 1.0357
22/200, train_loss: 0.9733
23/200, train_loss: 0.9140
24/200, train_loss: 0.9378
25/200, train_loss: 0.9121
26/200, train_loss: 0.9122
27/200, train_loss: 1.0114
28/200, train_loss: 0.9476
29/200, train_loss: 0.9535
30/200, train_loss: 0.7120
31/200, train_loss: 0.7972
32/200, train_loss: 1.1353
33/200, train_loss: 1.0030
34/200, train_loss: 0.8609
35/200, train_loss: 1.0995
36/200, train_loss: 1.0164
37/200, train_loss: 0.9117
38/200, train_loss: 0.7810
39/200, train_loss: 0.8830
40/200, train_loss: 0.8923
41/200, train_loss: 1.0581
42/200, train_loss: 1.0196
43/200, train_loss: 0.9972
44/200, train_loss: 0.9855
45/200, train_loss: 1.0007
46/200, train_loss: 0.9366
47/200, train_loss: 1.1303
48/200, train_loss: 0.8286
49/200, train_loss: 0.8828
50/200, train_loss: 1.0617
51/200, train_loss: 1.1600
52/200, train_loss: 1.1770
53/200, train_loss: 0.8436
54/200, train_loss: 1.0165
55/200, train_loss: 0.9740
56/200, train_loss: 1.0591
57/200, train_loss: 0.9403
58/200, train_loss: 0.9285
59/200, train_loss: 0.9159
60/200, train_loss: 0.9445
61/200, train_loss: 0.9007
62/200, train_loss: 0.9051
63/200, train_loss: 0.9608
64/200, train_loss: 0.8454
65/200, train_loss: 0.8765
66/200, train_loss: 0.9976
67/200, train_loss: 0.8679
68/200, train_loss: 0.8741
69/200, train_loss: 0.9383
70/200, train_loss: 1.0826
71/200, train_loss: 0.8470
72/200, train_loss: 0.9957
73/200, train_loss: 1.0458
74/200, train_loss: 0.8796
75/200, train_loss: 0.9626
76/200, train_loss: 0.8798
77/200, train_loss: 1.0170
78/200, train_loss: 0.9937
79/200, train_loss: 1.0095
80/200, train_loss: 1.0405
81/200, train_loss: 0.9903
82/200, train_loss: 0.9287
83/200, train_loss: 0.9741
84/200, train_loss: 0.8771
85/200, train_loss: 1.0646
86/200, train_loss: 1.0353
87/200, train_loss: 0.9620
88/200, train_loss: 0.9168
89/200, train_loss: 0.9379
90/200, train_loss: 0.8648
91/200, train_loss: 1.0960
92/200, train_loss: 0.9164
93/200, train_loss: 1.0479
94/200, train_loss: 1.0222
95/200, train_loss: 1.0393
96/200, train_loss: 0.8896
97/200, train_loss: 0.8939
98/200, train_loss: 0.9680
99/200, train_loss: 0.8754
100/200, train_loss: 0.9394
101/200, train_loss: 1.0944
102/200, train_loss: 0.7528
103/200, train_loss: 1.1231
104/200, train_loss: 1.0033
105/200, train_loss: 1.1536
106/200, train_loss: 1.0074
107/200, train_loss: 0.9850
108/200, train_loss: 0.8837
109/200, train_loss: 0.9343
110/200, train_loss: 0.9401
111/200, train_loss: 1.0117
112/200, train_loss: 0.9854
113/200, train_loss: 1.0094
114/200, train_loss: 1.1132
115/200, train_loss: 0.8195
116/200, train_loss: 1.0383
117/200, train_loss: 0.9583
118/200, train_loss: 1.0108
119/200, train_loss: 1.0929
120/200, train_loss: 0.8374
121/200, train_loss: 0.9817
122/200, train_loss: 0.9248
123/200, train_loss: 1.0547
124/200, train_loss: 1.0945
125/200, train_loss: 1.0480
126/200, train_loss: 0.9308
127/200, train_loss: 0.9232
128/200, train_loss: 0.9432
129/200, train_loss: 0.9027
130/200, train_loss: 0.8888
131/200, train_loss: 0.9845
132/200, train_loss: 0.9221
133/200, train_loss: 0.8477
134/200, train_loss: 0.8802
135/200, train_loss: 1.2340
136/200, train_loss: 1.0763
137/200, train_loss: 0.9631
138/200, train_loss: 0.8683
139/200, train_loss: 1.0463
140/200, train_loss: 0.9242
141/200, train_loss: 0.8114
142/200, train_loss: 1.1848
143/200, train_loss: 1.1729
144/200, train_loss: 0.8115
145/200, train_loss: 0.8676
146/200, train_loss: 0.8080
147/200, train_loss: 0.7689
148/200, train_loss: 0.9740
149/200, train_loss: 0.9136
150/200, train_loss: 0.8885
151/200, train_loss: 0.9877
152/200, train_loss: 0.8658
153/200, train_loss: 0.9242
154/200, train_loss: 0.8979
155/200, train_loss: 1.1444
156/200, train_loss: 0.9674
157/200, train_loss: 0.9005
158/200, train_loss: 1.0771
159/200, train_loss: 1.2428
160/200, train_loss: 0.9393
161/200, train_loss: 0.9735
162/200, train_loss: 0.7881
163/200, train_loss: 0.9818
164/200, train_loss: 1.0279
165/200, train_loss: 0.9297
166/200, train_loss: 1.1172
167/200, train_loss: 0.8493
168/200, train_loss: 1.0440
169/200, train_loss: 1.0458
170/200, train_loss: 0.9970
171/200, train_loss: 0.9853
172/200, train_loss: 0.9865
173/200, train_loss: 0.8561
174/200, train_loss: 0.7887
175/200, train_loss: 0.9091
176/200, train_loss: 0.9804
177/200, train_loss: 0.9578
178/200, train_loss: 0.8959
179/200, train_loss: 0.8194
180/200, train_loss: 0.9390
181/200, train_loss: 0.8841
182/200, train_loss: 0.8952
183/200, train_loss: 1.0078
184/200, train_loss: 1.0323
185/200, train_loss: 1.0477
186/200, train_loss: 0.8929
187/200, train_loss: 0.9383
188/200, train_loss: 0.8616
189/200, train_loss: 0.9581
190/200, train_loss: 0.8199
191/200, train_loss: 1.0012
192/200, train_loss: 0.8310
193/200, train_loss: 0.8583
194/200, train_loss: 1.0581
195/200, train_loss: 0.9375
196/200, train_loss: 1.0152
197/200, train_loss: 0.8232
198/200, train_loss: 0.8214
199/200, train_loss: 0.8437
200/200, train_loss: 0.9116
epoch 36 average loss: 0.9565
saved new best metric model
current epoch: 36 current mean dice: 0.4076 1: 0.3636 2: 0.4553
best mean dice: 0.4076 at epoch: 36
Epoch 36 completed
time consuming of epoch 36 is: 607.8834
----------
Epoch 37/50
1/200, train_loss: 1.0320
2/200, train_loss: 0.8864
3/200, train_loss: 0.9106
4/200, train_loss: 0.8061
5/200, train_loss: 0.9393
6/200, train_loss: 1.1024
7/200, train_loss: 1.2218
8/200, train_loss: 0.9429
9/200, train_loss: 1.0978
10/200, train_loss: 0.9679
11/200, train_loss: 1.0013
12/200, train_loss: 1.1326
13/200, train_loss: 0.8502
14/200, train_loss: 1.0391
15/200, train_loss: 0.9038
16/200, train_loss: 1.0226
17/200, train_loss: 0.7701
18/200, train_loss: 0.9982
19/200, train_loss: 0.8706
20/200, train_loss: 1.1047
21/200, train_loss: 0.9673
22/200, train_loss: 0.9920
23/200, train_loss: 0.9945
24/200, train_loss: 0.7984
25/200, train_loss: 0.9825
26/200, train_loss: 0.8106
27/200, train_loss: 1.0729
28/200, train_loss: 1.1368
29/200, train_loss: 0.8856
30/200, train_loss: 0.9598
31/200, train_loss: 0.9365
32/200, train_loss: 0.9118
33/200, train_loss: 1.2168
34/200, train_loss: 0.9305
35/200, train_loss: 0.9584
36/200, train_loss: 0.8916
37/200, train_loss: 0.8348
38/200, train_loss: 1.1370
39/200, train_loss: 0.7329
40/200, train_loss: 0.8404
41/200, train_loss: 0.8885
42/200, train_loss: 0.9287
43/200, train_loss: 0.9179
44/200, train_loss: 0.7102
45/200, train_loss: 0.8587
46/200, train_loss: 1.0092
47/200, train_loss: 0.8593
48/200, train_loss: 1.1252
49/200, train_loss: 1.0261
50/200, train_loss: 0.9972
51/200, train_loss: 0.7490
52/200, train_loss: 0.7258
53/200, train_loss: 0.9289
54/200, train_loss: 1.1080
55/200, train_loss: 1.0303
56/200, train_loss: 0.9336
57/200, train_loss: 1.0714
58/200, train_loss: 0.9393
59/200, train_loss: 0.8957
60/200, train_loss: 0.8909
61/200, train_loss: 0.9532
62/200, train_loss: 0.8858
63/200, train_loss: 0.9400
64/200, train_loss: 0.8333
65/200, train_loss: 0.7781
66/200, train_loss: 0.9415
67/200, train_loss: 1.0075
68/200, train_loss: 0.9566
69/200, train_loss: 1.0497
70/200, train_loss: 0.8571
71/200, train_loss: 1.0110
72/200, train_loss: 0.8668
73/200, train_loss: 1.0754
74/200, train_loss: 0.7617
75/200, train_loss: 1.0155
76/200, train_loss: 1.0429
77/200, train_loss: 0.9368
78/200, train_loss: 1.0268
79/200, train_loss: 0.9560
80/200, train_loss: 1.0030
81/200, train_loss: 1.0573
82/200, train_loss: 1.0192
83/200, train_loss: 0.7494
84/200, train_loss: 0.9652
85/200, train_loss: 1.0034
86/200, train_loss: 1.1359
87/200, train_loss: 0.8332
88/200, train_loss: 0.9130
89/200, train_loss: 0.8921
90/200, train_loss: 1.0854
91/200, train_loss: 0.8976
92/200, train_loss: 0.9769
93/200, train_loss: 1.0715
94/200, train_loss: 0.8509
95/200, train_loss: 0.9632
96/200, train_loss: 0.7729
97/200, train_loss: 0.7846
98/200, train_loss: 1.1065
99/200, train_loss: 1.1571
100/200, train_loss: 0.9880
101/200, train_loss: 0.7349
102/200, train_loss: 1.0411
103/200, train_loss: 1.0397
104/200, train_loss: 0.9676
105/200, train_loss: 0.8891
106/200, train_loss: 0.7690
107/200, train_loss: 1.0300
108/200, train_loss: 0.9896
109/200, train_loss: 0.8958
110/200, train_loss: 0.9578
111/200, train_loss: 0.9209
112/200, train_loss: 0.7730
113/200, train_loss: 0.9843
114/200, train_loss: 0.8874
115/200, train_loss: 1.0421
116/200, train_loss: 0.8222
117/200, train_loss: 0.9094
118/200, train_loss: 1.1302
119/200, train_loss: 0.8578
120/200, train_loss: 0.9125
121/200, train_loss: 1.0340
122/200, train_loss: 1.0270
123/200, train_loss: 1.0507
124/200, train_loss: 0.8772
125/200, train_loss: 0.8969
126/200, train_loss: 1.0370
127/200, train_loss: 0.9720
128/200, train_loss: 0.8736
129/200, train_loss: 0.8002
130/200, train_loss: 0.8888
131/200, train_loss: 1.0004
132/200, train_loss: 0.8875
133/200, train_loss: 0.9743
134/200, train_loss: 0.8632
135/200, train_loss: 0.9647
136/200, train_loss: 0.8768
137/200, train_loss: 0.9765
138/200, train_loss: 1.0404
139/200, train_loss: 0.9497
140/200, train_loss: 0.8259
141/200, train_loss: 0.9129
142/200, train_loss: 0.9542
143/200, train_loss: 1.0286
144/200, train_loss: 1.0480
145/200, train_loss: 0.8367
146/200, train_loss: 0.9048
147/200, train_loss: 1.1731
148/200, train_loss: 0.8732
149/200, train_loss: 0.8397
150/200, train_loss: 1.0166
151/200, train_loss: 0.9821
152/200, train_loss: 0.8992
153/200, train_loss: 1.0009
154/200, train_loss: 0.7604
155/200, train_loss: 1.0106
156/200, train_loss: 1.1728
157/200, train_loss: 0.9644
158/200, train_loss: 0.8948
159/200, train_loss: 0.7891
160/200, train_loss: 0.9833
161/200, train_loss: 0.9097
162/200, train_loss: 0.9767
163/200, train_loss: 0.9864
164/200, train_loss: 0.8685
165/200, train_loss: 1.0318
166/200, train_loss: 0.9070
167/200, train_loss: 1.1036
168/200, train_loss: 0.9911
169/200, train_loss: 0.8002
170/200, train_loss: 0.9752
171/200, train_loss: 0.9321
172/200, train_loss: 1.1019
173/200, train_loss: 0.8048
174/200, train_loss: 0.9810
175/200, train_loss: 1.0738
176/200, train_loss: 0.9185
177/200, train_loss: 0.8447
178/200, train_loss: 0.9300
179/200, train_loss: 1.0042
180/200, train_loss: 1.0090
181/200, train_loss: 0.9161
182/200, train_loss: 0.8741
183/200, train_loss: 1.0306
184/200, train_loss: 0.9700
185/200, train_loss: 0.8261
186/200, train_loss: 0.9823
187/200, train_loss: 0.8466
188/200, train_loss: 0.9268
189/200, train_loss: 1.1057
190/200, train_loss: 0.9093
191/200, train_loss: 0.8321
192/200, train_loss: 0.9637
193/200, train_loss: 0.8514
194/200, train_loss: 0.9568
195/200, train_loss: 0.9933
196/200, train_loss: 1.0225
197/200, train_loss: 1.2033
198/200, train_loss: 0.9064
199/200, train_loss: 0.8731
200/200, train_loss: 0.9591
epoch 37 average loss: 0.9491
current epoch: 37 current mean dice: 0.4017 1: 0.3642 2: 0.4430
best mean dice: 0.4076 at epoch: 36
Epoch 37 completed
time consuming of epoch 37 is: 594.3513
----------
Epoch 38/50
1/200, train_loss: 0.9928
2/200, train_loss: 0.9486
3/200, train_loss: 0.9141
4/200, train_loss: 1.1043
5/200, train_loss: 0.9524
6/200, train_loss: 0.7872
7/200, train_loss: 0.9648
8/200, train_loss: 0.8922
9/200, train_loss: 1.0020
10/200, train_loss: 0.9025
11/200, train_loss: 0.8829
12/200, train_loss: 0.9893
13/200, train_loss: 0.9527
14/200, train_loss: 1.0320
15/200, train_loss: 0.9962
16/200, train_loss: 0.9588
17/200, train_loss: 1.0735
18/200, train_loss: 0.9193
19/200, train_loss: 1.0482
20/200, train_loss: 0.8797
21/200, train_loss: 0.9087
22/200, train_loss: 1.1419
23/200, train_loss: 1.1140
24/200, train_loss: 0.7362
25/200, train_loss: 0.8200
26/200, train_loss: 1.0365
27/200, train_loss: 1.0386
28/200, train_loss: 0.9794
29/200, train_loss: 0.9770
30/200, train_loss: 1.0060
31/200, train_loss: 1.0602
32/200, train_loss: 0.9600
33/200, train_loss: 0.8653
34/200, train_loss: 0.9512
35/200, train_loss: 0.9860
36/200, train_loss: 0.7651
37/200, train_loss: 1.0478
38/200, train_loss: 1.0967
39/200, train_loss: 0.9056
40/200, train_loss: 0.9341
41/200, train_loss: 0.8269
42/200, train_loss: 0.9189
43/200, train_loss: 1.1313
44/200, train_loss: 0.9383
45/200, train_loss: 1.0060
46/200, train_loss: 0.9913
47/200, train_loss: 0.8220
48/200, train_loss: 1.0378
49/200, train_loss: 0.9067
50/200, train_loss: 0.9703
51/200, train_loss: 1.1435
52/200, train_loss: 1.0678
53/200, train_loss: 1.0274
54/200, train_loss: 0.9975
55/200, train_loss: 0.8874
56/200, train_loss: 0.7519
57/200, train_loss: 1.0587
58/200, train_loss: 0.9397
59/200, train_loss: 0.8185
60/200, train_loss: 1.0774
61/200, train_loss: 1.0114
62/200, train_loss: 0.7911
63/200, train_loss: 0.8879
64/200, train_loss: 1.0060
65/200, train_loss: 1.0374
66/200, train_loss: 1.0314
67/200, train_loss: 0.9591
68/200, train_loss: 1.0585
69/200, train_loss: 0.9592
70/200, train_loss: 1.0347
71/200, train_loss: 0.9216
72/200, train_loss: 1.1922
73/200, train_loss: 0.7220
74/200, train_loss: 1.2253
75/200, train_loss: 0.9344
76/200, train_loss: 1.1123
77/200, train_loss: 0.7707
78/200, train_loss: 1.0895
79/200, train_loss: 1.0962
80/200, train_loss: 0.8833
81/200, train_loss: 1.0387
82/200, train_loss: 0.8309
83/200, train_loss: 1.0209
84/200, train_loss: 0.9516
85/200, train_loss: 0.8574
86/200, train_loss: 1.0164
87/200, train_loss: 0.9362
88/200, train_loss: 0.8070
89/200, train_loss: 0.8773
90/200, train_loss: 1.0562
91/200, train_loss: 0.9710
92/200, train_loss: 1.1204
93/200, train_loss: 1.0441
94/200, train_loss: 0.8155
95/200, train_loss: 0.9597
96/200, train_loss: 0.9267
97/200, train_loss: 0.8506
98/200, train_loss: 0.8854
99/200, train_loss: 0.7917
100/200, train_loss: 0.8016
101/200, train_loss: 1.0978
102/200, train_loss: 0.9116
103/200, train_loss: 0.7651
104/200, train_loss: 1.1021
105/200, train_loss: 0.8214
106/200, train_loss: 0.8507
107/200, train_loss: 1.0753
108/200, train_loss: 1.1059
109/200, train_loss: 0.9151
110/200, train_loss: 0.8268
111/200, train_loss: 1.0178
112/200, train_loss: 0.7917
113/200, train_loss: 0.9402
114/200, train_loss: 1.0518
115/200, train_loss: 1.1127
116/200, train_loss: 0.7429
117/200, train_loss: 0.9148
118/200, train_loss: 0.8656
119/200, train_loss: 0.9382
120/200, train_loss: 0.9491
121/200, train_loss: 0.7441
122/200, train_loss: 0.8613
123/200, train_loss: 1.0924
124/200, train_loss: 0.8707
125/200, train_loss: 0.9985
126/200, train_loss: 0.9502
127/200, train_loss: 0.9154
128/200, train_loss: 1.1043
129/200, train_loss: 0.9306
130/200, train_loss: 0.7927
131/200, train_loss: 0.8784
132/200, train_loss: 0.9861
133/200, train_loss: 0.9870
134/200, train_loss: 0.9515
135/200, train_loss: 0.8630
136/200, train_loss: 0.7862
137/200, train_loss: 0.9366
138/200, train_loss: 1.0721
139/200, train_loss: 0.8850
140/200, train_loss: 1.0686
141/200, train_loss: 1.1163
142/200, train_loss: 0.8347
143/200, train_loss: 0.9694
144/200, train_loss: 0.9368
145/200, train_loss: 0.9013
146/200, train_loss: 0.9095
147/200, train_loss: 0.8215
148/200, train_loss: 1.0707
149/200, train_loss: 0.9343
150/200, train_loss: 0.9152
151/200, train_loss: 0.8548
152/200, train_loss: 0.9687
153/200, train_loss: 1.0883
154/200, train_loss: 0.8848
155/200, train_loss: 0.9025
156/200, train_loss: 0.9298
157/200, train_loss: 0.9920
158/200, train_loss: 0.8337
159/200, train_loss: 0.8785
160/200, train_loss: 1.0418
161/200, train_loss: 0.9155
162/200, train_loss: 0.9120
163/200, train_loss: 0.9908
164/200, train_loss: 0.9644
165/200, train_loss: 1.0850
166/200, train_loss: 0.9349
167/200, train_loss: 1.1388
168/200, train_loss: 0.9891
169/200, train_loss: 0.9947
170/200, train_loss: 0.7572
171/200, train_loss: 0.8956
172/200, train_loss: 0.9476
173/200, train_loss: 1.0045
174/200, train_loss: 0.9315
175/200, train_loss: 0.8924
176/200, train_loss: 1.0883
177/200, train_loss: 1.0734
178/200, train_loss: 0.8939
179/200, train_loss: 0.8633
180/200, train_loss: 0.9520
181/200, train_loss: 1.0094
182/200, train_loss: 0.8997
183/200, train_loss: 0.9453
184/200, train_loss: 1.0567
185/200, train_loss: 0.9332
186/200, train_loss: 0.9788
187/200, train_loss: 0.9432
188/200, train_loss: 0.9089
189/200, train_loss: 1.1486
190/200, train_loss: 1.1027
191/200, train_loss: 1.1383
192/200, train_loss: 0.9622
193/200, train_loss: 0.8450
194/200, train_loss: 0.9940
195/200, train_loss: 0.9020
196/200, train_loss: 0.9265
197/200, train_loss: 0.8165
198/200, train_loss: 0.9025
199/200, train_loss: 0.7637
200/200, train_loss: 1.0373
epoch 38 average loss: 0.9541
saved new best metric model
current epoch: 38 current mean dice: 0.4103 1: 0.3747 2: 0.4497
best mean dice: 0.4103 at epoch: 38
Epoch 38 completed
time consuming of epoch 38 is: 609.7846
----------
Epoch 39/50
1/200, train_loss: 0.9892
2/200, train_loss: 1.0600
3/200, train_loss: 0.9704
4/200, train_loss: 0.9039
5/200, train_loss: 0.8409
6/200, train_loss: 1.1134
7/200, train_loss: 1.0045
8/200, train_loss: 1.0443
9/200, train_loss: 0.9989
10/200, train_loss: 0.7598
11/200, train_loss: 1.0110
12/200, train_loss: 1.0080
13/200, train_loss: 0.9948
14/200, train_loss: 0.8608
15/200, train_loss: 1.0002
16/200, train_loss: 1.1252
17/200, train_loss: 0.9039
18/200, train_loss: 0.8134
19/200, train_loss: 0.8182
20/200, train_loss: 1.0056
21/200, train_loss: 0.9333
22/200, train_loss: 0.9372
23/200, train_loss: 1.2522
24/200, train_loss: 0.8494
25/200, train_loss: 0.9811
26/200, train_loss: 1.1279
27/200, train_loss: 1.0909
28/200, train_loss: 0.9512
29/200, train_loss: 0.8751
30/200, train_loss: 1.1589
31/200, train_loss: 1.0219
32/200, train_loss: 1.0713
33/200, train_loss: 0.9728
34/200, train_loss: 1.0728
35/200, train_loss: 0.8109
36/200, train_loss: 0.9425
37/200, train_loss: 0.8673
38/200, train_loss: 0.8406
39/200, train_loss: 0.9071
40/200, train_loss: 0.7953
41/200, train_loss: 0.8515
42/200, train_loss: 0.9833
43/200, train_loss: 0.9878
44/200, train_loss: 0.8747
45/200, train_loss: 1.0898
46/200, train_loss: 0.9123
47/200, train_loss: 0.8809
48/200, train_loss: 0.8371
49/200, train_loss: 0.8305
50/200, train_loss: 1.0882
51/200, train_loss: 1.0717
52/200, train_loss: 0.8608
53/200, train_loss: 0.8844
54/200, train_loss: 0.9741
55/200, train_loss: 1.0390
56/200, train_loss: 1.1315
57/200, train_loss: 1.0168
58/200, train_loss: 0.9350
59/200, train_loss: 0.8260
60/200, train_loss: 1.0819
61/200, train_loss: 1.0964
62/200, train_loss: 0.7982
63/200, train_loss: 0.8864
64/200, train_loss: 0.8552
65/200, train_loss: 1.0669
66/200, train_loss: 1.1792
67/200, train_loss: 1.1535
68/200, train_loss: 1.0373
69/200, train_loss: 1.0010
70/200, train_loss: 0.9271
71/200, train_loss: 1.0337
72/200, train_loss: 0.9306
73/200, train_loss: 0.9790
74/200, train_loss: 0.9988
75/200, train_loss: 0.8903
76/200, train_loss: 1.0594
77/200, train_loss: 1.0450
78/200, train_loss: 0.9837
79/200, train_loss: 0.9274
80/200, train_loss: 0.8926
81/200, train_loss: 0.8789
82/200, train_loss: 0.9449
83/200, train_loss: 0.9063
84/200, train_loss: 1.1631
85/200, train_loss: 0.8989
86/200, train_loss: 1.0168
87/200, train_loss: 0.9075
88/200, train_loss: 0.9167
89/200, train_loss: 0.7746
90/200, train_loss: 0.9401
91/200, train_loss: 1.0325
92/200, train_loss: 0.9219
93/200, train_loss: 1.0486
94/200, train_loss: 0.8687
95/200, train_loss: 1.1784
96/200, train_loss: 0.9206
97/200, train_loss: 0.9167
98/200, train_loss: 1.0582
99/200, train_loss: 0.9905
100/200, train_loss: 0.7790
101/200, train_loss: 1.1683
102/200, train_loss: 0.9127
103/200, train_loss: 1.1319
104/200, train_loss: 0.9248
105/200, train_loss: 0.8557
106/200, train_loss: 0.7932
107/200, train_loss: 0.8316
108/200, train_loss: 0.8671
109/200, train_loss: 0.9187
110/200, train_loss: 1.1436
111/200, train_loss: 0.8165
112/200, train_loss: 0.9500
113/200, train_loss: 0.9667
114/200, train_loss: 1.0636
115/200, train_loss: 0.9158
116/200, train_loss: 1.0030
117/200, train_loss: 1.0515
118/200, train_loss: 0.8819
119/200, train_loss: 0.8881
120/200, train_loss: 0.9646
121/200, train_loss: 0.8918
122/200, train_loss: 1.0280
123/200, train_loss: 0.9380
124/200, train_loss: 0.7931
125/200, train_loss: 0.9576
126/200, train_loss: 0.9056
127/200, train_loss: 0.9044
128/200, train_loss: 1.0278
129/200, train_loss: 0.8005
130/200, train_loss: 0.9490
131/200, train_loss: 0.8978
132/200, train_loss: 0.7752
133/200, train_loss: 0.8557
134/200, train_loss: 0.9013
135/200, train_loss: 0.9325
136/200, train_loss: 0.9005
137/200, train_loss: 1.1060
138/200, train_loss: 0.9423
139/200, train_loss: 1.0202
140/200, train_loss: 0.9080
141/200, train_loss: 0.8567
142/200, train_loss: 0.9965
143/200, train_loss: 0.9043
144/200, train_loss: 1.0159
145/200, train_loss: 0.9634
146/200, train_loss: 0.9315
147/200, train_loss: 0.9268
148/200, train_loss: 1.0290
149/200, train_loss: 0.8808
150/200, train_loss: 0.9966
151/200, train_loss: 0.8420
152/200, train_loss: 0.9506
153/200, train_loss: 0.8152
154/200, train_loss: 1.1321
155/200, train_loss: 0.9133
156/200, train_loss: 0.9484
157/200, train_loss: 0.8386
158/200, train_loss: 0.9638
159/200, train_loss: 1.0477
160/200, train_loss: 0.8922
161/200, train_loss: 0.8159
162/200, train_loss: 0.9029
163/200, train_loss: 0.8270
164/200, train_loss: 1.0945
165/200, train_loss: 1.0294
166/200, train_loss: 0.8269
167/200, train_loss: 1.1091
168/200, train_loss: 0.9471
169/200, train_loss: 0.8841
170/200, train_loss: 0.7660
171/200, train_loss: 0.9662
172/200, train_loss: 0.9501
173/200, train_loss: 0.7509
174/200, train_loss: 1.1451
175/200, train_loss: 0.9583
176/200, train_loss: 0.9761
177/200, train_loss: 0.8833
178/200, train_loss: 0.7912
179/200, train_loss: 1.0141
180/200, train_loss: 0.7774
181/200, train_loss: 1.0175
182/200, train_loss: 1.0223
183/200, train_loss: 0.9849
184/200, train_loss: 1.0524
185/200, train_loss: 1.0248
186/200, train_loss: 0.8781
187/200, train_loss: 0.9772
188/200, train_loss: 0.9704
189/200, train_loss: 0.8506
190/200, train_loss: 0.8764
191/200, train_loss: 0.9633
192/200, train_loss: 1.2439
193/200, train_loss: 1.0238
194/200, train_loss: 0.8298
195/200, train_loss: 0.9895
196/200, train_loss: 0.8641
197/200, train_loss: 0.9906
198/200, train_loss: 0.9020
199/200, train_loss: 1.0856
200/200, train_loss: 1.0953
epoch 39 average loss: 0.9552
current epoch: 39 current mean dice: 0.4040 1: 0.3555 2: 0.4570
best mean dice: 0.4103 at epoch: 38
Epoch 39 completed
time consuming of epoch 39 is: 590.4458
----------
Epoch 40/50
1/200, train_loss: 0.8549
2/200, train_loss: 1.0216
3/200, train_loss: 0.8748
4/200, train_loss: 0.9930
5/200, train_loss: 0.9636
6/200, train_loss: 0.8792
7/200, train_loss: 1.0355
8/200, train_loss: 0.8265
9/200, train_loss: 0.9134
10/200, train_loss: 0.8475
11/200, train_loss: 0.9346
12/200, train_loss: 0.8665
13/200, train_loss: 0.9574
14/200, train_loss: 0.9127
15/200, train_loss: 1.1262
16/200, train_loss: 0.8142
17/200, train_loss: 0.8656
18/200, train_loss: 0.8928
19/200, train_loss: 0.9222
20/200, train_loss: 0.8095
21/200, train_loss: 0.9815
22/200, train_loss: 0.9008
23/200, train_loss: 0.8852
24/200, train_loss: 0.9215
25/200, train_loss: 1.0712
26/200, train_loss: 0.8811
27/200, train_loss: 0.9517
28/200, train_loss: 0.8846
29/200, train_loss: 0.9434
30/200, train_loss: 0.9791
31/200, train_loss: 0.9063
32/200, train_loss: 1.0910
33/200, train_loss: 0.9525
34/200, train_loss: 0.9449
35/200, train_loss: 0.8449
36/200, train_loss: 0.9151
37/200, train_loss: 0.8683
38/200, train_loss: 0.9399
39/200, train_loss: 1.0763
40/200, train_loss: 0.9336
41/200, train_loss: 1.0092
42/200, train_loss: 0.7452
43/200, train_loss: 0.9935
44/200, train_loss: 1.1917
45/200, train_loss: 0.9331
46/200, train_loss: 1.0124
47/200, train_loss: 0.7700
48/200, train_loss: 1.0693
49/200, train_loss: 0.8793
50/200, train_loss: 1.1312
51/200, train_loss: 1.1612
52/200, train_loss: 0.9741
53/200, train_loss: 0.9567
54/200, train_loss: 0.9350
55/200, train_loss: 1.0471
56/200, train_loss: 0.9665
57/200, train_loss: 0.8321
58/200, train_loss: 0.9403
59/200, train_loss: 1.1611
60/200, train_loss: 1.1359
61/200, train_loss: 0.9508
62/200, train_loss: 0.9802
63/200, train_loss: 0.8573
64/200, train_loss: 0.8979
65/200, train_loss: 1.0430
66/200, train_loss: 0.9720
67/200, train_loss: 1.0673
68/200, train_loss: 0.7732
69/200, train_loss: 0.9583
70/200, train_loss: 0.8903
71/200, train_loss: 0.7963
72/200, train_loss: 0.7554
73/200, train_loss: 0.8576
74/200, train_loss: 0.8516
75/200, train_loss: 0.9928
76/200, train_loss: 1.0334
77/200, train_loss: 0.9011
78/200, train_loss: 1.0118
79/200, train_loss: 0.8818
80/200, train_loss: 0.9209
81/200, train_loss: 1.0329
82/200, train_loss: 0.8930
83/200, train_loss: 0.9885
84/200, train_loss: 1.0203
85/200, train_loss: 0.8255
86/200, train_loss: 0.9945
87/200, train_loss: 0.8613
88/200, train_loss: 0.8182
89/200, train_loss: 0.9154
90/200, train_loss: 0.9529
91/200, train_loss: 0.9442
92/200, train_loss: 0.7768
93/200, train_loss: 0.8734
94/200, train_loss: 0.9849
95/200, train_loss: 1.0705
96/200, train_loss: 1.0800
97/200, train_loss: 1.0118
98/200, train_loss: 0.8599
99/200, train_loss: 0.9868
100/200, train_loss: 0.8508
101/200, train_loss: 0.8896
102/200, train_loss: 1.0823
103/200, train_loss: 0.8749
104/200, train_loss: 1.0428
105/200, train_loss: 0.8912
106/200, train_loss: 0.8825
107/200, train_loss: 0.9971
108/200, train_loss: 1.0124
109/200, train_loss: 0.9882
110/200, train_loss: 1.0494
111/200, train_loss: 1.0218
112/200, train_loss: 0.7976
113/200, train_loss: 0.9328
114/200, train_loss: 1.0141
115/200, train_loss: 0.9938
116/200, train_loss: 0.8089
117/200, train_loss: 0.8951
118/200, train_loss: 0.9312
119/200, train_loss: 0.9707
120/200, train_loss: 1.0784
121/200, train_loss: 0.9393
122/200, train_loss: 0.9640
123/200, train_loss: 0.8939
124/200, train_loss: 1.0101
125/200, train_loss: 0.9622
126/200, train_loss: 0.7083
127/200, train_loss: 0.9344
128/200, train_loss: 0.9393
129/200, train_loss: 0.8382
130/200, train_loss: 0.9246
131/200, train_loss: 1.1173
132/200, train_loss: 1.0360
133/200, train_loss: 0.9615
134/200, train_loss: 0.9507
135/200, train_loss: 0.8428
136/200, train_loss: 1.0731
137/200, train_loss: 0.9431
138/200, train_loss: 1.0361
139/200, train_loss: 0.8074
140/200, train_loss: 0.9994
141/200, train_loss: 0.9380
142/200, train_loss: 1.0978
143/200, train_loss: 0.8558
144/200, train_loss: 0.9021
145/200, train_loss: 1.1120
146/200, train_loss: 0.9509
147/200, train_loss: 1.0593
148/200, train_loss: 0.9286
149/200, train_loss: 0.9801
150/200, train_loss: 0.8633
151/200, train_loss: 0.9922
152/200, train_loss: 1.1507
153/200, train_loss: 0.8288
154/200, train_loss: 0.9832
155/200, train_loss: 0.7308
156/200, train_loss: 0.9735
157/200, train_loss: 0.8363
158/200, train_loss: 0.7531
159/200, train_loss: 0.9751
160/200, train_loss: 0.9198
161/200, train_loss: 0.8294
162/200, train_loss: 0.9526
163/200, train_loss: 1.0532
164/200, train_loss: 0.8591
165/200, train_loss: 0.9027
166/200, train_loss: 0.8556
167/200, train_loss: 0.8766
168/200, train_loss: 0.8831
169/200, train_loss: 1.0835
170/200, train_loss: 0.9020
171/200, train_loss: 0.9127
172/200, train_loss: 1.1330
173/200, train_loss: 0.9393
174/200, train_loss: 1.1343
175/200, train_loss: 1.0066
176/200, train_loss: 0.8336
177/200, train_loss: 0.9002
178/200, train_loss: 1.0366
179/200, train_loss: 0.7877
180/200, train_loss: 0.9240
181/200, train_loss: 1.0810
182/200, train_loss: 1.0033
183/200, train_loss: 0.9051
184/200, train_loss: 0.7567
185/200, train_loss: 1.0214
186/200, train_loss: 0.9799
187/200, train_loss: 1.1563
188/200, train_loss: 1.1532
189/200, train_loss: 0.9068
190/200, train_loss: 0.9319
191/200, train_loss: 0.9798
192/200, train_loss: 1.1199
193/200, train_loss: 0.8981
194/200, train_loss: 0.9932
195/200, train_loss: 0.8751
196/200, train_loss: 0.9422
197/200, train_loss: 0.9258
198/200, train_loss: 0.8261
199/200, train_loss: 1.0781
200/200, train_loss: 0.9082
epoch 40 average loss: 0.9464
current epoch: 40 current mean dice: 0.4064 1: 0.3584 2: 0.4590
best mean dice: 0.4103 at epoch: 38
Epoch 40 completed
time consuming of epoch 40 is: 586.6863
----------
Epoch 41/50
1/200, train_loss: 0.8556
2/200, train_loss: 0.8224
3/200, train_loss: 1.0403
4/200, train_loss: 0.8837
5/200, train_loss: 0.7975
6/200, train_loss: 0.8748
7/200, train_loss: 0.9373
8/200, train_loss: 0.9285
9/200, train_loss: 1.0324
10/200, train_loss: 1.0081
11/200, train_loss: 0.8040
12/200, train_loss: 0.7275
13/200, train_loss: 1.0011
14/200, train_loss: 1.0894
15/200, train_loss: 0.9846
16/200, train_loss: 1.0558
17/200, train_loss: 0.9681
18/200, train_loss: 0.9629
19/200, train_loss: 0.8151
20/200, train_loss: 0.9386
21/200, train_loss: 0.9198
22/200, train_loss: 1.0895
23/200, train_loss: 0.8412
24/200, train_loss: 1.1436
25/200, train_loss: 0.7831
26/200, train_loss: 0.9026
27/200, train_loss: 0.9041
28/200, train_loss: 1.0292
29/200, train_loss: 1.0692
30/200, train_loss: 0.8464
31/200, train_loss: 0.9692
32/200, train_loss: 0.8153
33/200, train_loss: 0.9544
34/200, train_loss: 0.9927
35/200, train_loss: 0.8743
36/200, train_loss: 1.0724
37/200, train_loss: 0.8644
38/200, train_loss: 0.9452
39/200, train_loss: 1.0116
40/200, train_loss: 0.9487
41/200, train_loss: 0.9155
42/200, train_loss: 1.1314
43/200, train_loss: 1.0382
44/200, train_loss: 0.9282
45/200, train_loss: 0.7345
46/200, train_loss: 1.1026
47/200, train_loss: 0.7981
48/200, train_loss: 0.9274
49/200, train_loss: 0.8747
50/200, train_loss: 0.8471
51/200, train_loss: 0.8142
52/200, train_loss: 0.8691
53/200, train_loss: 0.9686
54/200, train_loss: 0.8267
55/200, train_loss: 0.7723
56/200, train_loss: 0.8652
57/200, train_loss: 1.1228
58/200, train_loss: 1.0203
59/200, train_loss: 0.9485
60/200, train_loss: 1.0680
61/200, train_loss: 1.1456
62/200, train_loss: 0.9304
63/200, train_loss: 0.9741
64/200, train_loss: 0.9797
65/200, train_loss: 1.0607
66/200, train_loss: 0.9966
67/200, train_loss: 0.9035
68/200, train_loss: 0.7471
69/200, train_loss: 0.8319
70/200, train_loss: 1.1088
71/200, train_loss: 1.1526
72/200, train_loss: 1.0283
73/200, train_loss: 0.8828
74/200, train_loss: 1.0301
75/200, train_loss: 0.9560
76/200, train_loss: 1.0516
77/200, train_loss: 0.9455
78/200, train_loss: 0.9148
79/200, train_loss: 0.9688
80/200, train_loss: 0.8918
81/200, train_loss: 0.8303
82/200, train_loss: 1.0091
83/200, train_loss: 0.8773
84/200, train_loss: 0.8258
85/200, train_loss: 1.0175
86/200, train_loss: 0.9732
87/200, train_loss: 1.0335
88/200, train_loss: 0.7215
89/200, train_loss: 0.7743
90/200, train_loss: 0.8410
91/200, train_loss: 0.8144
92/200, train_loss: 1.0821
93/200, train_loss: 0.9200
94/200, train_loss: 0.9909
95/200, train_loss: 0.9184
96/200, train_loss: 0.9158
97/200, train_loss: 0.9196
98/200, train_loss: 0.9378
99/200, train_loss: 1.0021
100/200, train_loss: 1.0307
101/200, train_loss: 1.0006
102/200, train_loss: 1.0076
103/200, train_loss: 1.0168
104/200, train_loss: 0.7827
105/200, train_loss: 0.8443
106/200, train_loss: 0.8235
107/200, train_loss: 0.8493
108/200, train_loss: 0.8803
109/200, train_loss: 1.1078
110/200, train_loss: 0.8373
111/200, train_loss: 0.8634
112/200, train_loss: 0.9994
113/200, train_loss: 0.9276
114/200, train_loss: 0.9290
115/200, train_loss: 0.9706
116/200, train_loss: 0.8665
117/200, train_loss: 0.7606
118/200, train_loss: 0.9980
119/200, train_loss: 0.9853
120/200, train_loss: 0.9832
121/200, train_loss: 0.8993
122/200, train_loss: 0.8799
123/200, train_loss: 0.9796
124/200, train_loss: 0.7740
125/200, train_loss: 1.0256
126/200, train_loss: 0.9006
127/200, train_loss: 1.0209
128/200, train_loss: 0.8370
129/200, train_loss: 0.8269
130/200, train_loss: 1.0844
131/200, train_loss: 1.0112
132/200, train_loss: 1.0749
133/200, train_loss: 1.0231
134/200, train_loss: 0.9365
135/200, train_loss: 1.0262
136/200, train_loss: 0.8008
137/200, train_loss: 1.0006
138/200, train_loss: 0.8279
139/200, train_loss: 0.7510
140/200, train_loss: 0.9603
141/200, train_loss: 0.7693
142/200, train_loss: 0.9736
143/200, train_loss: 1.0288
144/200, train_loss: 0.9203
145/200, train_loss: 0.9340
146/200, train_loss: 0.9956
147/200, train_loss: 0.8928
148/200, train_loss: 1.1095
149/200, train_loss: 0.9089
150/200, train_loss: 1.0045
151/200, train_loss: 0.8486
152/200, train_loss: 1.0782
153/200, train_loss: 0.8225
154/200, train_loss: 0.9727
155/200, train_loss: 0.9907
156/200, train_loss: 0.9180
157/200, train_loss: 1.0497
158/200, train_loss: 0.8356
159/200, train_loss: 1.0743
160/200, train_loss: 0.9331
161/200, train_loss: 0.7879
162/200, train_loss: 0.9367
163/200, train_loss: 0.9325
164/200, train_loss: 0.8628
165/200, train_loss: 0.8378
166/200, train_loss: 0.9522
167/200, train_loss: 1.0542
168/200, train_loss: 1.0140
169/200, train_loss: 0.8120
170/200, train_loss: 0.9103
171/200, train_loss: 1.0819
172/200, train_loss: 0.9625
173/200, train_loss: 0.9031
174/200, train_loss: 1.0585
175/200, train_loss: 1.1208
176/200, train_loss: 0.9062
177/200, train_loss: 1.0432
178/200, train_loss: 1.0134
179/200, train_loss: 0.8852
180/200, train_loss: 1.0506
181/200, train_loss: 0.8656
182/200, train_loss: 0.9144
183/200, train_loss: 0.7380
184/200, train_loss: 1.0067
185/200, train_loss: 0.9393
186/200, train_loss: 0.9834
187/200, train_loss: 0.9919
188/200, train_loss: 0.9589
189/200, train_loss: 0.9519
190/200, train_loss: 0.8902
191/200, train_loss: 0.9649
192/200, train_loss: 0.9272
193/200, train_loss: 0.9397
194/200, train_loss: 0.7933
195/200, train_loss: 0.9681
196/200, train_loss: 0.9875
197/200, train_loss: 0.9630
198/200, train_loss: 1.0134
199/200, train_loss: 0.9528
200/200, train_loss: 0.8147
epoch 41 average loss: 0.9392
current epoch: 41 current mean dice: 0.3960 1: 0.3580 2: 0.4363
best mean dice: 0.4103 at epoch: 38
Epoch 41 completed
time consuming of epoch 41 is: 582.5481
----------
Epoch 42/50
1/200, train_loss: 0.9832
2/200, train_loss: 0.7801
3/200, train_loss: 0.8092
4/200, train_loss: 0.8535
5/200, train_loss: 0.9527
6/200, train_loss: 0.9327
7/200, train_loss: 0.9209
8/200, train_loss: 0.8142
9/200, train_loss: 0.8678
10/200, train_loss: 1.0007
11/200, train_loss: 0.8120
12/200, train_loss: 0.9721
13/200, train_loss: 0.9836
14/200, train_loss: 0.7623
15/200, train_loss: 0.9294
16/200, train_loss: 1.0248
17/200, train_loss: 0.8267
18/200, train_loss: 0.8764
19/200, train_loss: 0.8935
20/200, train_loss: 0.9261
21/200, train_loss: 0.8312
22/200, train_loss: 0.9848
23/200, train_loss: 0.8721
24/200, train_loss: 0.8864
25/200, train_loss: 0.9010
26/200, train_loss: 0.8155
27/200, train_loss: 0.8951
28/200, train_loss: 1.0265
29/200, train_loss: 0.9150
30/200, train_loss: 0.9733
31/200, train_loss: 0.8736
32/200, train_loss: 1.0991
33/200, train_loss: 0.8739
34/200, train_loss: 1.1056
35/200, train_loss: 0.9288
36/200, train_loss: 0.8525
37/200, train_loss: 1.0752
38/200, train_loss: 0.8848
39/200, train_loss: 0.9947
40/200, train_loss: 1.0669
41/200, train_loss: 1.0314
42/200, train_loss: 0.8734
43/200, train_loss: 0.8106
44/200, train_loss: 1.1354
45/200, train_loss: 1.0849
46/200, train_loss: 0.8221
47/200, train_loss: 1.1256
48/200, train_loss: 0.8663
49/200, train_loss: 0.9374
50/200, train_loss: 0.9744
51/200, train_loss: 1.0729
52/200, train_loss: 0.8086
53/200, train_loss: 1.0289
54/200, train_loss: 0.7293
55/200, train_loss: 0.9722
56/200, train_loss: 0.8462
57/200, train_loss: 0.9820
58/200, train_loss: 0.8819
59/200, train_loss: 0.9861
60/200, train_loss: 1.0272
61/200, train_loss: 0.8402
62/200, train_loss: 0.8610
63/200, train_loss: 0.9540
64/200, train_loss: 0.7656
65/200, train_loss: 1.0373
66/200, train_loss: 1.0575
67/200, train_loss: 0.8252
68/200, train_loss: 1.0821
69/200, train_loss: 0.9044
70/200, train_loss: 1.0305
71/200, train_loss: 0.8423
72/200, train_loss: 0.9103
73/200, train_loss: 0.9863
74/200, train_loss: 0.9842
75/200, train_loss: 1.0350
76/200, train_loss: 1.0205
77/200, train_loss: 0.9777
78/200, train_loss: 0.7858
79/200, train_loss: 0.7559
80/200, train_loss: 0.9332
81/200, train_loss: 0.7449
82/200, train_loss: 1.0391
83/200, train_loss: 0.9507
84/200, train_loss: 0.8743
85/200, train_loss: 0.9798
86/200, train_loss: 1.0588
87/200, train_loss: 0.8761
88/200, train_loss: 1.0354
89/200, train_loss: 1.0783
90/200, train_loss: 0.8732
91/200, train_loss: 1.0075
92/200, train_loss: 0.8715
93/200, train_loss: 1.0472
94/200, train_loss: 0.9444
95/200, train_loss: 0.9915
96/200, train_loss: 0.8485
97/200, train_loss: 0.8396
98/200, train_loss: 0.9327
99/200, train_loss: 0.7298
100/200, train_loss: 0.8731
101/200, train_loss: 0.9514
102/200, train_loss: 0.9875
103/200, train_loss: 0.8843
104/200, train_loss: 1.1389
105/200, train_loss: 0.7766
106/200, train_loss: 0.8583
107/200, train_loss: 0.7899
108/200, train_loss: 0.7950
109/200, train_loss: 0.8488
110/200, train_loss: 1.0104
111/200, train_loss: 1.0039
112/200, train_loss: 0.8597
113/200, train_loss: 1.0529
114/200, train_loss: 0.7982
115/200, train_loss: 0.9356
116/200, train_loss: 0.8789
117/200, train_loss: 1.0276
118/200, train_loss: 0.9764
119/200, train_loss: 0.8947
120/200, train_loss: 0.9356
121/200, train_loss: 0.9317
122/200, train_loss: 0.8237
123/200, train_loss: 1.1114
124/200, train_loss: 1.0614
125/200, train_loss: 1.0513
126/200, train_loss: 1.0266
127/200, train_loss: 1.0984
128/200, train_loss: 0.9028
129/200, train_loss: 0.9686
130/200, train_loss: 0.9371
131/200, train_loss: 0.9035
132/200, train_loss: 0.9906
133/200, train_loss: 1.0303
134/200, train_loss: 0.8392
135/200, train_loss: 0.8568
136/200, train_loss: 1.1043
137/200, train_loss: 0.8173
138/200, train_loss: 0.7685
139/200, train_loss: 1.0417
140/200, train_loss: 0.9591
141/200, train_loss: 0.8991
142/200, train_loss: 0.9084
143/200, train_loss: 0.9238
144/200, train_loss: 0.9234
145/200, train_loss: 1.1436
146/200, train_loss: 0.8606
147/200, train_loss: 1.0645
148/200, train_loss: 0.9007
149/200, train_loss: 0.9730
150/200, train_loss: 0.8535
151/200, train_loss: 1.0190
152/200, train_loss: 0.8884
153/200, train_loss: 0.9520
154/200, train_loss: 1.1439
155/200, train_loss: 0.8824
156/200, train_loss: 0.8403
157/200, train_loss: 1.0287
158/200, train_loss: 0.9656
159/200, train_loss: 1.1815
160/200, train_loss: 0.8690
161/200, train_loss: 0.9226
162/200, train_loss: 0.8753
163/200, train_loss: 0.9567
164/200, train_loss: 1.1056
165/200, train_loss: 0.9360
166/200, train_loss: 0.9093
167/200, train_loss: 1.1198
168/200, train_loss: 0.8876
169/200, train_loss: 1.0169
170/200, train_loss: 0.8422
171/200, train_loss: 0.8463
172/200, train_loss: 0.7948
173/200, train_loss: 1.0411
174/200, train_loss: 0.9219
175/200, train_loss: 0.9569
176/200, train_loss: 1.0714
177/200, train_loss: 0.9015
178/200, train_loss: 0.9071
179/200, train_loss: 0.7972
180/200, train_loss: 0.9154
181/200, train_loss: 0.9522
182/200, train_loss: 0.8335
183/200, train_loss: 0.8258
184/200, train_loss: 0.9324
185/200, train_loss: 1.0592
186/200, train_loss: 0.8791
187/200, train_loss: 1.0908
188/200, train_loss: 0.8979
189/200, train_loss: 0.7648
190/200, train_loss: 0.8281
191/200, train_loss: 1.0149
192/200, train_loss: 0.9978
193/200, train_loss: 0.8287
194/200, train_loss: 0.8778
195/200, train_loss: 0.9508
196/200, train_loss: 0.9178
197/200, train_loss: 0.9050
198/200, train_loss: 0.7702
199/200, train_loss: 1.0323
200/200, train_loss: 0.9026
epoch 42 average loss: 0.9340
current epoch: 42 current mean dice: 0.4072 1: 0.3664 2: 0.4517
best mean dice: 0.4103 at epoch: 38
Epoch 42 completed
time consuming of epoch 42 is: 582.9883
----------
Epoch 43/50
1/200, train_loss: 0.8905
2/200, train_loss: 1.0853
3/200, train_loss: 0.8656
4/200, train_loss: 0.8039
5/200, train_loss: 0.9167
6/200, train_loss: 0.9606
7/200, train_loss: 1.0234
8/200, train_loss: 0.8183
9/200, train_loss: 0.8490
10/200, train_loss: 1.0199
11/200, train_loss: 0.8350
12/200, train_loss: 0.6703
13/200, train_loss: 0.9237
14/200, train_loss: 1.0402
15/200, train_loss: 1.0621
16/200, train_loss: 0.7819
17/200, train_loss: 0.9940
18/200, train_loss: 1.0111
19/200, train_loss: 0.8594
20/200, train_loss: 0.9943
21/200, train_loss: 0.9604
22/200, train_loss: 1.0067
23/200, train_loss: 1.0558
24/200, train_loss: 1.1277
25/200, train_loss: 0.9214
26/200, train_loss: 0.9926
27/200, train_loss: 0.7431
28/200, train_loss: 0.8077
29/200, train_loss: 0.8319
30/200, train_loss: 0.9331
31/200, train_loss: 0.8348
32/200, train_loss: 0.8989
33/200, train_loss: 0.9901
34/200, train_loss: 1.0238
35/200, train_loss: 0.8177
36/200, train_loss: 0.8021
37/200, train_loss: 1.0192
38/200, train_loss: 1.0265
39/200, train_loss: 1.0364
40/200, train_loss: 0.9231
41/200, train_loss: 0.8333
42/200, train_loss: 0.9988
43/200, train_loss: 1.0495
44/200, train_loss: 0.7471
45/200, train_loss: 0.9772
46/200, train_loss: 0.9004
47/200, train_loss: 1.0074
48/200, train_loss: 0.8624
49/200, train_loss: 0.9327
50/200, train_loss: 0.8671
51/200, train_loss: 1.0161
52/200, train_loss: 0.9462
53/200, train_loss: 0.9385
54/200, train_loss: 1.1560
55/200, train_loss: 0.7480
56/200, train_loss: 0.7229
57/200, train_loss: 0.9985
58/200, train_loss: 1.0188
59/200, train_loss: 0.9141
60/200, train_loss: 0.8789
61/200, train_loss: 0.8193
62/200, train_loss: 0.8390
63/200, train_loss: 0.8087
64/200, train_loss: 1.0454
65/200, train_loss: 1.0044
66/200, train_loss: 0.9113
67/200, train_loss: 0.9311
68/200, train_loss: 0.8709
69/200, train_loss: 1.0677
70/200, train_loss: 0.8948
71/200, train_loss: 1.0142
72/200, train_loss: 1.0546
73/200, train_loss: 0.8980
74/200, train_loss: 0.9598
75/200, train_loss: 0.8658
76/200, train_loss: 0.9786
77/200, train_loss: 1.0698
78/200, train_loss: 0.9515
79/200, train_loss: 1.0300
80/200, train_loss: 0.9990
81/200, train_loss: 0.8798
82/200, train_loss: 1.0199
83/200, train_loss: 1.1723
84/200, train_loss: 0.9272
85/200, train_loss: 1.0112
86/200, train_loss: 0.9795
87/200, train_loss: 1.0076
88/200, train_loss: 0.8250
89/200, train_loss: 0.7848
90/200, train_loss: 1.0378
91/200, train_loss: 0.8205
92/200, train_loss: 0.8593
93/200, train_loss: 1.1198
94/200, train_loss: 0.8808
95/200, train_loss: 1.0218
96/200, train_loss: 0.9260
97/200, train_loss: 0.9741
98/200, train_loss: 0.8616
99/200, train_loss: 0.9743
100/200, train_loss: 0.7821
101/200, train_loss: 0.8709
102/200, train_loss: 1.0072
103/200, train_loss: 0.6898
104/200, train_loss: 1.1700
105/200, train_loss: 1.0057
106/200, train_loss: 0.9621
107/200, train_loss: 0.8455
108/200, train_loss: 0.7970
109/200, train_loss: 0.9961
110/200, train_loss: 0.9393
111/200, train_loss: 0.8676
112/200, train_loss: 0.8351
113/200, train_loss: 0.9457
114/200, train_loss: 0.8614
115/200, train_loss: 0.9221
116/200, train_loss: 1.0677
117/200, train_loss: 0.9666
118/200, train_loss: 1.0100
119/200, train_loss: 0.9122
120/200, train_loss: 0.8414
121/200, train_loss: 0.9752
122/200, train_loss: 1.0799
123/200, train_loss: 1.0037
124/200, train_loss: 1.0282
125/200, train_loss: 0.8004
126/200, train_loss: 0.8664
127/200, train_loss: 1.0895
128/200, train_loss: 1.0450
129/200, train_loss: 0.9206
130/200, train_loss: 0.9417
131/200, train_loss: 0.8907
132/200, train_loss: 1.0753
133/200, train_loss: 1.1635
134/200, train_loss: 1.0243
135/200, train_loss: 0.8959
136/200, train_loss: 1.0883
137/200, train_loss: 0.7455
138/200, train_loss: 1.0940
139/200, train_loss: 0.8719
140/200, train_loss: 0.8704
141/200, train_loss: 0.7609
142/200, train_loss: 0.9012
143/200, train_loss: 0.9962
144/200, train_loss: 0.8631
145/200, train_loss: 0.9452
146/200, train_loss: 0.8934
147/200, train_loss: 0.8530
148/200, train_loss: 0.9337
149/200, train_loss: 1.1315
150/200, train_loss: 0.9381
151/200, train_loss: 0.9990
152/200, train_loss: 1.0409
153/200, train_loss: 0.9457
154/200, train_loss: 0.9938
155/200, train_loss: 0.8914
156/200, train_loss: 0.7460
157/200, train_loss: 0.7381
158/200, train_loss: 1.1206
159/200, train_loss: 0.9167
160/200, train_loss: 0.8247
161/200, train_loss: 1.0116
162/200, train_loss: 0.8115
163/200, train_loss: 0.9406
164/200, train_loss: 0.7667
165/200, train_loss: 0.9218
166/200, train_loss: 0.9129
167/200, train_loss: 1.1621
168/200, train_loss: 1.0482
169/200, train_loss: 1.0185
170/200, train_loss: 0.8719
171/200, train_loss: 0.9020
172/200, train_loss: 1.1248
173/200, train_loss: 0.7491
174/200, train_loss: 0.8684
175/200, train_loss: 0.8538
176/200, train_loss: 0.8585
177/200, train_loss: 0.7171
178/200, train_loss: 0.9463
179/200, train_loss: 0.9519
180/200, train_loss: 0.9224
181/200, train_loss: 0.8526
182/200, train_loss: 0.9918
183/200, train_loss: 1.0594
184/200, train_loss: 0.7755
185/200, train_loss: 1.0565
186/200, train_loss: 0.7812
187/200, train_loss: 0.9759
188/200, train_loss: 0.8604
189/200, train_loss: 0.9314
190/200, train_loss: 1.0622
191/200, train_loss: 0.8500
192/200, train_loss: 1.1416
193/200, train_loss: 0.9291
194/200, train_loss: 0.9026
195/200, train_loss: 0.8341
196/200, train_loss: 1.0439
197/200, train_loss: 1.0144
198/200, train_loss: 1.0744
199/200, train_loss: 0.9533
200/200, train_loss: 0.8454
epoch 43 average loss: 0.9363
current epoch: 43 current mean dice: 0.4043 1: 0.3569 2: 0.4556
best mean dice: 0.4103 at epoch: 38
Epoch 43 completed
time consuming of epoch 43 is: 587.1752
----------
Epoch 44/50
1/200, train_loss: 0.7733
2/200, train_loss: 0.9457
3/200, train_loss: 0.9083
4/200, train_loss: 0.7550
5/200, train_loss: 0.8947
6/200, train_loss: 0.8439
7/200, train_loss: 0.9735
8/200, train_loss: 0.9036
9/200, train_loss: 0.9422
10/200, train_loss: 0.9258
11/200, train_loss: 1.0363
12/200, train_loss: 0.6592
13/200, train_loss: 0.9145
14/200, train_loss: 0.9246
15/200, train_loss: 0.8549
16/200, train_loss: 0.8219
17/200, train_loss: 0.9865
18/200, train_loss: 0.9168
19/200, train_loss: 0.7646
20/200, train_loss: 0.9565
21/200, train_loss: 1.0862
22/200, train_loss: 0.9445
23/200, train_loss: 0.9509
24/200, train_loss: 0.9360
25/200, train_loss: 0.9426
26/200, train_loss: 0.8855
27/200, train_loss: 0.8486
28/200, train_loss: 1.0325
29/200, train_loss: 0.8972
30/200, train_loss: 0.9017
31/200, train_loss: 0.8718
32/200, train_loss: 0.9259
33/200, train_loss: 1.1087
34/200, train_loss: 0.9545
35/200, train_loss: 0.8261
36/200, train_loss: 0.9976
37/200, train_loss: 0.9498
38/200, train_loss: 0.9523
39/200, train_loss: 1.0262
40/200, train_loss: 0.8269
41/200, train_loss: 0.9474
42/200, train_loss: 0.7558
43/200, train_loss: 0.8634
44/200, train_loss: 0.8791
45/200, train_loss: 0.8514
46/200, train_loss: 0.8609
47/200, train_loss: 0.9713
48/200, train_loss: 0.9456
49/200, train_loss: 0.8850
50/200, train_loss: 0.8713
51/200, train_loss: 1.1292
52/200, train_loss: 1.0208
53/200, train_loss: 0.9243
54/200, train_loss: 0.9310
55/200, train_loss: 0.9634
56/200, train_loss: 0.8516
57/200, train_loss: 0.9531
58/200, train_loss: 1.0066
59/200, train_loss: 1.0524
60/200, train_loss: 0.9490
61/200, train_loss: 0.9295
62/200, train_loss: 0.9989
63/200, train_loss: 0.9264
64/200, train_loss: 0.9835
65/200, train_loss: 1.0282
66/200, train_loss: 1.0963
67/200, train_loss: 0.9174
68/200, train_loss: 0.9355
69/200, train_loss: 0.9216
70/200, train_loss: 0.8109
71/200, train_loss: 1.0559
72/200, train_loss: 1.0406
73/200, train_loss: 0.8702
74/200, train_loss: 0.8580
75/200, train_loss: 0.9109
76/200, train_loss: 0.9292
77/200, train_loss: 0.8810
78/200, train_loss: 0.9730
79/200, train_loss: 0.8782
80/200, train_loss: 0.8853
81/200, train_loss: 0.8923
82/200, train_loss: 0.7802
83/200, train_loss: 1.0204
84/200, train_loss: 1.0566
85/200, train_loss: 0.8127
86/200, train_loss: 0.8091
87/200, train_loss: 1.0201
88/200, train_loss: 1.0460
89/200, train_loss: 0.9593
90/200, train_loss: 1.0039
91/200, train_loss: 0.8900
92/200, train_loss: 0.9328
93/200, train_loss: 0.9828
94/200, train_loss: 1.0196
95/200, train_loss: 0.8497
96/200, train_loss: 1.0136
97/200, train_loss: 0.9727
98/200, train_loss: 1.1066
99/200, train_loss: 0.8972
100/200, train_loss: 1.0069
101/200, train_loss: 0.9928
102/200, train_loss: 0.8423
103/200, train_loss: 0.9298
104/200, train_loss: 1.0377
105/200, train_loss: 1.0158
106/200, train_loss: 0.9317
107/200, train_loss: 0.7803
108/200, train_loss: 1.0975
109/200, train_loss: 0.7717
110/200, train_loss: 0.9258
111/200, train_loss: 0.9580
112/200, train_loss: 1.1524
113/200, train_loss: 1.0797
114/200, train_loss: 1.2133
115/200, train_loss: 1.0702
116/200, train_loss: 0.8486
117/200, train_loss: 0.9322
118/200, train_loss: 0.9134
119/200, train_loss: 0.8520
120/200, train_loss: 0.9196
121/200, train_loss: 0.9851
122/200, train_loss: 0.9819
123/200, train_loss: 1.0953
124/200, train_loss: 0.9417
125/200, train_loss: 1.0334
126/200, train_loss: 1.2739
127/200, train_loss: 1.1016
128/200, train_loss: 0.9461
129/200, train_loss: 0.9188
130/200, train_loss: 0.9934
131/200, train_loss: 0.9370
132/200, train_loss: 0.7999
133/200, train_loss: 1.0015
134/200, train_loss: 0.8079
135/200, train_loss: 0.9938
136/200, train_loss: 0.8692
137/200, train_loss: 0.8704
138/200, train_loss: 0.9186
139/200, train_loss: 0.9110
140/200, train_loss: 0.9740
141/200, train_loss: 1.1330
142/200, train_loss: 0.9599
143/200, train_loss: 0.9022
144/200, train_loss: 0.8617
145/200, train_loss: 0.8328
146/200, train_loss: 1.1401
147/200, train_loss: 1.0081
148/200, train_loss: 0.9315
149/200, train_loss: 0.7690
150/200, train_loss: 0.8370
151/200, train_loss: 1.0838
152/200, train_loss: 0.8888
153/200, train_loss: 0.8084
154/200, train_loss: 0.8849
155/200, train_loss: 0.8972
156/200, train_loss: 0.8647
157/200, train_loss: 0.7739
158/200, train_loss: 1.0163
159/200, train_loss: 0.9535
160/200, train_loss: 1.0196
161/200, train_loss: 1.0700
162/200, train_loss: 0.9135
163/200, train_loss: 1.0241
164/200, train_loss: 0.9418
165/200, train_loss: 0.9870
166/200, train_loss: 0.8597
167/200, train_loss: 0.9552
168/200, train_loss: 0.7310
169/200, train_loss: 1.0960
170/200, train_loss: 0.8434
171/200, train_loss: 0.8149
172/200, train_loss: 0.8013
173/200, train_loss: 1.0069
174/200, train_loss: 1.0850
175/200, train_loss: 1.0548
176/200, train_loss: 0.9391
177/200, train_loss: 0.9210
178/200, train_loss: 0.9058
179/200, train_loss: 0.9348
180/200, train_loss: 1.1370
181/200, train_loss: 0.9455
182/200, train_loss: 0.8750
183/200, train_loss: 1.0982
184/200, train_loss: 0.8864
185/200, train_loss: 1.0560
186/200, train_loss: 0.8750
187/200, train_loss: 1.1256
188/200, train_loss: 0.8659
189/200, train_loss: 0.7900
190/200, train_loss: 0.8542
191/200, train_loss: 0.9014
192/200, train_loss: 0.8240
193/200, train_loss: 0.8932
194/200, train_loss: 0.7815
195/200, train_loss: 0.8332
196/200, train_loss: 0.9502
197/200, train_loss: 0.9009
198/200, train_loss: 0.9090
199/200, train_loss: 1.0100
200/200, train_loss: 0.8941
epoch 44 average loss: 0.9378
current epoch: 44 current mean dice: 0.4082 1: 0.3686 2: 0.4509
best mean dice: 0.4103 at epoch: 38
Epoch 44 completed
time consuming of epoch 44 is: 583.8380
----------
Epoch 45/50
1/200, train_loss: 1.0228
2/200, train_loss: 0.8396
3/200, train_loss: 0.8434
4/200, train_loss: 0.7487
5/200, train_loss: 1.0781
6/200, train_loss: 0.9881
7/200, train_loss: 0.9363
8/200, train_loss: 0.9804
9/200, train_loss: 1.1171
10/200, train_loss: 0.8225
11/200, train_loss: 1.0126
12/200, train_loss: 0.7590
13/200, train_loss: 0.8046
14/200, train_loss: 0.8332
15/200, train_loss: 1.0071
16/200, train_loss: 0.8735
17/200, train_loss: 0.7681
18/200, train_loss: 0.7508
19/200, train_loss: 1.1862
20/200, train_loss: 0.9666
21/200, train_loss: 0.7300
22/200, train_loss: 0.9665
23/200, train_loss: 0.9061
24/200, train_loss: 0.9385
25/200, train_loss: 0.8607
26/200, train_loss: 1.0689
27/200, train_loss: 0.9495
28/200, train_loss: 0.9683
29/200, train_loss: 0.9365
30/200, train_loss: 0.9665
31/200, train_loss: 0.8733
32/200, train_loss: 0.9931
33/200, train_loss: 0.8922
34/200, train_loss: 1.0301
35/200, train_loss: 0.7861
36/200, train_loss: 0.8483
37/200, train_loss: 1.0078
38/200, train_loss: 0.8969
39/200, train_loss: 0.8093
40/200, train_loss: 0.9648
41/200, train_loss: 1.0379
42/200, train_loss: 0.9256
43/200, train_loss: 1.0522
44/200, train_loss: 1.1429
45/200, train_loss: 0.8378
46/200, train_loss: 1.1326
47/200, train_loss: 0.9116
48/200, train_loss: 0.9168
49/200, train_loss: 0.8983
50/200, train_loss: 1.0403
51/200, train_loss: 0.8279
52/200, train_loss: 0.8774
53/200, train_loss: 0.9459
54/200, train_loss: 0.8846
55/200, train_loss: 0.7959
56/200, train_loss: 0.8663
57/200, train_loss: 0.8437
58/200, train_loss: 0.9035
59/200, train_loss: 0.9175
60/200, train_loss: 1.0498
61/200, train_loss: 1.0451
62/200, train_loss: 0.8751
63/200, train_loss: 1.0093
64/200, train_loss: 1.0894
65/200, train_loss: 0.8129
66/200, train_loss: 1.0283
67/200, train_loss: 0.9019
68/200, train_loss: 0.7362
69/200, train_loss: 0.9814
70/200, train_loss: 1.0211
71/200, train_loss: 1.0655
72/200, train_loss: 0.9549
73/200, train_loss: 0.7903
74/200, train_loss: 0.9340
75/200, train_loss: 0.8237
76/200, train_loss: 0.9847
77/200, train_loss: 0.8919
78/200, train_loss: 0.8461
79/200, train_loss: 0.7897
80/200, train_loss: 0.9852
81/200, train_loss: 1.0530
82/200, train_loss: 0.8391
83/200, train_loss: 0.9883
84/200, train_loss: 0.8988
85/200, train_loss: 0.9290
86/200, train_loss: 0.8550
87/200, train_loss: 1.0065
88/200, train_loss: 0.8001
89/200, train_loss: 0.8468
90/200, train_loss: 0.8659
91/200, train_loss: 0.8966
92/200, train_loss: 0.9399
93/200, train_loss: 0.9608
94/200, train_loss: 1.0575
95/200, train_loss: 1.0909
96/200, train_loss: 1.1067
97/200, train_loss: 0.9086
98/200, train_loss: 0.9474
99/200, train_loss: 0.9484
100/200, train_loss: 0.9043
101/200, train_loss: 0.9289
102/200, train_loss: 0.8635
103/200, train_loss: 0.9038
104/200, train_loss: 1.0255
105/200, train_loss: 1.2331
106/200, train_loss: 1.1310
107/200, train_loss: 1.0465
108/200, train_loss: 0.8068
109/200, train_loss: 0.9403
110/200, train_loss: 0.9500
111/200, train_loss: 0.9188
112/200, train_loss: 0.8599
113/200, train_loss: 0.7658
114/200, train_loss: 0.8622
115/200, train_loss: 0.9648
116/200, train_loss: 0.8120
117/200, train_loss: 1.1147
118/200, train_loss: 0.8276
119/200, train_loss: 0.9054
120/200, train_loss: 1.0717
121/200, train_loss: 0.9435
122/200, train_loss: 0.9072
123/200, train_loss: 0.9033
124/200, train_loss: 0.9262
125/200, train_loss: 0.8706
126/200, train_loss: 1.0796
127/200, train_loss: 0.9539
128/200, train_loss: 0.8616
129/200, train_loss: 1.0100
130/200, train_loss: 1.0228
131/200, train_loss: 0.8943
132/200, train_loss: 0.9399
133/200, train_loss: 1.0773
134/200, train_loss: 0.7501
135/200, train_loss: 0.8016
136/200, train_loss: 0.8928
137/200, train_loss: 1.0678
138/200, train_loss: 0.8972
139/200, train_loss: 0.9909
140/200, train_loss: 0.8671
141/200, train_loss: 1.0964
142/200, train_loss: 0.9040
143/200, train_loss: 1.0833
144/200, train_loss: 0.9324
145/200, train_loss: 0.8827
146/200, train_loss: 1.2086
147/200, train_loss: 0.9121
148/200, train_loss: 0.8197
149/200, train_loss: 0.9149
150/200, train_loss: 1.1368
151/200, train_loss: 1.0294
152/200, train_loss: 0.9899
153/200, train_loss: 0.8730
154/200, train_loss: 0.8215
155/200, train_loss: 0.9840
156/200, train_loss: 1.0444
157/200, train_loss: 0.9945
158/200, train_loss: 1.0013
159/200, train_loss: 0.7949
160/200, train_loss: 0.8612
161/200, train_loss: 0.9394
162/200, train_loss: 0.8702
163/200, train_loss: 0.8449
164/200, train_loss: 0.9125
165/200, train_loss: 0.9659
166/200, train_loss: 1.0220
167/200, train_loss: 0.7686
168/200, train_loss: 0.7594
169/200, train_loss: 0.9142
170/200, train_loss: 0.7565
171/200, train_loss: 0.8870
172/200, train_loss: 0.9165
173/200, train_loss: 0.7230
174/200, train_loss: 0.8453
175/200, train_loss: 1.0081
176/200, train_loss: 0.8512
177/200, train_loss: 0.9425
178/200, train_loss: 0.9605
179/200, train_loss: 0.9751
180/200, train_loss: 1.0060
181/200, train_loss: 1.1677
182/200, train_loss: 0.8499
183/200, train_loss: 1.0987
184/200, train_loss: 0.9358
185/200, train_loss: 0.9629
186/200, train_loss: 0.9381
187/200, train_loss: 0.7978
188/200, train_loss: 0.9739
189/200, train_loss: 0.8025
190/200, train_loss: 0.8667
191/200, train_loss: 0.9613
192/200, train_loss: 0.8611
193/200, train_loss: 0.8674
194/200, train_loss: 0.8669
195/200, train_loss: 0.8623
196/200, train_loss: 0.9053
197/200, train_loss: 0.9790
198/200, train_loss: 1.0040
199/200, train_loss: 0.9484
200/200, train_loss: 1.0683
epoch 45 average loss: 0.9321
current epoch: 45 current mean dice: 0.4088 1: 0.3692 2: 0.4515
best mean dice: 0.4103 at epoch: 38
Epoch 45 completed
time consuming of epoch 45 is: 585.9921
----------
Epoch 46/50
1/200, train_loss: 0.7249
2/200, train_loss: 0.9041
3/200, train_loss: 0.8672
4/200, train_loss: 0.8183
5/200, train_loss: 1.0943
6/200, train_loss: 0.9611
7/200, train_loss: 0.9249
8/200, train_loss: 1.1337
9/200, train_loss: 0.9740
10/200, train_loss: 0.8426
11/200, train_loss: 0.9613
12/200, train_loss: 1.1161
13/200, train_loss: 0.7484
14/200, train_loss: 0.8773
15/200, train_loss: 0.9387
16/200, train_loss: 0.7872
17/200, train_loss: 0.8164
18/200, train_loss: 0.8466
19/200, train_loss: 1.0298
20/200, train_loss: 0.8654
21/200, train_loss: 0.9436
22/200, train_loss: 1.0080
23/200, train_loss: 1.0071
24/200, train_loss: 1.1065
25/200, train_loss: 0.7748
26/200, train_loss: 0.9097
27/200, train_loss: 1.0395
28/200, train_loss: 0.7627
29/200, train_loss: 0.8851
30/200, train_loss: 0.7632
31/200, train_loss: 0.9347
32/200, train_loss: 0.9504
33/200, train_loss: 0.9459
34/200, train_loss: 0.9290
35/200, train_loss: 1.0614
36/200, train_loss: 1.0805
37/200, train_loss: 0.9841
38/200, train_loss: 0.8180
39/200, train_loss: 1.0557
40/200, train_loss: 0.8069
41/200, train_loss: 0.8700
42/200, train_loss: 1.0874
43/200, train_loss: 0.7667
44/200, train_loss: 0.9681
45/200, train_loss: 1.0488
46/200, train_loss: 0.8856
47/200, train_loss: 0.9196
48/200, train_loss: 0.9672
49/200, train_loss: 0.9166
50/200, train_loss: 1.0675
51/200, train_loss: 0.7877
52/200, train_loss: 1.0263
53/200, train_loss: 0.9765
54/200, train_loss: 0.7721
55/200, train_loss: 0.7818
56/200, train_loss: 1.0581
57/200, train_loss: 1.1392
58/200, train_loss: 1.0126
59/200, train_loss: 0.9239
60/200, train_loss: 1.0064
61/200, train_loss: 0.8342
62/200, train_loss: 0.9073
63/200, train_loss: 1.0988
64/200, train_loss: 0.8724
65/200, train_loss: 0.9444
66/200, train_loss: 0.8336
67/200, train_loss: 0.9616
68/200, train_loss: 1.0731
69/200, train_loss: 0.7414
70/200, train_loss: 0.8907
71/200, train_loss: 0.8143
72/200, train_loss: 0.9795
73/200, train_loss: 0.9134
74/200, train_loss: 0.8788
75/200, train_loss: 0.8246
76/200, train_loss: 0.9564
77/200, train_loss: 0.8330
78/200, train_loss: 0.9916
79/200, train_loss: 0.9802
80/200, train_loss: 1.1346
81/200, train_loss: 0.9029
82/200, train_loss: 0.9952
83/200, train_loss: 0.7679
84/200, train_loss: 1.0111
85/200, train_loss: 0.9422
86/200, train_loss: 0.8871
87/200, train_loss: 1.0106
88/200, train_loss: 0.8284
89/200, train_loss: 0.8434
90/200, train_loss: 0.9407
91/200, train_loss: 0.8155
92/200, train_loss: 0.8304
93/200, train_loss: 0.7678
94/200, train_loss: 0.9576
95/200, train_loss: 0.9303
96/200, train_loss: 0.9227
97/200, train_loss: 0.9578
98/200, train_loss: 0.9721
99/200, train_loss: 0.9529
100/200, train_loss: 1.0397
101/200, train_loss: 1.1819
102/200, train_loss: 0.8625
103/200, train_loss: 1.0941
104/200, train_loss: 1.0683
105/200, train_loss: 0.8555
106/200, train_loss: 0.8803
107/200, train_loss: 0.9008
108/200, train_loss: 0.7940
109/200, train_loss: 0.9309
110/200, train_loss: 0.9586
111/200, train_loss: 0.8920
112/200, train_loss: 0.7695
113/200, train_loss: 1.1699
114/200, train_loss: 1.0198
115/200, train_loss: 1.0946
116/200, train_loss: 1.1058
117/200, train_loss: 0.9015
118/200, train_loss: 0.9793
119/200, train_loss: 0.9812
120/200, train_loss: 1.0018
121/200, train_loss: 0.8369
122/200, train_loss: 0.8478
123/200, train_loss: 0.9505
124/200, train_loss: 0.9389
125/200, train_loss: 0.8165
126/200, train_loss: 0.7691
127/200, train_loss: 1.1124
128/200, train_loss: 0.7976
129/200, train_loss: 0.8085
130/200, train_loss: 0.8585
131/200, train_loss: 0.8743
132/200, train_loss: 0.7979
133/200, train_loss: 0.9763
134/200, train_loss: 0.9347
135/200, train_loss: 0.7681
136/200, train_loss: 1.0447
137/200, train_loss: 0.8889
138/200, train_loss: 0.9657
139/200, train_loss: 0.8821
140/200, train_loss: 1.1048
141/200, train_loss: 0.8113
142/200, train_loss: 0.8038
143/200, train_loss: 1.0004
144/200, train_loss: 1.0249
145/200, train_loss: 0.8392
146/200, train_loss: 0.9477
147/200, train_loss: 1.0052
148/200, train_loss: 1.0659
149/200, train_loss: 0.9298
150/200, train_loss: 0.9692
151/200, train_loss: 0.8125
152/200, train_loss: 1.2209
153/200, train_loss: 0.9193
154/200, train_loss: 1.0170
155/200, train_loss: 1.0375
156/200, train_loss: 0.9025
157/200, train_loss: 1.0098
158/200, train_loss: 0.8632
159/200, train_loss: 0.7673
160/200, train_loss: 0.8689
161/200, train_loss: 0.8480
162/200, train_loss: 0.8785
163/200, train_loss: 1.0153
164/200, train_loss: 0.9972
165/200, train_loss: 0.9687
166/200, train_loss: 1.1599
167/200, train_loss: 0.9828
168/200, train_loss: 0.9727
169/200, train_loss: 0.8245
170/200, train_loss: 0.9300
171/200, train_loss: 0.8713
172/200, train_loss: 0.9944
173/200, train_loss: 0.9163
174/200, train_loss: 0.9918
175/200, train_loss: 0.8329
176/200, train_loss: 1.0878
177/200, train_loss: 0.9335
178/200, train_loss: 0.9417
179/200, train_loss: 0.9615
180/200, train_loss: 0.8355
181/200, train_loss: 0.9055
182/200, train_loss: 0.9321
183/200, train_loss: 0.8665
184/200, train_loss: 0.8238
185/200, train_loss: 0.8312
186/200, train_loss: 0.8450
187/200, train_loss: 0.9456
188/200, train_loss: 0.7717
189/200, train_loss: 0.9772
190/200, train_loss: 1.0280
191/200, train_loss: 0.9118
192/200, train_loss: 0.8847
193/200, train_loss: 0.8836
194/200, train_loss: 0.8878
195/200, train_loss: 0.9249
196/200, train_loss: 0.9173
197/200, train_loss: 0.8726
198/200, train_loss: 0.7643
199/200, train_loss: 0.9696
200/200, train_loss: 1.1132
epoch 46 average loss: 0.9298
current epoch: 46 current mean dice: 0.4062 1: 0.3629 2: 0.4522
best mean dice: 0.4103 at epoch: 38
Epoch 46 completed
time consuming of epoch 46 is: 588.3878
----------
Epoch 47/50
1/200, train_loss: 1.1622
2/200, train_loss: 0.8148
3/200, train_loss: 0.9130
4/200, train_loss: 0.8723
5/200, train_loss: 0.9956
6/200, train_loss: 1.0478
7/200, train_loss: 0.8178
8/200, train_loss: 0.7872
9/200, train_loss: 0.9525
10/200, train_loss: 0.9884
11/200, train_loss: 0.9707
12/200, train_loss: 0.8737
13/200, train_loss: 0.7572
14/200, train_loss: 0.9517
15/200, train_loss: 0.9336
16/200, train_loss: 0.9582
17/200, train_loss: 0.9329
18/200, train_loss: 0.8317
19/200, train_loss: 0.7259
20/200, train_loss: 0.8534
21/200, train_loss: 0.9141
22/200, train_loss: 1.0231
23/200, train_loss: 0.7668
24/200, train_loss: 0.9254
25/200, train_loss: 0.8956
26/200, train_loss: 0.9961
27/200, train_loss: 0.8270
28/200, train_loss: 0.9580
29/200, train_loss: 0.7099
30/200, train_loss: 0.8319
31/200, train_loss: 0.8209
32/200, train_loss: 1.0538
33/200, train_loss: 0.9052
34/200, train_loss: 1.0961
35/200, train_loss: 0.9265
36/200, train_loss: 0.9589
37/200, train_loss: 0.8368
38/200, train_loss: 0.6788
39/200, train_loss: 0.7879
40/200, train_loss: 1.0642
41/200, train_loss: 0.9091
42/200, train_loss: 0.9819
43/200, train_loss: 0.9566
44/200, train_loss: 1.1035
45/200, train_loss: 0.8276
46/200, train_loss: 0.9185
47/200, train_loss: 0.9759
48/200, train_loss: 0.9711
49/200, train_loss: 1.0403
50/200, train_loss: 0.8663
51/200, train_loss: 1.1374
52/200, train_loss: 0.9345
53/200, train_loss: 1.1108
54/200, train_loss: 0.8403
55/200, train_loss: 1.0723
56/200, train_loss: 0.8118
57/200, train_loss: 1.1009
58/200, train_loss: 1.0241
59/200, train_loss: 0.8784
60/200, train_loss: 0.9121
61/200, train_loss: 0.9969
62/200, train_loss: 0.8456
63/200, train_loss: 0.9199
64/200, train_loss: 0.9334
65/200, train_loss: 1.0454
66/200, train_loss: 1.0093
67/200, train_loss: 0.7749
68/200, train_loss: 0.8794
69/200, train_loss: 0.8414
70/200, train_loss: 0.9796
71/200, train_loss: 1.0485
72/200, train_loss: 0.9117
73/200, train_loss: 0.9561
74/200, train_loss: 0.9425
75/200, train_loss: 0.9685
76/200, train_loss: 0.9275
77/200, train_loss: 0.9816
78/200, train_loss: 1.1530
79/200, train_loss: 1.1609
80/200, train_loss: 1.1180
81/200, train_loss: 1.0820
82/200, train_loss: 1.0679
83/200, train_loss: 0.9448
84/200, train_loss: 0.8625
85/200, train_loss: 0.9689
86/200, train_loss: 0.8724
87/200, train_loss: 0.9161
88/200, train_loss: 0.8886
89/200, train_loss: 0.9463
90/200, train_loss: 0.9759
91/200, train_loss: 1.0235
92/200, train_loss: 0.9707
93/200, train_loss: 0.9266
94/200, train_loss: 0.9386
95/200, train_loss: 0.7732
96/200, train_loss: 0.8743
97/200, train_loss: 1.0102
98/200, train_loss: 1.1249
99/200, train_loss: 0.9771
100/200, train_loss: 0.8068
101/200, train_loss: 0.8637
102/200, train_loss: 0.8744
103/200, train_loss: 0.9238
104/200, train_loss: 1.0919
105/200, train_loss: 0.9741
106/200, train_loss: 0.8211
107/200, train_loss: 0.9127
108/200, train_loss: 0.9744
109/200, train_loss: 0.8751
110/200, train_loss: 1.0218
111/200, train_loss: 0.9887
112/200, train_loss: 1.0712
113/200, train_loss: 0.8065
114/200, train_loss: 0.8868
115/200, train_loss: 0.9072
116/200, train_loss: 0.9335
117/200, train_loss: 1.0742
118/200, train_loss: 1.0308
119/200, train_loss: 0.9343
120/200, train_loss: 0.8969
121/200, train_loss: 0.7725
122/200, train_loss: 0.8909
123/200, train_loss: 0.8664
124/200, train_loss: 0.8277
125/200, train_loss: 0.9214
126/200, train_loss: 0.9071
127/200, train_loss: 0.9888
128/200, train_loss: 0.8966
129/200, train_loss: 0.9420
130/200, train_loss: 0.8830
131/200, train_loss: 0.9061
132/200, train_loss: 0.9393
133/200, train_loss: 1.1882
134/200, train_loss: 0.9820
135/200, train_loss: 1.0830
136/200, train_loss: 0.9208
137/200, train_loss: 1.1483
138/200, train_loss: 0.8084
139/200, train_loss: 1.1339
140/200, train_loss: 0.8574
141/200, train_loss: 0.8588
142/200, train_loss: 1.0545
143/200, train_loss: 0.9939
144/200, train_loss: 0.9446
145/200, train_loss: 0.9532
146/200, train_loss: 0.7655
147/200, train_loss: 1.0198
148/200, train_loss: 1.0135
149/200, train_loss: 0.9397
150/200, train_loss: 0.8825
151/200, train_loss: 1.1236
152/200, train_loss: 1.0585
153/200, train_loss: 0.9911
154/200, train_loss: 0.8652
155/200, train_loss: 0.8967
156/200, train_loss: 0.8950
157/200, train_loss: 0.9608
158/200, train_loss: 0.7756
159/200, train_loss: 0.7964
160/200, train_loss: 1.1616
161/200, train_loss: 0.7358
162/200, train_loss: 0.8277
163/200, train_loss: 0.8056
164/200, train_loss: 0.9470
165/200, train_loss: 1.0296
166/200, train_loss: 0.7686
167/200, train_loss: 1.0727
168/200, train_loss: 0.7631
169/200, train_loss: 0.9949
170/200, train_loss: 0.9523
171/200, train_loss: 1.0391
172/200, train_loss: 0.8356
173/200, train_loss: 0.8189
174/200, train_loss: 0.9692
175/200, train_loss: 1.0087
176/200, train_loss: 0.8822
177/200, train_loss: 1.0709
178/200, train_loss: 0.9568
179/200, train_loss: 0.8846
180/200, train_loss: 1.0735
181/200, train_loss: 0.9479
182/200, train_loss: 1.0067
183/200, train_loss: 0.9180
184/200, train_loss: 0.8181
185/200, train_loss: 0.8987
186/200, train_loss: 0.8394
187/200, train_loss: 1.0258
188/200, train_loss: 0.8872
189/200, train_loss: 0.9349
190/200, train_loss: 0.9676
191/200, train_loss: 0.9862
192/200, train_loss: 0.9776
193/200, train_loss: 0.9925
194/200, train_loss: 0.8829
195/200, train_loss: 0.9341
196/200, train_loss: 0.9756
197/200, train_loss: 0.9217
198/200, train_loss: 0.8363
199/200, train_loss: 1.0154
200/200, train_loss: 0.8202
epoch 47 average loss: 0.9377
current epoch: 47 current mean dice: 0.4056 1: 0.3642 2: 0.4500
best mean dice: 0.4103 at epoch: 38
Epoch 47 completed
time consuming of epoch 47 is: 590.0953
----------
Epoch 48/50
1/200, train_loss: 1.0353
2/200, train_loss: 0.9515
3/200, train_loss: 0.9439
4/200, train_loss: 0.9519
5/200, train_loss: 0.8623
6/200, train_loss: 1.1084
7/200, train_loss: 0.9093
8/200, train_loss: 0.9012
9/200, train_loss: 0.9466
10/200, train_loss: 0.7765
11/200, train_loss: 0.9285
12/200, train_loss: 0.8465
13/200, train_loss: 0.9671
14/200, train_loss: 0.8767
15/200, train_loss: 0.9554
16/200, train_loss: 0.7681
17/200, train_loss: 0.9571
18/200, train_loss: 0.8285
19/200, train_loss: 0.9616
20/200, train_loss: 1.1478
21/200, train_loss: 0.6802
22/200, train_loss: 0.8165
23/200, train_loss: 1.0876
24/200, train_loss: 0.8211
25/200, train_loss: 0.9854
26/200, train_loss: 1.0205
27/200, train_loss: 0.7473
28/200, train_loss: 1.0168
29/200, train_loss: 1.0037
30/200, train_loss: 0.8094
31/200, train_loss: 0.7291
32/200, train_loss: 0.9410
33/200, train_loss: 0.7975
34/200, train_loss: 1.1475
35/200, train_loss: 1.0367
36/200, train_loss: 0.8854
37/200, train_loss: 0.7880
38/200, train_loss: 0.8506
39/200, train_loss: 1.0484
40/200, train_loss: 0.9699
41/200, train_loss: 0.9279
42/200, train_loss: 1.0201
43/200, train_loss: 0.9880
44/200, train_loss: 0.8245
45/200, train_loss: 0.9978
46/200, train_loss: 0.9348
47/200, train_loss: 0.8306
48/200, train_loss: 0.9011
49/200, train_loss: 0.9718
50/200, train_loss: 0.9015
51/200, train_loss: 1.0779
52/200, train_loss: 1.0062
53/200, train_loss: 0.9837
54/200, train_loss: 1.0761
55/200, train_loss: 1.1184
56/200, train_loss: 0.8344
57/200, train_loss: 0.8102
58/200, train_loss: 0.8979
59/200, train_loss: 0.9973
60/200, train_loss: 1.0765
61/200, train_loss: 0.8521
62/200, train_loss: 0.8518
63/200, train_loss: 1.2572
64/200, train_loss: 0.9734
65/200, train_loss: 0.9255
66/200, train_loss: 0.9891
67/200, train_loss: 0.9709
68/200, train_loss: 1.0058
69/200, train_loss: 0.8417
70/200, train_loss: 0.8534
71/200, train_loss: 0.8840
72/200, train_loss: 1.0135
73/200, train_loss: 0.8068
74/200, train_loss: 0.7785
75/200, train_loss: 0.9488
76/200, train_loss: 0.9729
77/200, train_loss: 0.8845
78/200, train_loss: 1.0719
79/200, train_loss: 0.9477
80/200, train_loss: 0.9891
81/200, train_loss: 0.7303
82/200, train_loss: 0.9446
83/200, train_loss: 0.9105
84/200, train_loss: 1.1105
85/200, train_loss: 0.9027
86/200, train_loss: 0.9323
87/200, train_loss: 0.9487
88/200, train_loss: 0.9746
89/200, train_loss: 0.9117
90/200, train_loss: 1.0173
91/200, train_loss: 0.9005
92/200, train_loss: 1.0915
93/200, train_loss: 1.0460
94/200, train_loss: 0.9114
95/200, train_loss: 1.1319
96/200, train_loss: 0.8577
97/200, train_loss: 0.7472
98/200, train_loss: 0.9084
99/200, train_loss: 0.7940
100/200, train_loss: 0.7612
101/200, train_loss: 0.9407
102/200, train_loss: 0.7246
103/200, train_loss: 0.9603
104/200, train_loss: 0.9126
105/200, train_loss: 0.8742
106/200, train_loss: 0.7644
107/200, train_loss: 0.8423
108/200, train_loss: 0.8897
109/200, train_loss: 0.8824
110/200, train_loss: 0.7451
111/200, train_loss: 1.0957
112/200, train_loss: 1.0780
113/200, train_loss: 1.0541
114/200, train_loss: 0.9611
115/200, train_loss: 0.9106
116/200, train_loss: 0.9386
117/200, train_loss: 0.8711
118/200, train_loss: 0.8528
119/200, train_loss: 0.8846
120/200, train_loss: 1.0689
121/200, train_loss: 0.9070
122/200, train_loss: 0.9487
123/200, train_loss: 1.0195
124/200, train_loss: 0.9914
125/200, train_loss: 0.8292
126/200, train_loss: 0.9080
127/200, train_loss: 0.8380
128/200, train_loss: 0.8182
129/200, train_loss: 0.8415
130/200, train_loss: 0.7136
131/200, train_loss: 0.8448
132/200, train_loss: 0.8861
133/200, train_loss: 0.9353
134/200, train_loss: 0.9253
135/200, train_loss: 0.8287
136/200, train_loss: 0.8610
137/200, train_loss: 0.9053
138/200, train_loss: 0.8862
139/200, train_loss: 1.0775
140/200, train_loss: 0.8452
141/200, train_loss: 0.9829
142/200, train_loss: 0.8846
143/200, train_loss: 0.9275
144/200, train_loss: 0.9406
145/200, train_loss: 1.0192
146/200, train_loss: 0.8769
147/200, train_loss: 0.8688
148/200, train_loss: 0.6995
149/200, train_loss: 0.8689
150/200, train_loss: 0.7065
151/200, train_loss: 1.0893
152/200, train_loss: 1.0244
153/200, train_loss: 0.8497
154/200, train_loss: 0.9186
155/200, train_loss: 0.9357
156/200, train_loss: 0.8242
157/200, train_loss: 0.9786
158/200, train_loss: 0.9385
159/200, train_loss: 0.9114
160/200, train_loss: 1.1201
161/200, train_loss: 0.8471
162/200, train_loss: 0.8779
163/200, train_loss: 0.8774
164/200, train_loss: 0.8259
165/200, train_loss: 1.0190
166/200, train_loss: 1.0060
167/200, train_loss: 0.8218
168/200, train_loss: 0.8696
169/200, train_loss: 0.9654
170/200, train_loss: 0.8011
171/200, train_loss: 1.0257
172/200, train_loss: 0.7806
173/200, train_loss: 0.8560
174/200, train_loss: 1.0384
175/200, train_loss: 0.7611
176/200, train_loss: 1.0379
177/200, train_loss: 0.9070
178/200, train_loss: 0.9362
179/200, train_loss: 0.9654
180/200, train_loss: 1.0456
181/200, train_loss: 0.8761
182/200, train_loss: 1.0021
183/200, train_loss: 0.8721
184/200, train_loss: 1.0337
185/200, train_loss: 0.8597
186/200, train_loss: 0.8082
187/200, train_loss: 0.9135
188/200, train_loss: 0.8513
189/200, train_loss: 1.0729
190/200, train_loss: 0.8979
191/200, train_loss: 0.8891
192/200, train_loss: 0.9082
193/200, train_loss: 0.9970
194/200, train_loss: 0.9643
195/200, train_loss: 1.0154
196/200, train_loss: 1.2876
197/200, train_loss: 0.8006
198/200, train_loss: 1.1686
199/200, train_loss: 1.0410
200/200, train_loss: 0.8837
epoch 48 average loss: 0.9259
current epoch: 48 current mean dice: 0.4072 1: 0.3620 2: 0.4556
best mean dice: 0.4103 at epoch: 38
Epoch 48 completed
time consuming of epoch 48 is: 586.1512
----------
Epoch 49/50
1/200, train_loss: 0.6950
2/200, train_loss: 0.8824
3/200, train_loss: 0.9862
4/200, train_loss: 1.0119
5/200, train_loss: 0.8824
6/200, train_loss: 1.0694
7/200, train_loss: 0.9503
8/200, train_loss: 1.0165
9/200, train_loss: 1.0078
10/200, train_loss: 1.0367
11/200, train_loss: 0.8751
12/200, train_loss: 1.0335
13/200, train_loss: 0.9824
14/200, train_loss: 0.9065
15/200, train_loss: 0.9165
16/200, train_loss: 0.9096
17/200, train_loss: 1.0273
18/200, train_loss: 1.1181
19/200, train_loss: 0.9475
20/200, train_loss: 0.8279
21/200, train_loss: 0.9145
22/200, train_loss: 0.9508
23/200, train_loss: 0.9321
24/200, train_loss: 1.0117
25/200, train_loss: 0.9360
26/200, train_loss: 0.9431
27/200, train_loss: 1.0250
28/200, train_loss: 0.9085
29/200, train_loss: 0.9602
30/200, train_loss: 0.8181
31/200, train_loss: 0.9397
32/200, train_loss: 1.0271
33/200, train_loss: 0.8843
34/200, train_loss: 0.8246
35/200, train_loss: 1.0010
36/200, train_loss: 0.8939
37/200, train_loss: 0.9297
38/200, train_loss: 0.8593
39/200, train_loss: 1.0065
40/200, train_loss: 0.9246
41/200, train_loss: 0.7275
42/200, train_loss: 0.9856
43/200, train_loss: 1.1544
44/200, train_loss: 0.9077
45/200, train_loss: 1.0300
46/200, train_loss: 0.7397
47/200, train_loss: 1.0029
48/200, train_loss: 1.0170
49/200, train_loss: 1.0216
50/200, train_loss: 1.0536
51/200, train_loss: 1.0258
52/200, train_loss: 0.8291
53/200, train_loss: 1.0333
54/200, train_loss: 0.9928
55/200, train_loss: 0.7607
56/200, train_loss: 1.0628
57/200, train_loss: 0.8883
58/200, train_loss: 0.8355
59/200, train_loss: 1.0510
60/200, train_loss: 0.9711
61/200, train_loss: 0.9964
62/200, train_loss: 1.0081
63/200, train_loss: 0.7863
64/200, train_loss: 1.0779
65/200, train_loss: 1.0894
66/200, train_loss: 1.0209
67/200, train_loss: 1.0097
68/200, train_loss: 0.9258
69/200, train_loss: 1.0803
70/200, train_loss: 1.0234
71/200, train_loss: 0.7704
72/200, train_loss: 0.8880
73/200, train_loss: 0.9673
74/200, train_loss: 0.9481
75/200, train_loss: 0.8956
76/200, train_loss: 0.8626
77/200, train_loss: 0.8461
78/200, train_loss: 0.8146
79/200, train_loss: 0.8010
80/200, train_loss: 0.9914
81/200, train_loss: 0.8184
82/200, train_loss: 0.8306
83/200, train_loss: 0.7559
84/200, train_loss: 0.8692
85/200, train_loss: 0.8902
86/200, train_loss: 0.9030
87/200, train_loss: 0.9358
88/200, train_loss: 1.0195
89/200, train_loss: 0.9119
90/200, train_loss: 0.9865
91/200, train_loss: 0.9036
92/200, train_loss: 0.7210
93/200, train_loss: 0.9159
94/200, train_loss: 0.7960
95/200, train_loss: 0.8218
96/200, train_loss: 0.9075
97/200, train_loss: 0.9137
98/200, train_loss: 1.1209
99/200, train_loss: 0.8877
100/200, train_loss: 0.9042
101/200, train_loss: 1.0500
102/200, train_loss: 0.8988
103/200, train_loss: 0.8154
104/200, train_loss: 0.9613
105/200, train_loss: 1.1741
106/200, train_loss: 1.1196
107/200, train_loss: 0.8711
108/200, train_loss: 1.1223
109/200, train_loss: 0.8891
110/200, train_loss: 1.1388
111/200, train_loss: 0.8435
112/200, train_loss: 1.0925
113/200, train_loss: 0.9845
114/200, train_loss: 0.8111
115/200, train_loss: 0.9024
116/200, train_loss: 1.2084
117/200, train_loss: 1.0093
118/200, train_loss: 1.0460
119/200, train_loss: 0.9302
120/200, train_loss: 0.9021
121/200, train_loss: 0.8591
122/200, train_loss: 0.7528
123/200, train_loss: 0.8857
124/200, train_loss: 0.8831
125/200, train_loss: 0.8471
126/200, train_loss: 1.0081
127/200, train_loss: 0.8977
128/200, train_loss: 1.0104
129/200, train_loss: 0.8206
130/200, train_loss: 0.8113
131/200, train_loss: 0.9517
132/200, train_loss: 0.9154
133/200, train_loss: 0.9095
134/200, train_loss: 0.9328
135/200, train_loss: 0.8595
136/200, train_loss: 0.8743
137/200, train_loss: 0.8840
138/200, train_loss: 0.9521
139/200, train_loss: 0.8112
140/200, train_loss: 1.0369
141/200, train_loss: 0.8171
142/200, train_loss: 0.9105
143/200, train_loss: 0.9464
144/200, train_loss: 0.9557
145/200, train_loss: 0.8777
146/200, train_loss: 0.8183
147/200, train_loss: 0.9479
148/200, train_loss: 0.9219
149/200, train_loss: 0.9497
150/200, train_loss: 0.7661
151/200, train_loss: 1.0828
152/200, train_loss: 0.9308
153/200, train_loss: 0.9855
154/200, train_loss: 0.7252
155/200, train_loss: 0.7316
156/200, train_loss: 1.0703
157/200, train_loss: 0.8875
158/200, train_loss: 0.9534
159/200, train_loss: 0.8891
160/200, train_loss: 0.9947
161/200, train_loss: 0.9272
162/200, train_loss: 0.8817
163/200, train_loss: 0.7960
164/200, train_loss: 0.8590
165/200, train_loss: 0.8437
166/200, train_loss: 0.9382
167/200, train_loss: 0.9203
168/200, train_loss: 0.9110
169/200, train_loss: 0.7385
170/200, train_loss: 1.0357
171/200, train_loss: 0.8072
172/200, train_loss: 0.9392
173/200, train_loss: 0.8279
174/200, train_loss: 0.7233
175/200, train_loss: 0.9315
176/200, train_loss: 1.1336
177/200, train_loss: 1.0298
178/200, train_loss: 1.0430
179/200, train_loss: 0.8106
180/200, train_loss: 1.0149
181/200, train_loss: 0.7915
182/200, train_loss: 0.8668
183/200, train_loss: 1.0815
184/200, train_loss: 0.9965
185/200, train_loss: 0.8229
186/200, train_loss: 0.7999
187/200, train_loss: 0.9365
188/200, train_loss: 0.9238
189/200, train_loss: 0.8212
190/200, train_loss: 0.9042
191/200, train_loss: 0.9627
192/200, train_loss: 0.8795
193/200, train_loss: 1.0160
194/200, train_loss: 1.2098
195/200, train_loss: 0.8737
196/200, train_loss: 0.9076
197/200, train_loss: 0.8283
198/200, train_loss: 0.9309
199/200, train_loss: 1.0072
200/200, train_loss: 0.9738
epoch 49 average loss: 0.9298
current epoch: 49 current mean dice: 0.4061 1: 0.3640 2: 0.4512
best mean dice: 0.4103 at epoch: 38
Epoch 49 completed
time consuming of epoch 49 is: 590.4863
----------
Epoch 50/50
1/200, train_loss: 0.8259
2/200, train_loss: 1.0255
3/200, train_loss: 0.7404
4/200, train_loss: 0.9831
5/200, train_loss: 0.9034
6/200, train_loss: 1.1214
7/200, train_loss: 0.8235
8/200, train_loss: 0.9511
9/200, train_loss: 1.1334
10/200, train_loss: 0.8655
11/200, train_loss: 1.0529
12/200, train_loss: 0.8199
13/200, train_loss: 0.9195
14/200, train_loss: 0.9941
15/200, train_loss: 0.8361
16/200, train_loss: 0.9907
17/200, train_loss: 1.0569
18/200, train_loss: 0.8716
19/200, train_loss: 0.8214
20/200, train_loss: 0.8458
21/200, train_loss: 0.8820
22/200, train_loss: 0.9945
23/200, train_loss: 1.0464
24/200, train_loss: 1.0531
25/200, train_loss: 0.8953
26/200, train_loss: 0.9172
27/200, train_loss: 0.7665
28/200, train_loss: 0.9751
29/200, train_loss: 0.8666
30/200, train_loss: 0.8734
31/200, train_loss: 0.9253
32/200, train_loss: 1.0345
33/200, train_loss: 1.0525
34/200, train_loss: 1.0427
35/200, train_loss: 1.0468
36/200, train_loss: 0.9288
37/200, train_loss: 1.0868
38/200, train_loss: 1.1820
39/200, train_loss: 0.9964
40/200, train_loss: 1.1754
41/200, train_loss: 0.8652
42/200, train_loss: 1.0017
43/200, train_loss: 0.9375
44/200, train_loss: 1.0113
45/200, train_loss: 1.0148
46/200, train_loss: 1.0106
47/200, train_loss: 0.8421
48/200, train_loss: 0.9306
49/200, train_loss: 0.9998
50/200, train_loss: 1.0585
51/200, train_loss: 1.0052
52/200, train_loss: 0.9826
53/200, train_loss: 0.9772
54/200, train_loss: 0.9564
55/200, train_loss: 0.9386
56/200, train_loss: 1.0528
57/200, train_loss: 0.8474
58/200, train_loss: 0.9173
59/200, train_loss: 0.8639
60/200, train_loss: 0.8981
61/200, train_loss: 0.9385
62/200, train_loss: 1.1033
63/200, train_loss: 0.8854
64/200, train_loss: 0.7998
65/200, train_loss: 1.0351
66/200, train_loss: 0.7884
67/200, train_loss: 1.0444
68/200, train_loss: 0.9421
69/200, train_loss: 0.9687
70/200, train_loss: 0.9180
71/200, train_loss: 1.0382
72/200, train_loss: 0.9688
73/200, train_loss: 0.7779
74/200, train_loss: 0.9786
75/200, train_loss: 0.8564
76/200, train_loss: 0.9178
77/200, train_loss: 0.9429
78/200, train_loss: 0.8690
79/200, train_loss: 0.9034
80/200, train_loss: 0.8216
81/200, train_loss: 0.7645
82/200, train_loss: 0.8853
83/200, train_loss: 0.8211
84/200, train_loss: 1.0119
85/200, train_loss: 0.9871
86/200, train_loss: 0.7469
87/200, train_loss: 1.0304
88/200, train_loss: 1.0034
89/200, train_loss: 0.8056
90/200, train_loss: 1.0575
91/200, train_loss: 0.8823
92/200, train_loss: 0.7559
93/200, train_loss: 0.9518
94/200, train_loss: 0.8673
95/200, train_loss: 0.9003
96/200, train_loss: 0.9617
97/200, train_loss: 0.9036
98/200, train_loss: 0.8174
99/200, train_loss: 0.9040
100/200, train_loss: 0.9709
101/200, train_loss: 1.0313
102/200, train_loss: 1.0187
103/200, train_loss: 0.8783
104/200, train_loss: 1.0747
105/200, train_loss: 0.9467
106/200, train_loss: 1.1997
107/200, train_loss: 0.8511
108/200, train_loss: 1.0033
109/200, train_loss: 0.8181
110/200, train_loss: 1.0596
111/200, train_loss: 1.0402
112/200, train_loss: 0.7609
113/200, train_loss: 0.7666
114/200, train_loss: 1.0948
115/200, train_loss: 0.8607
116/200, train_loss: 1.0160
117/200, train_loss: 1.1280
118/200, train_loss: 1.0346
119/200, train_loss: 1.0616
120/200, train_loss: 0.8994
121/200, train_loss: 1.0125
122/200, train_loss: 1.0836
123/200, train_loss: 0.9452
124/200, train_loss: 1.1018
125/200, train_loss: 0.9755
126/200, train_loss: 0.9413
127/200, train_loss: 0.9946
128/200, train_loss: 0.7699
129/200, train_loss: 0.9696
130/200, train_loss: 1.0377
131/200, train_loss: 1.0068
132/200, train_loss: 0.9667
133/200, train_loss: 0.9201
134/200, train_loss: 1.0193
135/200, train_loss: 0.9425
136/200, train_loss: 0.7869
137/200, train_loss: 0.9080
138/200, train_loss: 0.8512
139/200, train_loss: 1.0209
140/200, train_loss: 1.0382
141/200, train_loss: 1.1175
142/200, train_loss: 1.0422
143/200, train_loss: 0.9946
144/200, train_loss: 1.0806
145/200, train_loss: 0.8158
146/200, train_loss: 0.8927
147/200, train_loss: 0.8583
148/200, train_loss: 0.8209
149/200, train_loss: 0.8673
150/200, train_loss: 0.8911
151/200, train_loss: 0.9775
152/200, train_loss: 0.9460
153/200, train_loss: 1.0224
154/200, train_loss: 1.0760
155/200, train_loss: 0.9401
156/200, train_loss: 0.8048
157/200, train_loss: 0.9929
158/200, train_loss: 0.9378
159/200, train_loss: 0.9893
160/200, train_loss: 1.0043
161/200, train_loss: 0.8558
162/200, train_loss: 0.9339
163/200, train_loss: 0.7793
164/200, train_loss: 0.9915
165/200, train_loss: 0.9734
166/200, train_loss: 0.8130
167/200, train_loss: 0.8696
168/200, train_loss: 1.0223
169/200, train_loss: 0.9857
170/200, train_loss: 0.8908
171/200, train_loss: 1.0036
172/200, train_loss: 0.9720
173/200, train_loss: 0.7972
174/200, train_loss: 1.0269
175/200, train_loss: 0.8493
176/200, train_loss: 0.9097
177/200, train_loss: 0.9702
178/200, train_loss: 0.9259
179/200, train_loss: 1.0286
180/200, train_loss: 0.8541
181/200, train_loss: 1.0416
182/200, train_loss: 1.0449
183/200, train_loss: 1.1470
184/200, train_loss: 0.9407
185/200, train_loss: 0.7811
186/200, train_loss: 0.9849
187/200, train_loss: 0.9366
188/200, train_loss: 0.9479
189/200, train_loss: 1.0072
190/200, train_loss: 0.8695
191/200, train_loss: 1.0828
192/200, train_loss: 0.7608
193/200, train_loss: 0.8860
194/200, train_loss: 0.9778
195/200, train_loss: 0.9980
196/200, train_loss: 1.0382
197/200, train_loss: 0.8543
198/200, train_loss: 1.0279
199/200, train_loss: 0.7672
200/200, train_loss: 0.8718
epoch 50 average loss: 0.9464
current epoch: 50 current mean dice: 0.4067 1: 0.3646 2: 0.4517
best mean dice: 0.4103 at epoch: 38
Epoch 50 completed
time consuming of epoch 50 is: 596.3208
train completed, best_metric: 0.4103 at epoch: 38, total time: 29739.220298051834.
Data saved to metrics directory
