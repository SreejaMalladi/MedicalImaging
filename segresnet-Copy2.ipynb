{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca5c074-68d7-403c-82fe-4626ecf78f05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip -q install monai gdown einops mlflow pynrrd torchinfo \n",
    "!pip install pandas numpy nibabel tqdm\n",
    "!python -c \"import monai\" || pip install -q \"monai-weekly[gdown, nibabel, tqdm, ignite]\"\n",
    "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1015532b-b47f-4fc5-9b6d-b8969f3758f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "import warnings\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "from collections.abc import Callable, Sequence, Hashable\n",
    "from typing import Mapping,Dict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from monai.transforms import (\n",
    "    EnsureType,\n",
    "    FillHoles,\n",
    "    OneOf,\n",
    "    SpatialCropd,\n",
    "    Activations,\n",
    "    Activationsd,\n",
    "    ConcatItemsd,\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    Compose,\n",
    "    Invertd,\n",
    "    LoadImaged,\n",
    "    MapTransform,\n",
    "    RandAffined,\n",
    "    NormalizeIntensityd,\n",
    "    ToTensord,\n",
    "    EnsureChannelFirstd ,\n",
    "    Orientationd,\n",
    "    Spacingd,\n",
    "    ScaleIntensityRanged,\n",
    "    CropForegroundd,\n",
    "    NormalizeIntensityd,\n",
    "    Resized,\n",
    "    SaveImaged,\n",
    "    RandScaleIntensityd,\n",
    "    RandShiftIntensityd,\n",
    "    RandSpatialCropd,\n",
    "    RandSpatialCropSamplesd,\n",
    "    RandFlipd,\n",
    "    RandRotated,\n",
    "    EnsureTyped,\n",
    "    ScaleIntensityd,\n",
    "    RandCropByPosNegLabeld,\n",
    ")\n",
    "\n",
    "from monai.apps import DecathlonDataset\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.losses import DiceLoss, DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric, HausdorffDistanceMetric\n",
    "from monai.networks.nets import SegResNet, SwinUNETR\n",
    "from monai.data import Dataset, DataLoader, CacheDataset, decollate_batch\n",
    "from monai.utils import first\n",
    "from monai.utils import set_determinism\n",
    "from monai.config import print_config\n",
    "from monai.data.meta_tensor import MetaTensor\n",
    "from monai.config.type_definitions import NdarrayOrTensor\n",
    "from monai.utils.misc import ImageMetaKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba17af21-bd73-4cf9-b3d8-3e4047fecb86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_determinism(seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ffdcf87-27e5-43ef-bba9-7d229a1a4207",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "488"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = 'Hecktor22/model_data'\n",
    "data_dir = 'hecktor2022_training/hecktor2022'\n",
    "resampled_ct_path = 'hecktor2022_training/hecktor2022/resampled_largerCt'\n",
    "resampled_pt_path = 'hecktor2022_training/hecktor2022/resampled_largerPt'\n",
    "resampled_label_path = 'hecktor2022_training/hecktor2022/resampled_largerlabel'\n",
    "\n",
    "train_images = sorted(\n",
    "    glob(os.path.join(resampled_ct_path, \"*_CT*\")))\n",
    "train_images2 = sorted(\n",
    "    glob(os.path.join(resampled_pt_path, \"*_PT*\")))\n",
    "train_labels = sorted(\n",
    "    glob(os.path.join(resampled_label_path, \"*.nii.gz\")))\n",
    "data_dicts = [{\"image\": image_name, \"image2\": pet_image, 'label': label_name}\n",
    "    for image_name, pet_image, label_name in zip(train_images, train_images2, train_labels)\n",
    "]\n",
    "len(data_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4434a5cd-a7f1-4101-bf05-a35972559531",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488\n",
      "488\n",
      "488\n"
     ]
    }
   ],
   "source": [
    "print(len(train_images))\n",
    "print(len(train_images2))\n",
    "print(len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1665020-267c-4da6-843b-2dad82c380d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "x=[i for i in range(488)]\n",
    "# print(x)\n",
    "random.shuffle(x)\n",
    "# print(x)\n",
    "train_index,val_index,test_index=x[:100],x[400:410],x[480:]\n",
    "train_files=[]\n",
    "val_files=[]\n",
    "test_files=[]\n",
    "for i in train_index:\n",
    "    train_files.append(data_dicts[i])\n",
    "for i in val_index:\n",
    "    val_files.append(data_dicts[i])\n",
    "for i in test_index:\n",
    "    test_files.append(data_dicts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d4c43b-af4c-47c9-9352-1c157c091c20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "10\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(train_files))\n",
    "print(len(val_files))\n",
    "print(len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49680af-b0e7-4939-9769-5d699445f8ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_files[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b523696e-6209-4b84-8aef-9f55c82989cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# root_dir = 'model_data'\n",
    "# data_dir = 'Hecktor22/data'\n",
    "\n",
    "# train_images_ct = sorted(glob(os.path.join(data_dir, 'TrainData', '*_CT.nii.gz')))\n",
    "# train_images_pt = sorted(glob(os.path.join(data_dir, 'TrainData', '*_PT.nii.gz')))\n",
    "# train_labels = sorted(glob(os.path.join(data_dir, 'TrainLabels', '*.nii.gz')))\n",
    "# train_files = [{\"image\": image_name, \"image2\": pet_image, 'label': label_name} for image_name, pet_image, label_name in zip(train_images_ct, train_images_pt, train_labels)]\n",
    "\n",
    "# val_images_ct = sorted(glob(os.path.join(data_dir, 'ValData', '*_CT.nii.gz')))\n",
    "# val_images_pt = sorted(glob(os.path.join(data_dir, 'ValData', '*_PT.nii.gz')))\n",
    "# val_labels = sorted(glob(os.path.join(data_dir, 'ValLabels', '*.nii.gz')))\n",
    "# val_files = [{\"image\": image_name, \"image2\": pet_image, 'label': label_name} for image_name, pet_image, label_name in zip(val_images_ct, val_images_pt, val_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68953cd-2f3e-433d-8170-a86cf9b8148d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(train_files)\n",
    "# print(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74007bbf-8cfa-4a06-8b1b-a51290be0a08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvertToMultiChannelBasedOnClassesd(MapTransform):\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            result = []\n",
    "            result.append(d[key] == 0)\n",
    "            result.append(d[key] == 1)\n",
    "            result.append(d[key] == 2)\n",
    "            d[key] = torch.stack(result, axis=0).float()\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89707476-5c67-40f8-bdb0-60d4575b0576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ct_a_min = -200\n",
    "ct_a_max = 400\n",
    "pt_a_min = 0\n",
    "pt_a_max = 25\n",
    "crop_samples = 2\n",
    "input_size = [192, 192, 192]\n",
    "modes_2d = ['bilinear', 'bilinear', 'nearest']\n",
    "p = 0.5\n",
    "image_keys = [\"image\", \"image2\", \"label\"]\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"image2\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys = [\"image\", \"image2\"]),\n",
    "        # EnsureChannelFirstd(keys = [\"image\", \"image2\", \"label\"]),\n",
    "        # EnsureTyped(keys=[\"image\", \"image2\", \"label\"]),\n",
    "        ConvertToMultiChannelBasedOnClassesd(keys=\"label\"),\n",
    "        Orientationd(keys=[\"image\", \"image2\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=image_keys,\n",
    "            pixdim=(1, 1, 1),\n",
    "            mode=modes_2d,\n",
    "        ),\n",
    "        ScaleIntensityRanged(keys=['image'], a_min=ct_a_min, a_max=ct_a_max, b_min=0.0, b_max=1.0, clip=True),\n",
    "        ScaleIntensityRanged(keys=['image2'], a_min=pt_a_min, a_max=pt_a_max, b_min=0.0, b_max=1.0, clip=True),\n",
    "        # CropForegroundd(keys=image_keys, source_key='image'),\n",
    "        # RandCropByPosNegLabeld(\n",
    "        #     keys=image_keys,\n",
    "        #     label_key='label',\n",
    "        #     spatial_size=input_size,\n",
    "        #     pos=1,\n",
    "        #     neg=1,\n",
    "        #     num_samples=crop_samples,\n",
    "        #     image_key='image',\n",
    "        #     image_threshold=0,\n",
    "        # ),\n",
    "        RandFlipd(keys=[\"image\", \"image2\", \"label\"], prob=p/3, spatial_axis=0),\n",
    "        RandFlipd(keys=[\"image\", \"image2\", \"label\"], prob=p/3, spatial_axis=1),\n",
    "        RandFlipd(keys=[\"image\", \"image2\", \"label\"], prob=p/3, spatial_axis=2),\n",
    "        ToTensord(keys=[\"image\", \"image2\", \"label\"])\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"image2\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys = [\"image\", \"image2\"]),\n",
    "        # EnsureChannelFirstd(keys = [\"image\", \"image2\", \"label\"]),\n",
    "        # EnsureTyped(keys=[\"image\", \"image2\", \"label\"]),\n",
    "        ConvertToMultiChannelBasedOnClassesd(keys='label'),\n",
    "        Orientationd(keys=[\"image\", \"image2\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=image_keys,\n",
    "            pixdim=(1, 1, 1),\n",
    "            mode=modes_2d,\n",
    "        ),\n",
    "        ScaleIntensityRanged(keys=['image'], a_min=ct_a_min, a_max=ct_a_max, b_min=0.0, b_max=1.0, clip=True),\n",
    "        ScaleIntensityRanged(keys=['image2'], a_min=pt_a_min, a_max=pt_a_max, b_min=0.0, b_max=1.0, clip=True),\n",
    "        CropForegroundd(keys=image_keys, source_key='image'),\n",
    "        ToTensord(keys=[\"image\", \"image2\", \"label\"])\n",
    "    ]\n",
    ")\n",
    "\n",
    "orig_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"image2\", \"label\"]),\n",
    "        # ConvertToMultiChannelBasedOnClassesd(keys='label'),\n",
    "    ]\n",
    ")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b6849f-871f-4f06-9758-6a3431038617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=1)\n",
    "# for check_data in check_loader:\n",
    "#     print(check_data[0]['image'].shape)\n",
    "#     print(check_data[0]['label'].shape)\n",
    "#     break\n",
    "# image, label = (check_data[\"image\"][0][0], check_data[\"label\"][0][0])\n",
    "# print(f\"image shape: {image.shape}, label shape: {label.shape}\")\n",
    "check_data = check_ds[2]\n",
    "# print(check_data['image'].meta[ImageMetaKey.FILENAME_OR_OBJ])\n",
    "plt.figure(\"image\", (6, 6))\n",
    "for i in range(1):\n",
    "    plt.subplot(1, 1, i + 1)\n",
    "    plt.title(f\"image channel {i}\")\n",
    "    plt.imshow(check_data[\"image\"][i, :, :, 90].detach().cpu())\n",
    "plt.show()\n",
    "plt.figure(\"image\", (6, 6))\n",
    "for i in range(1):\n",
    "    plt.subplot(1, 1, i + 1)\n",
    "    plt.title(f\"image channel {i}\")\n",
    "    plt.imshow(check_data[\"image2\"][i, :, :, 150].detach().cpu())\n",
    "plt.show()\n",
    "plt.figure(\"label\", (6, 6))\n",
    "for i in range(1):\n",
    "    plt.subplot(1, 1, i + 1)\n",
    "    plt.title(f\"label channel {i}\")\n",
    "    plt.imshow(check_data[\"label\"][i, :, :, 97].detach().cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbe3250-9ef7-4693-9c7d-402b700a48ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.count_nonzero(label == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28072e9c-8807-47be-a40b-53d17d295d57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=0.0,\n",
    "    num_workers=2)\n",
    "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=2)\n",
    "val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=0.0,\n",
    "    num_workers=2)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d9d9d6-6918-49d8-ae5a-8da89f6e128e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds[5]['label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a866a7e5-c6a3-4db4-a408-7c7c7668597c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_epochs = 10\n",
    "val_interval = 1\n",
    "VAL_AMP = True\n",
    "lr = 1e-4\n",
    "momentum = 0\n",
    "weight_decay = 1e-5\n",
    "T_0 = 40\n",
    "n_classes = 3\n",
    "n_channels = 2\n",
    "input_size = (192, 192, 192)\n",
    "# standard PyTorch program style: create SegResNet, DiceLoss and Adam optimizer\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = SegResNet(\n",
    "    blocks_down=[1, 2, 2, 4],\n",
    "    blocks_up=[1, 1, 1],\n",
    "    init_filters=16,\n",
    "    in_channels=2,\n",
    "    out_channels= n_classes,\n",
    "    dropout_prob=0.2,\n",
    ").to(device)\n",
    "# loss_function = DiceCELoss(include_background=False, to_onehot_y=True, softmax=True)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "# # Scheduler\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=T_0, T_mult=1, eta_min=1e-8)\n",
    "# dice_metric = DiceMetric(include_background=False, reduction='mean', get_not_nans=False)\n",
    "# dice_metric_batch = DiceMetric(include_background=True, reduction=\"mean_batch\")\n",
    "\n",
    "# post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "# post_label = AsDiscrete(to_onehot=n_classes)\n",
    "# post_pred = AsDiscrete(argmax=True, to_onehot=n_classes)\n",
    "loss_function = DiceLoss(smooth_nr=0, smooth_dr=1e-5, squared_pred=True, to_onehot_y=False, sigmoid=True)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), 1e-4, weight_decay=1e-5)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=T_0,\n",
    "                                                                     T_mult=1, eta_min=1e-8)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)\n",
    "\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "dice_metric_batch = DiceMetric(include_background=False, reduction=\"mean_batch\")\n",
    "# post_pred = Compose([AsDiscrete(argmax=True, to_onehot=n_classes)])\n",
    "# post_label = Compose([AsDiscrete(to_onehot=n_classes)])\n",
    "# post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "\n",
    "# define inference method\n",
    "def inference(input):\n",
    "    def _compute(input):\n",
    "        return sliding_window_inference(\n",
    "            inputs=input,\n",
    "            roi_size=input_size,\n",
    "            sw_batch_size=4,\n",
    "            predictor=model,\n",
    "            overlap=0.5,\n",
    "        )\n",
    "\n",
    "    if VAL_AMP:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            return _compute(input)\n",
    "    else:\n",
    "        return _compute(input)\n",
    "\n",
    "\n",
    "# use amp to accelerate training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "# enable cuDNN benchmark\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f8c1ad5-1839-41e7-a8e7-70afc278f674",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/10\n",
      "1/100, train_loss: 1.7973, step time: 20.7050\n",
      "2/100, train_loss: 1.6567, step time: 0.8898\n",
      "3/100, train_loss: 1.6226, step time: 0.8731\n",
      "4/100, train_loss: 1.5979, step time: 0.9499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "best_metrics_epochs_and_time = [[], [], []]\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "metric_values_1 = []\n",
    "metric_values_2 = []\n",
    "max_epochs = 10\n",
    "total_start = time.time()\n",
    "for epoch in range(max_epochs):\n",
    "    epoch_start = time.time()\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step_start = time.time()\n",
    "        step += 1\n",
    "        inputsct, inputspt, labels = (\n",
    "            batch_data['image'].to(device),\n",
    "            batch_data['image2'].to(device),\n",
    "            batch_data['label'].to(device),\n",
    "        )\n",
    "        inputs = torch.concat([inputsct, inputspt], axis=1)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        # loss.backward()\n",
    "        scaler.step(optimizer)\n",
    "        # optimizer.step()\n",
    "        scaler.update()\n",
    "        epoch_loss += loss.item()\n",
    "        print(\n",
    "            f\"{step}/{len(train_ds) // train_loader.batch_size}\"\n",
    "            f\", train_loss: {loss.item():.4f}\"\n",
    "            f\", step time: {(time.time() - step_start):.4f}\"\n",
    "        )\n",
    "    # lr_scheduler.step()\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            count = 0\n",
    "            for val_data in val_loader:\n",
    "                count += 1\n",
    "                val_inputsct, val_inputspt, val_labels = (\n",
    "                    val_data['image'].to(device),\n",
    "                    val_data['image2'].to(device),\n",
    "                    val_data['label'].to(device),\n",
    "                )\n",
    "                val_inputs = torch.concat([val_inputsct, val_inputspt], axis=1)\n",
    "                val_outputs = inference(val_inputs)\n",
    "                loss = loss_function(val_outputs, val_labels)\n",
    "                val_loss += loss.item()\n",
    "                # val_outputs_convert = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "                # val_labels_convert = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "                # val_outputs = sliding_window_inference(val_inputs, input_size, 4, model)\n",
    "                # val_label_list = decollate_batch(val_label)\n",
    "                # val_label_convert = [post_label(val_label_tensor) for val_label_tensor in val_label_list]\n",
    "                # val_outputs_list = decollate_batch(val_outputs)\n",
    "                # val_output_convert = [post_pred(val_pred_tensor) for val_pred_tensor in val_outputs_list]\n",
    "                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
    "                # dice_metric(y_pred=val_output_convert, y=val_label_convert)\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "                dice_metric_batch(y_pred=val_outputs_convert, y=val_labels_convert)\n",
    "            print(f\"val loss: {val_loss / count}\")\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            metric_values.append(metric)\n",
    "            metric_batch = dice_metric_batch.aggregate()\n",
    "            metric_1 = metric_batch[0].item()\n",
    "            metric_values_1.append(metric_1)\n",
    "            metric_2 = metric_batch[1].item()\n",
    "            metric_values_2.append(metric_2)\n",
    "            dice_metric.reset()\n",
    "            dice_metric_batch.reset()\n",
    "\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                best_metrics_epochs_and_time[0].append(best_metric)\n",
    "                best_metrics_epochs_and_time[1].append(best_metric_epoch)\n",
    "                best_metrics_epochs_and_time[2].append(time.time() - total_start)\n",
    "                torch.save(\n",
    "                    model.state_dict(),\n",
    "                    os.path.join(root_dir, \"best_metric_model.pth\"),\n",
    "                )\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "                f\" 1: {metric_1:.4f} 2: {metric_2:.4f}\"\n",
    "                f\"\\nbest mean dice: {best_metric:.4f}\"\n",
    "                f\" at epoch: {best_metric_epoch}\"\n",
    "            )\n",
    "    print(f\"time consuming of epoch {epoch + 1} is: {(time.time() - epoch_start):.4f}\")\n",
    "total_time = time.time() - total_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c7da3a-5e5c-46a3-bb46-132878adb015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}, total time: {total_time}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f95a55-ffd2-4105-a744-723680331f94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(\"train\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y, color=\"red\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Val Mean Dice\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y, color=\"green\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(\"train\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Val Mean Dice : 1\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values_1))]\n",
    "y = metric_values_1\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y, color=\"blue\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Val Mean Dice : 2\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values_2))]\n",
    "y = metric_values_2\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y, color=\"brown\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34fd202-1748-4fb4-b39b-98642ce56a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(root_dir, \"best_metric_model.pth\")))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # select one image to evaluate and visualize the model output\n",
    "    val_inputct = val_ds[5][\"image\"].unsqueeze(0).to(device)\n",
    "    val_inputpt = val_ds[5][\"image2\"].unsqueeze(0).to(device)\n",
    "    val_input = torch.concat([val_inputct, val_inputpt], axis=1)\n",
    "    roi_size = (192, 192, 192)\n",
    "    sw_batch_size = 4\n",
    "    val_output = inference(val_input)\n",
    "    val_output = post_trans(val_output[0])\n",
    "    plt.figure(\"image\", (6, 6))\n",
    "    for i in range(1):\n",
    "        plt.subplot(1, 2, i + 1)\n",
    "        plt.title(f\"image channel {i}\")\n",
    "        plt.imshow(val_ds[5][\"image\"][i, :, :, 70].detach().cpu(), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    # visualize the 3 channels label corresponding to this image\n",
    "    plt.figure(\"label\", (18, 6))\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.title(f\"label channel {i}\")\n",
    "        plt.imshow(val_ds[5][\"label\"][i, :, :, 70].detach().cpu())\n",
    "    plt.show()\n",
    "    # visualize the 3 channels model output corresponding to this image\n",
    "    plt.figure(\"output\", (18, 6))\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.title(f\"output channel {i}\")\n",
    "        plt.imshow(val_output[i, :, :, 70].detach().cpu())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72008d25-1557-4bf3-b8ba-2ff2ee593c19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # select one image to evaluate and visualize the model output\n",
    "    val_inputct = val_ds[7][\"image\"].unsqueeze(0).to(device)\n",
    "    val_inputpt = val_ds[7][\"image2\"].unsqueeze(0).to(device)\n",
    "    val_input = torch.concat([val_inputct, val_inputpt], axis=1)\n",
    "    roi_size = (192, 192, 192)\n",
    "    sw_batch_size = 4\n",
    "    val_output = inference(val_input)\n",
    "    val_output = post_trans(val_output[0])\n",
    "    plt.figure(\"image\", (6, 6))\n",
    "    for i in range(1):\n",
    "        plt.subplot(1, 2, i + 1)\n",
    "        plt.title(f\"image channel {i}\")\n",
    "        plt.imshow(val_ds[7][\"image\"][i, :, :, 70].detach().cpu(), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    # visualize the 3 channels label corresponding to this image\n",
    "    plt.figure(\"label\", (18, 6))\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.title(f\"label channel {i}\")\n",
    "        plt.imshow(val_ds[7][\"label\"][i, :, :, 70].detach().cpu())\n",
    "    plt.show()\n",
    "    # visualize the 3 channels model output corresponding to this image\n",
    "    plt.figure(\"output\", (18, 6))\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.title(f\"output channel {i}\")\n",
    "        plt.imshow(val_output[i, :, :, 70].detach().cpu())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2bb456-9b43-4d56-a80d-37fd956bb3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
